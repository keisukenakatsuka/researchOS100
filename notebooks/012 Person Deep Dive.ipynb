{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf37ff2-d1da-47e7-bf88-dc1a2e1f636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 012 Person Deep Dive\n",
    "# ============================================================\n",
    "# Purpose:\n",
    "# This notebook is designed to support *initial meetings* with startup founders,\n",
    "# executives, or key decision-makers by producing a concise, evidence-based\n",
    "# briefing using lightweight public signals.\n",
    "#\n",
    "# Rather than attempting exhaustive web crawling or deep document parsing,\n",
    "# this notebook prioritizes speed, robustness, and decision relevance.\n",
    "#\n",
    "# The core idea is:\n",
    "#   \"Good enough context, quickly, with clear sources and open questions.\"\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# What this notebook does\n",
    "# ------------------------------------------------------------\n",
    "# 1) Collects minimal user inputs (name, company, context)\n",
    "# 2) Generates a small set of simple, high-signal search queries\n",
    "# 3) Retrieves only top-ranked Google CSE results (title + snippet + URL)\n",
    "# 4) Passes those results to an LLM for structured summarization and synthesis\n",
    "# 5) Outputs a short meeting-ready brief with sources and validation questions\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# What this notebook intentionally does NOT do\n",
    "# ------------------------------------------------------------\n",
    "# - It does NOT attempt full biography reconstruction.\n",
    "# - It does NOT scrape or deeply parse webpage HTML.\n",
    "# - It does NOT infer private attributes or make definitive judgments.\n",
    "# - It does NOT replace direct confirmation during the meeting.\n",
    "#\n",
    "# Any missing or ambiguous information is explicitly labeled as such\n",
    "# and treated as a prompt for clarification, not speculation.\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# Intended use cases\n",
    "# ------------------------------------------------------------\n",
    "# - First meetings with founders or executives\n",
    "# - Investment or partnership pre-reads\n",
    "# - Rapid personal context building before live discussions\n",
    "# - Hypothesis-driven conversation preparation\n",
    "#\n",
    "# This notebook is optimized for \"speed to insight\", not completeness.\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# Design principles\n",
    "# ------------------------------------------------------------\n",
    "# - Lightweight by default: prefer snippets over full documents\n",
    "# - Source-first: every claim should point to a concrete URL\n",
    "# - Hypothesis, not conclusion: outputs are meant to be tested in conversation\n",
    "# - Transparency: search queries and sources are always visible\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# Output philosophy\n",
    "# ------------------------------------------------------------\n",
    "# The final output should help the user:\n",
    "# - Avoid obvious questions already answered publicly\n",
    "# - Ask sharper, more specific validation questions\n",
    "# - Quickly understand how this individual presents themselves externally\n",
    "# - Identify gaps or ambiguities worth exploring in the meeting\n",
    "#\n",
    "# In short, this notebook helps you walk into the room\n",
    "# *informed, curious, and directionally prepared*â€”not overconfident.\n",
    "# ============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f65e3b3-46df-44bd-9461-2b4c977d24da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 1. Input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Provide minimal context to guide search and synthesis. Fields can be left blank if unknown."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3362ed6f4fbf45f787a41535829f6207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Name', layout=Layout(width='450px'), placeholder='e.g., Keisuke Nakâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. Widget Input\n",
    "# ============================================================\n",
    "# Purpose:\n",
    "# Capture minimal but high-signal inputs that guide search queries\n",
    "# and downstream LLM synthesis.\n",
    "#\n",
    "# Inputs are intentionally lightweight.\n",
    "# If a field is unknown, it can be left blank.\n",
    "#\n",
    "# The notebook is designed to work even with partial information.\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1-1. Imports\n",
    "# ----------------------------\n",
    "import ipywidgets as widgets\n",
    "from dataclasses import dataclass\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1-2. Input data model\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class InputContext:\n",
    "    person_name: str\n",
    "    company_name: str\n",
    "    meeting_context: str\n",
    "    role_hint: str\n",
    "    language_preference: str   # \"en\" or \"ja\"\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1-3. Widgets\n",
    "# ----------------------------\n",
    "\n",
    "person_name_w = widgets.Text(\n",
    "    description=\"Name\",\n",
    "    placeholder=\"e.g., Keisuke Nakatsuka\",\n",
    "    style={\"description_width\": \"120px\"},\n",
    "    layout=widgets.Layout(width=\"450px\"),\n",
    ")\n",
    "\n",
    "company_name_w = widgets.Text(\n",
    "    description=\"Company\",\n",
    "    placeholder=\"e.g., B Capital\",\n",
    "    style={\"description_width\": \"120px\"},\n",
    "    layout=widgets.Layout(width=\"450px\"),\n",
    ")\n",
    "\n",
    "role_hint_w = widgets.Text(\n",
    "    description=\"Role (optional)\",\n",
    "    placeholder=\"e.g., Founder, CEO, GM Japan\",\n",
    "    style={\"description_width\": \"120px\"},\n",
    "    layout=widgets.Layout(width=\"450px\"),\n",
    ")\n",
    "\n",
    "meeting_context_w = widgets.Textarea(\n",
    "    description=\"Meeting context\",\n",
    "    placeholder=(\n",
    "        \"e.g., Initial investment discussion, partnership exploration, \"\n",
    "        \"customer introduction, recruiting conversation\"\n",
    "    ),\n",
    "    style={\"description_width\": \"120px\"},\n",
    "    layout=widgets.Layout(width=\"650px\", height=\"90px\"),\n",
    ")\n",
    "\n",
    "language_w = widgets.Dropdown(\n",
    "    description=\"Output language\",\n",
    "    options=[(\"English\", \"en\"), (\"Japanese\", \"ja\")],\n",
    "    value=\"en\",\n",
    "    style={\"description_width\": \"120px\"},\n",
    ")\n",
    "\n",
    "submit_button = widgets.Button(\n",
    "    description=\"Confirm inputs\",\n",
    "    button_style=\"success\",\n",
    "    icon=\"check\",\n",
    "    layout=widgets.Layout(width=\"200px\"),\n",
    ")\n",
    "\n",
    "input_out = widgets.Output()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1-4. State & handler\n",
    "# ----------------------------\n",
    "INPUT_STATE = {\"context\": None}\n",
    "\n",
    "def _on_submit(_):\n",
    "    with input_out:\n",
    "        input_out.clear_output()\n",
    "\n",
    "        INPUT_STATE[\"context\"] = InputContext(\n",
    "            person_name=person_name_w.value.strip(),\n",
    "            company_name=company_name_w.value.strip(),\n",
    "            role_hint=role_hint_w.value.strip(),\n",
    "            meeting_context=meeting_context_w.value.strip(),\n",
    "            language_preference=language_w.value,\n",
    "        )\n",
    "\n",
    "        ctx = INPUT_STATE[\"context\"]\n",
    "\n",
    "        # Basic validation (lightweight)\n",
    "        if not ctx.person_name:\n",
    "            display(Markdown(\"âš ï¸ **Name is required to proceed.**\"))\n",
    "            return\n",
    "\n",
    "        display(Markdown(\"### âœ… Input confirmed\"))\n",
    "        display(Markdown(f\"- **Name**: {ctx.person_name}\"))\n",
    "        display(Markdown(f\"- **Company**: {ctx.company_name or '(not provided)'}\"))\n",
    "        if ctx.role_hint:\n",
    "            display(Markdown(f\"- **Role hint**: {ctx.role_hint}\"))\n",
    "        if ctx.meeting_context:\n",
    "            display(Markdown(f\"- **Meeting context**: {ctx.meeting_context}\"))\n",
    "        display(Markdown(f\"- **Output language**: {ctx.language_preference}\"))\n",
    "\n",
    "submit_button.on_click(_on_submit)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1-5. Render UI\n",
    "# ----------------------------\n",
    "display(Markdown(\"### 1. Input\"))\n",
    "display(Markdown(\n",
    "    \"Provide minimal context to guide search and synthesis. \"\n",
    "    \"Fields can be left blank if unknown.\"\n",
    "))\n",
    "\n",
    "display(widgets.VBox([\n",
    "    person_name_w,\n",
    "    company_name_w,\n",
    "    role_hint_w,\n",
    "    meeting_context_w,\n",
    "    language_w,\n",
    "    submit_button,\n",
    "    input_out,\n",
    "]))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1-6. Accessor\n",
    "# ----------------------------\n",
    "def get_input_context() -> InputContext:\n",
    "    \"\"\"\n",
    "    Returns the confirmed input context.\n",
    "    \"\"\"\n",
    "    ctx = INPUT_STATE.get(\"context\")\n",
    "    if ctx is None:\n",
    "        raise ValueError(\"Input not confirmed. Please fill in the fields and click 'Confirm inputs'.\")\n",
    "    return ctx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6863f95e-e04e-4e9c-86b8-4393708ffbf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OPENAI_API_KEY loaded successfully\n",
      "âœ… Google CSE credentials loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 2. Query Generation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Generating a minimal set of high-signal search queries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Generated queries"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. `\"Pham Quang Cuong\" \"Eureka Robotics\" ç•¥æ­´`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. `\"Pham Quang Cuong\" \"Eureka Robotics\" çµŒæ­´`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. `\"Pham Quang Cuong\" \"Eureka Robotics\" interview`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. `\"Pham Quang Cuong\" \"Eureka Robotics\" ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5. `\"Pham Quang Cuong\" \"Eureka Robotics\" speaker`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "6. `\"Pham Quang Cuong\" \"Eureka Robotics\" ç™»å£‡`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "7. `\"Pham Quang Cuong\" \"Eureka Robotics\" LinkedIn`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "8. `\"Pham Quang Cuong\" \"CEO\" \"Eureka Robotics\"`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2. Query (Ultra-Simple)\n",
    "# ============================================================\n",
    "# Purpose:\n",
    "# Generate a small set of high-signal search queries that are\n",
    "# robust across languages and content types.\n",
    "#\n",
    "# This section intentionally avoids complex query logic.\n",
    "# Fewer, clearer queries tend to outperform long, overfitted ones\n",
    "# for initial discovery.\n",
    "#\n",
    "# Input:\n",
    "# - InputContext from Section 1\n",
    "#\n",
    "# Output:\n",
    "# - A short, ordered list of search queries to be sent to Google CSE\n",
    "# ============================================================\n",
    "\n",
    "# ----------------------------\n",
    "# 2-0. Load API Keys\n",
    "# ----------------------------\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load env.txt explicitly\n",
    "load_dotenv(\"env.txt\")\n",
    "\n",
    "# --- OpenAI ---\n",
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY could not be loaded from env.txt.\")\n",
    "else:\n",
    "    print(\"âœ… OPENAI_API_KEY loaded successfully\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# --- Google CSE ---\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_CSE_CX = os.getenv(\"GOOGLE_CSE_CX\")\n",
    "\n",
    "if GOOGLE_API_KEY is None or GOOGLE_CSE_CX is None:\n",
    "    raise ValueError(\"GOOGLE_API_KEY or GOOGLE_CSE_CX is missing in env.txt\")\n",
    "else:\n",
    "    print(\"âœ… Google CSE credentials loaded successfully\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2-1. Load input context\n",
    "# ----------------------------\n",
    "ctx = get_input_context()\n",
    "\n",
    "display(Markdown(\"### 2. Query Generation\"))\n",
    "display(Markdown(\"Generating a minimal set of high-signal search queries.\"))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2-2. Query builder\n",
    "# ----------------------------\n",
    "def build_simple_queries(ctx) -> list[str]:\n",
    "    \"\"\"\n",
    "    Build a small number of clear, intent-driven search queries.\n",
    "    Queries are language-aware but remain simple.\n",
    "    \"\"\"\n",
    "    name = ctx.person_name.strip()\n",
    "    company = ctx.company_name.strip()\n",
    "    role = ctx.role_hint.strip()\n",
    "\n",
    "    base = f'\"{name}\"'\n",
    "    company_clause = f' \"{company}\"' if company else \"\"\n",
    "    role_clause = f' \"{role}\"' if role else \"\"\n",
    "\n",
    "    queries = []\n",
    "\n",
    "    # --- Biography / background ---\n",
    "    queries.append(f'{base}{company_clause} ç•¥æ­´')\n",
    "    queries.append(f'{base}{company_clause} çµŒæ­´')\n",
    "\n",
    "    # --- Interviews / thought leadership ---\n",
    "    queries.append(f'{base}{company_clause} interview')\n",
    "    queries.append(f'{base}{company_clause} ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼')\n",
    "\n",
    "    # --- Talks / public appearances ---\n",
    "    queries.append(f'{base}{company_clause} speaker')\n",
    "    queries.append(f'{base}{company_clause} ç™»å£‡')\n",
    "\n",
    "    # --- LinkedIn anchor (identity check) ---\n",
    "    queries.append(f'{base}{company_clause} LinkedIn')\n",
    "\n",
    "    # Optional role disambiguation\n",
    "    if role:\n",
    "        queries.append(f'{base}{role_clause}{company_clause}')\n",
    "\n",
    "    # De-duplicate while preserving order\n",
    "    seen = set()\n",
    "    clean_queries = []\n",
    "    for q in queries:\n",
    "        q2 = \" \".join(q.split())\n",
    "        if q2 not in seen:\n",
    "            clean_queries.append(q2)\n",
    "            seen.add(q2)\n",
    "\n",
    "    return clean_queries\n",
    "\n",
    "\n",
    "queries = build_simple_queries(ctx)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2-3. Review queries (transparency)\n",
    "# ----------------------------\n",
    "display(Markdown(\"#### Generated queries\"))\n",
    "for i, q in enumerate(queries, start=1):\n",
    "    display(Markdown(f\"{i}. `{q}`\"))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2-4. Accessor\n",
    "# ----------------------------\n",
    "def get_search_queries() -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns the generated search queries.\n",
    "    \"\"\"\n",
    "    return queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b60af3f-e42c-4cab-a555-ce1182717304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 3. Google CSE Retrieval"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Running **8** base queries and collecting top results."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" ç•¥æ­´' page=0 start=1 items=5\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" ç•¥æ­´' page=1 start=6 items=1\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" çµŒæ­´' page=0 start=1 items=5\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" çµŒæ­´' page=1 start=6 items=5\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" interview' page=0 start=1 items=5\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" interview' page=1 start=6 items=5\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼' page=0 start=1 items=5\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼' page=1 start=6 items=0\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" speaker' page=0 start=1 items=5\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" speaker' page=1 start=6 items=5\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" ç™»å£‡' page=0 start=1 items=4\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" ç™»å£‡' page=1 start=6 items=0\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" LinkedIn' page=0 start=1 items=5\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"Eureka Robotics\" LinkedIn' page=1 start=6 items=5\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"CEO\" \"Eureka Robotics\"' page=0 start=1 items=5\n",
      "[DEBUG] base q='\"Pham Quang Cuong\" \"CEO\" \"Eureka Robotics\"' page=1 start=6 items=5\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 3.2 Second-wave retrieval (multi-site discovery)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Running **27** second-wave queries to broaden coverage."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 2nd q='\"Pham Quang Cuong\" \"Eureka Robotics\" \"CEO\" interview' start=1 items=5\n",
      "[DEBUG] 2nd q='\"Pham Quang Cuong\" \"Eureka Robotics\" \"CEO\" ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼' start=1 items=5\n",
      "[DEBUG] 2nd q='\"Pham Quang Cuong\" \"Eureka Robotics\" ç™»å£‡' start=1 items=4\n",
      "[DEBUG] 2nd q='\"Pham Quang Cuong\" \"Eureka Robotics\" speaker' start=1 items=5\n",
      "[DEBUG] 2nd q='\"Pham Quang Cuong\" \"Eureka Robotics\" çµŒæ­´' start=1 items=5\n",
      "[DEBUG] 2nd q='\"Pham Quang Cuong\" çµŒæ­´' start=1 items=5\n",
      "[DEBUG] 2nd q='site:prtimes.jp \"Pham Quang Cuong\" \"Eureka Robotics\" ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼' start=1 items=0\n",
      "[DEBUG] 2nd q='site:prtimes.jp \"Pham Quang Cuong\" \"Eureka Robotics\" ç™»å£‡' start=1 items=0\n",
      "[DEBUG] 2nd q='site:prtimes.jp \"Pham Quang Cuong\" \"Eureka Robotics\" profile' start=1 items=0\n",
      "[DEBUG] 2nd q='site:note.com \"Pham Quang Cuong\" \"Eureka Robotics\" ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼' start=1 items=1\n",
      "[DEBUG] 2nd q='site:note.com \"Pham Quang Cuong\" \"Eureka Robotics\" ç™»å£‡' start=1 items=0\n",
      "[DEBUG] 2nd q='site:note.com \"Pham Quang Cuong\" \"Eureka Robotics\" profile' start=1 items=0\n",
      "[DEBUG] 2nd q='site:medium.com \"Pham Quang Cuong\" \"Eureka Robotics\" ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼' start=1 items=0\n",
      "[DEBUG] 2nd q='site:medium.com \"Pham Quang Cuong\" \"Eureka Robotics\" ç™»å£‡' start=1 items=0\n",
      "[DEBUG] 2nd q='site:medium.com \"Pham Quang Cuong\" \"Eureka Robotics\" profile' start=1 items=0\n",
      "[DEBUG] 2nd q='site:youtube.com \"Pham Quang Cuong\" \"Eureka Robotics\" ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼' start=1 items=0\n",
      "[DEBUG] 2nd q='site:youtube.com \"Pham Quang Cuong\" \"Eureka Robotics\" ç™»å£‡' start=1 items=0\n",
      "[DEBUG] 2nd q='site:youtube.com \"Pham Quang Cuong\" \"Eureka Robotics\" profile' start=1 items=0\n",
      "[DEBUG] 2nd q='site:podcasts.apple.com \"Pham Quang Cuong\" \"Eureka Robotics\" ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼' start=1 items=0\n",
      "[DEBUG] 2nd q='site:podcasts.apple.com \"Pham Quang Cuong\" \"Eureka Robotics\" ç™»å£‡' start=1 items=0\n",
      "[DEBUG] 2nd q='site:podcasts.apple.com \"Pham Quang Cuong\" \"Eureka Robotics\" profile' start=1 items=0\n",
      "[DEBUG] 2nd q='site:spotify.com \"Pham Quang Cuong\" \"Eureka Robotics\" ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼' start=1 items=0\n",
      "[DEBUG] 2nd q='site:spotify.com \"Pham Quang Cuong\" \"Eureka Robotics\" ç™»å£‡' start=1 items=0\n",
      "[DEBUG] 2nd q='site:spotify.com \"Pham Quang Cuong\" \"Eureka Robotics\" profile' start=1 items=1\n",
      "[DEBUG] 2nd q='site:nikkan.co.jp \"Pham Quang Cuong\" \"Eureka Robotics\" ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼' start=1 items=0\n",
      "[DEBUG] 2nd q='site:nikkan.co.jp \"Pham Quang Cuong\" \"Eureka Robotics\" ç™»å£‡' start=1 items=0\n",
      "[DEBUG] 2nd q='site:nikkan.co.jp \"Pham Quang Cuong\" \"Eureka Robotics\" profile' start=1 items=0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Collected results: **47** (deduped, max 5 per domain)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wave</th>\n",
       "      <th>query_idx</th>\n",
       "      <th>rank_in_query</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>creators.spotify.com</td>\n",
       "      <td>#1 æ—¥æœ¬æœ€å¼·ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é›†å›£ALGO ARTISã€‚æ¥µé™ã¾ã§è‡ªç”±ã«è€ƒãˆã‚‹çŸ¥ ...</td>\n",
       "      <td>https://creators.spotify.com/pod/profile/utec/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>jp.linkedin.com</td>\n",
       "      <td>Eureka Robotics | LinkedIn</td>\n",
       "      <td>https://jp.linkedin.com/company/eurekarobotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>scholar.google.es</td>\n",
       "      <td>â€ªJingyi Yangâ€¬ - â€ªGoogle Scholarâ€¬</td>\n",
       "      <td>https://scholar.google.es/citations?user=AEINg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>scholar.google.com</td>\n",
       "      <td>Shohei Fujii - Google Scholar</td>\n",
       "      <td>https://scholar.google.com/citations?user=fh3r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>instagram.com</td>\n",
       "      <td>NTU College of Engineering (@ntucoe) Â· Singapo...</td>\n",
       "      <td>https://www.instagram.com/ntucoe/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>ut-ec.co.jp</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>https://www.ut-ec.co.jp/admin/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>base</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>sg.linkedin.com</td>\n",
       "      <td>Eureka Robotics | LinkedIn</td>\n",
       "      <td>https://sg.linkedin.com/company/eurekarobotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>base</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ut-ec.co.jp</td>\n",
       "      <td>Eureka Robotics Pte. Ltd.ï½œæŠ•è³‡å…ˆä¼æ¥­ï½œUTEC-æ±äº¬å¤§å­¦ã‚¨ãƒƒã‚¸ ...</td>\n",
       "      <td>https://www.ut-ec.co.jp/our_companies/eureka-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>base</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>startupclass.co.jp</td>\n",
       "      <td>Eureka Roboticsæ ªå¼ä¼šç¤¾ã®è»¢è·ãƒ»æ±‚äººæƒ…å ± | ã‚¹ã‚¿ã‚¯ãƒ©</td>\n",
       "      <td>https://startupclass.co.jp/online/companies/1742/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>prtimes.jp</td>\n",
       "      <td>Eureka Roboticsã€ã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1,050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’ ...</td>\n",
       "      <td>https://prtimes.jp/main/html/rd/p/000000001.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>base</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>x.com</td>\n",
       "      <td>Kiran Mysore (@ThinkSpection) / Posts / X</td>\n",
       "      <td>https://x.com/ThinkSpection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>base</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>pdf.irpocket.com</td>\n",
       "      <td>EUREKA ROBOTICS PTE. LTD.ã¸ã®å‡ºè³‡ã«é–¢ã™ã‚‹ãŠçŸ¥ã‚‰ã›</td>\n",
       "      <td>https://pdf.irpocket.com/C7128/PEbr/A4ef/OHYp.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>base</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>startup.aliyun.com</td>\n",
       "      <td>çœ‹è§äºšæ´²ä¹‹æ˜Ÿï¼šEureka Roboticsè”åˆåˆ›å§‹äººå¯¹æœºå™¨äººç§‘æŠ€çš„5ä¸ªæ€è€ƒ</td>\n",
       "      <td>https://startup.aliyun.com/info/107582.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>base</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>robotstart.info</td>\n",
       "      <td>Eureka RoboticsãŒã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’ ...</td>\n",
       "      <td>https://robotstart.info/article/2024/12/13/365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>base</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>alibabacloud.com</td>\n",
       "      <td>Eureka Robotics Co-founder: 5 Thoughts on Robo...</td>\n",
       "      <td>https://www.alibabacloud.com/blog/eureka-robot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>base</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>backscoop.com</td>\n",
       "      <td>Ice Breakers with Pham Quang Cuong</td>\n",
       "      <td>https://www.backscoop.com/newsletter-posts/ice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>base</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>kr-asia.com</td>\n",
       "      <td>5 thoughts from Eureka Robotics co-founder on ...</td>\n",
       "      <td>https://kr-asia.com/5-thoughts-from-eureka-rob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>base</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>Eureka Robotics' new robotic arm is designed f...</td>\n",
       "      <td>https://techcrunch.com/2019/10/09/eureka-robot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>base</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>ntu.edu.sg</td>\n",
       "      <td>Latest News | Innovation and Entrepreneurship ...</td>\n",
       "      <td>https://www.ntu.edu.sg/innovates/news-events/news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>base</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>technode.global</td>\n",
       "      <td>Singapore's Eureka Robotics raises $10.5 in Se...</td>\n",
       "      <td>https://technode.global/2024/12/13/singapores-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>base</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>youtube.com</td>\n",
       "      <td>Eureka Robotics' Archimedes | Interview with P...</td>\n",
       "      <td>https://www.youtube.com/watch?v=yM1L3dFbfF8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>base</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>instagram.com</td>\n",
       "      <td>Eureka Robotics on Instagram: \" Eureka Tokyo i...</td>\n",
       "      <td>https://www.instagram.com/p/DLZXxs0SjQ2/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>base</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>facebook.com</td>\n",
       "      <td>Eureka Robotics | Singapore Singapore</td>\n",
       "      <td>https://www.facebook.com/eurekarobotics/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>base</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ut-ec.co.jp</td>\n",
       "      <td>Eureka Robotics Pte. Ltd.ï½œOur Companiesï½œUTEC-T...</td>\n",
       "      <td>https://www.ut-ec.co.jp/english/our_companies/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>base</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>note.com</td>\n",
       "      <td>Physical AIã¯ç¾å ´ã§å®Œæˆã™ã‚‹ â€• Eureka RoboticsãŒé¸ã¶é“ï½œæ ªå¼ ...</td>\n",
       "      <td>https://note.com/torch_inc/n/n2ab26d800197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>base</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>robotics247.com</td>\n",
       "      <td>Eureka Robotics Develops Software to Add Sensi...</td>\n",
       "      <td>https://www.robotics247.com/article/eureka_rob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>base</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>roboticsynl.com</td>\n",
       "      <td>Invited Speakers â€“ International Robotics Work...</td>\n",
       "      <td>http://roboticsynl.com/IRW/invited-speakers/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>base</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>vir.com.vn</td>\n",
       "      <td>Innovation charms in Singapore</td>\n",
       "      <td>https://vir.com.vn/innovation-charms-in-singap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>base</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>Brian Heater, Author at TechCrunch | Page 90 o...</td>\n",
       "      <td>https://techcrunch.com/author/brian-heater/pag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>base</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>ut-ec.co.jp</td>\n",
       "      <td>â€œUTEC UTokyo Meetupâ€ (Supported by: The Univer...</td>\n",
       "      <td>https://www.ut-ec.co.jp/english/about_us/news/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wave  query_idx  rank_in_query                domain  \\\n",
       "0   base          1              1  creators.spotify.com   \n",
       "1   base          1              2       jp.linkedin.com   \n",
       "2   base          1              3     scholar.google.es   \n",
       "3   base          1              4    scholar.google.com   \n",
       "4   base          1              5         instagram.com   \n",
       "5   base          1              6           ut-ec.co.jp   \n",
       "6   base          2              1       sg.linkedin.com   \n",
       "7   base          2              2           ut-ec.co.jp   \n",
       "8   base          2              3    startupclass.co.jp   \n",
       "9   base          2              4            prtimes.jp   \n",
       "10  base          2              6                 x.com   \n",
       "11  base          2              7      pdf.irpocket.com   \n",
       "12  base          2              8    startup.aliyun.com   \n",
       "13  base          2             10       robotstart.info   \n",
       "14  base          3              1      alibabacloud.com   \n",
       "15  base          3              2         backscoop.com   \n",
       "16  base          3              3           kr-asia.com   \n",
       "17  base          3              4        techcrunch.com   \n",
       "18  base          3              5            ntu.edu.sg   \n",
       "19  base          3              6       technode.global   \n",
       "20  base          3              7           youtube.com   \n",
       "21  base          3              8         instagram.com   \n",
       "22  base          3              9          facebook.com   \n",
       "23  base          4              1           ut-ec.co.jp   \n",
       "24  base          4              5              note.com   \n",
       "25  base          5              2       robotics247.com   \n",
       "26  base          5              3       roboticsynl.com   \n",
       "27  base          5              4            vir.com.vn   \n",
       "28  base          5              5        techcrunch.com   \n",
       "29  base          5              6           ut-ec.co.jp   \n",
       "\n",
       "                                                title  \\\n",
       "0            #1 æ—¥æœ¬æœ€å¼·ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é›†å›£ALGO ARTISã€‚æ¥µé™ã¾ã§è‡ªç”±ã«è€ƒãˆã‚‹çŸ¥ ...   \n",
       "1                          Eureka Robotics | LinkedIn   \n",
       "2                    â€ªJingyi Yangâ€¬ - â€ªGoogle Scholarâ€¬   \n",
       "3                       Shohei Fujii - Google Scholar   \n",
       "4   NTU College of Engineering (@ntucoe) Â· Singapo...   \n",
       "5                                            Untitled   \n",
       "6                          Eureka Robotics | LinkedIn   \n",
       "7    Eureka Robotics Pte. Ltd.ï½œæŠ•è³‡å…ˆä¼æ¥­ï½œUTEC-æ±äº¬å¤§å­¦ã‚¨ãƒƒã‚¸ ...   \n",
       "8                  Eureka Roboticsæ ªå¼ä¼šç¤¾ã®è»¢è·ãƒ»æ±‚äººæƒ…å ± | ã‚¹ã‚¿ã‚¯ãƒ©   \n",
       "9        Eureka Roboticsã€ã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1,050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’ ...   \n",
       "10          Kiran Mysore (@ThinkSpection) / Posts / X   \n",
       "11              EUREKA ROBOTICS PTE. LTD.ã¸ã®å‡ºè³‡ã«é–¢ã™ã‚‹ãŠçŸ¥ã‚‰ã›   \n",
       "12             çœ‹è§äºšæ´²ä¹‹æ˜Ÿï¼šEureka Roboticsè”åˆåˆ›å§‹äººå¯¹æœºå™¨äººç§‘æŠ€çš„5ä¸ªæ€è€ƒ   \n",
       "13        Eureka RoboticsãŒã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’ ...   \n",
       "14  Eureka Robotics Co-founder: 5 Thoughts on Robo...   \n",
       "15                 Ice Breakers with Pham Quang Cuong   \n",
       "16  5 thoughts from Eureka Robotics co-founder on ...   \n",
       "17  Eureka Robotics' new robotic arm is designed f...   \n",
       "18  Latest News | Innovation and Entrepreneurship ...   \n",
       "19  Singapore's Eureka Robotics raises $10.5 in Se...   \n",
       "20  Eureka Robotics' Archimedes | Interview with P...   \n",
       "21  Eureka Robotics on Instagram: \" Eureka Tokyo i...   \n",
       "22              Eureka Robotics | Singapore Singapore   \n",
       "23  Eureka Robotics Pte. Ltd.ï½œOur Companiesï½œUTEC-T...   \n",
       "24   Physical AIã¯ç¾å ´ã§å®Œæˆã™ã‚‹ â€• Eureka RoboticsãŒé¸ã¶é“ï½œæ ªå¼ ...   \n",
       "25  Eureka Robotics Develops Software to Add Sensi...   \n",
       "26  Invited Speakers â€“ International Robotics Work...   \n",
       "27                     Innovation charms in Singapore   \n",
       "28  Brian Heater, Author at TechCrunch | Page 90 o...   \n",
       "29  â€œUTEC UTokyo Meetupâ€ (Supported by: The Univer...   \n",
       "\n",
       "                                                  url  \n",
       "0   https://creators.spotify.com/pod/profile/utec/...  \n",
       "1      https://jp.linkedin.com/company/eurekarobotics  \n",
       "2   https://scholar.google.es/citations?user=AEINg...  \n",
       "3   https://scholar.google.com/citations?user=fh3r...  \n",
       "4                   https://www.instagram.com/ntucoe/  \n",
       "5   https://www.ut-ec.co.jp/admin/wp-content/uploa...  \n",
       "6      https://sg.linkedin.com/company/eurekarobotics  \n",
       "7   https://www.ut-ec.co.jp/our_companies/eureka-r...  \n",
       "8   https://startupclass.co.jp/online/companies/1742/  \n",
       "9   https://prtimes.jp/main/html/rd/p/000000001.00...  \n",
       "10                        https://x.com/ThinkSpection  \n",
       "11  https://pdf.irpocket.com/C7128/PEbr/A4ef/OHYp.pdf  \n",
       "12        https://startup.aliyun.com/info/107582.html  \n",
       "13  https://robotstart.info/article/2024/12/13/365...  \n",
       "14  https://www.alibabacloud.com/blog/eureka-robot...  \n",
       "15  https://www.backscoop.com/newsletter-posts/ice...  \n",
       "16  https://kr-asia.com/5-thoughts-from-eureka-rob...  \n",
       "17  https://techcrunch.com/2019/10/09/eureka-robot...  \n",
       "18  https://www.ntu.edu.sg/innovates/news-events/news  \n",
       "19  https://technode.global/2024/12/13/singapores-...  \n",
       "20        https://www.youtube.com/watch?v=yM1L3dFbfF8  \n",
       "21           https://www.instagram.com/p/DLZXxs0SjQ2/  \n",
       "22           https://www.facebook.com/eurekarobotics/  \n",
       "23  https://www.ut-ec.co.jp/english/our_companies/...  \n",
       "24         https://note.com/torch_inc/n/n2ab26d800197  \n",
       "25  https://www.robotics247.com/article/eureka_rob...  \n",
       "26       http://roboticsynl.com/IRW/invited-speakers/  \n",
       "27  https://vir.com.vn/innovation-charms-in-singap...  \n",
       "28  https://techcrunch.com/author/brian-heater/pag...  \n",
       "29  https://www.ut-ec.co.jp/english/about_us/news/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ğŸ” Search Results Preview (Title / Snippet / URL)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**1. #1 æ—¥æœ¬æœ€å¼·ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é›†å›£ALGO ARTISã€‚æ¥µé™ã¾ã§è‡ªç”±ã«è€ƒãˆã‚‹çŸ¥ ...**\n",
       "\n",
       "ã‚²ã‚¹ãƒˆçµŒæ­´ä¸­æ²¢å†¬èŠ½1998å¹´ç”Ÿã¾ã‚Œã€‚é•·é‡çœŒæ¾æœ¬å¸‚å‡ºèº«ã€‚ æ±äº¬å¤§å­¦æ³•å­¦éƒ¨åœ¨å­¦ä¸­ã« ... We are thrilled to have Dr. Pham Quang Cuong, CEO of Eureka Robotics, theÂ ...\n",
       "\n",
       "ğŸ”— https://creators.spotify.com/pod/profile/utec/episodes/2-ALGO-ARTISALGO-ARTIS-e2l0qs7\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**2. Eureka Robotics | LinkedIn**\n",
       "\n",
       "Jan 12, 2025 ... Eureka Robotics | LinkedInã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°6856äººã€‚Physical AI ... Our CEO Pham Quang Cuong, CTO Hung Pham, SVP of Products Sami AkhtarÂ ...\n",
       "\n",
       "ğŸ”— https://jp.linkedin.com/company/eurekarobotics\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**3. â€ªJingyi Yangâ€¬ - â€ªGoogle Scholarâ€¬**\n",
       "\n",
       "* ãŒä»˜ã„ãŸè«–æ–‡ã¯ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å†…ã®è«–æ–‡ã¨ã¯ç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ ... Pháº¡m Quang CÆ°á»ngEureka Roboticsç¢ºèªã—ãŸãƒ¡ãƒ¼ãƒ« ã‚¢ãƒ‰ãƒ¬ã‚¹: normalesup.org.\n",
       "\n",
       "ğŸ”— https://scholar.google.es/citations?user=AEINg6kAAAAJ&hl=ja\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**4. Shohei Fujii - Google Scholar**\n",
       "\n",
       "* ãŒä»˜ã„ãŸè«–æ–‡ã¯ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å†…ã®è«–æ–‡ã¨ã¯ç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ ... å…±è‘—è€…. Pháº¡m Quang CÆ°á»ngEureka Roboticsç¢ºèªã—ãŸãƒ¡ãƒ¼ãƒ« ã‚¢ãƒ‰ãƒ¬ã‚¹: normalesup.\n",
       "\n",
       "ğŸ”— https://scholar.google.com/citations?user=fh3rENwAAAAJ&hl=ja\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**5. NTU College of Engineering (@ntucoe) Â· Singapore, Singapore**\n",
       "\n",
       "... Eureka Robotics now has a firm grip on the future of industrial automation ... Pham Quang Cuong, the firm has now developed software algorithms thatÂ ...\n",
       "\n",
       "ğŸ”— https://www.instagram.com/ntucoe/\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**6. Untitled**\n",
       "\n",
       "Eureka Robotics Pte. Ltd. HA-HAï¼ˆHigh Accuracy-High Agilityï¼‰ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã® ... Pham Quang Cuongã¯ã€ãƒ•ãƒ©ãƒ³ã‚¹ã®ã‚½ãƒ«ãƒœãƒ³. ãƒŒå¤§å­¦ã§ç¥çµŒç§‘å­¦ã¨ãƒ­ãƒœãƒƒãƒˆå·¥å­¦ã®Â ...\n",
       "\n",
       "ğŸ”— https://www.ut-ec.co.jp/admin/wp-content/uploads/2024/05/2024_utec_jp_compressed.pdf\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**7. Eureka Robotics | LinkedIn**\n",
       "\n",
       "Jan 12, 2025 ... Our CEO Pham Quang Cuong, CTO Hung Pham, SVP of Products Sami Akhtar ... View organization page for Eureka Robotics. Eureka Robotics. 6,875Â ...\n",
       "\n",
       "ğŸ”— https://sg.linkedin.com/company/eurekarobotics\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**8. Eureka Robotics Pte. Ltd.ï½œæŠ•è³‡å…ˆä¼æ¥­ï½œUTEC-æ±äº¬å¤§å­¦ã‚¨ãƒƒã‚¸ ...**\n",
       "\n",
       "Eureka Robotics Pte. Ltd.ï½œæŠ•è³‡å…ˆä¼æ¥­ã®ç´¹ä»‹ãƒšãƒ¼ã‚¸ã§ã™ã€‚UTEC ... Pham Quang Cuongã¯ã€ãƒ•ãƒ©ãƒ³ã‚¹ã®ã‚½ãƒ«ãƒœãƒ³ãƒŒå¤§å­¦ã§ç¥çµŒç§‘å­¦ã¨ãƒ­ãƒœãƒƒãƒˆå·¥å­¦ã®åšå£«å·Â ...\n",
       "\n",
       "ğŸ”— https://www.ut-ec.co.jp/our_companies/eureka-robotics/\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**9. Eureka Roboticsæ ªå¼ä¼šç¤¾ã®è»¢è·ãƒ»æ±‚äººæƒ…å ± | ã‚¹ã‚¿ã‚¯ãƒ©**\n",
       "\n",
       "ä¼šç¤¾æ¦‚è¦. ä¼šç¤¾å, Eureka Roboticsæ ªå¼ä¼šç¤¾. ä»£è¡¨è€…å, ä»£è¡¨å–ç· å½¹ Pham Quang Cuong. æ‰€åœ¨åœ°, æ±äº¬éƒ½. ä¼šç¤¾URL, https://eurekarobotics.com/. è¨­ç«‹, 2018å¹´. å¾“æ¥­å“¡æ•°Â ...\n",
       "\n",
       "ğŸ”— https://startupclass.co.jp/online/companies/1742/\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**10. Eureka Roboticsã€ã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1,050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’ ...**\n",
       "\n",
       "Dec 13, 2024 ... Eureka Roboticsã®å…±åŒå‰µæ¥­è€… å…¼ CEOã§ã‚ã‚‹ãƒ•ã‚¡ãƒ ãƒ»ã‚¯ã‚¢ãƒ³ãƒ»ã‚¯ã‚ªãƒ³ï¼ˆPham Quang Cuongï¼‰ã¯æ¬¡ã®ã‚ˆã†ã«è¿°ã¹ã¦ã„ã¾ã™ã€‚ ã€ŒEureka Roboticsã¯ä¸–ç•Œã®å·¥å ´Â ...\n",
       "\n",
       "ğŸ”— https://prtimes.jp/main/html/rd/p/000000001.000153512.html\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**11. Kiran Mysore (@ThinkSpection) / Posts / X**\n",
       "\n",
       "ã€å…¬å¼ã€‘UTEC (æ±äº¬å¤§å­¦ã‚¨ãƒƒã‚¸ã‚­ãƒ£ãƒ”ã‚¿ãƒ«ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚º)'s Image 1 on. ã€å…¬å¼ã€‘ ... Pham Quang Cuong dives into Eureka Robotics' expansion in Japan and theirÂ ...\n",
       "\n",
       "ğŸ”— https://x.com/ThinkSpection\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**12. EUREKA ROBOTICS PTE. LTD.ã¸ã®å‡ºè³‡ã«é–¢ã™ã‚‹ãŠçŸ¥ã‚‰ã›**\n",
       "\n",
       "Dec 13, 2024 ... EUREKA ROBOTICS PTE. LTD.ã¸ã®å‡ºè³‡ã«é–¢ã™ã‚‹ãŠçŸ¥ã‚‰ã›. å½“ç¤¾ ... EUREKA ç¤¾ã¯ã€ã‚·ãƒ³ã‚¬ãƒãƒ¼ãƒ«ã®å—æ´‹ç†å·¥å¤§å­¦ã®å‡†æ•™æˆã§ã‚ã£ãŸ Pham Quang Cuong æ°ãŒ.\n",
       "\n",
       "ğŸ”— https://pdf.irpocket.com/C7128/PEbr/A4ef/OHYp.pdf\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**13. çœ‹è§äºšæ´²ä¹‹æ˜Ÿï¼šEureka Roboticsè”åˆåˆ›å§‹äººå¯¹æœºå™¨äººç§‘æŠ€çš„5ä¸ªæ€è€ƒ**\n",
       "\n",
       "æ–°åŠ å¡åˆ›ä¸šå…¬å¸Eureka Roboticsæ­£åŠªåŠ›ä¸ºæ—¥ç›Šå¢é•¿çš„æœºå™¨äººå¸‚åœºæ·»ç –åŠ ç“¦ï¼Œå¹¶åœ¨ä¸œå—äºšå¸¦æ¥åˆ›æ–°ã€‚è¯¥å…¬å¸ç”±Pham Quang Cuongå’ŒHung Phamäº2018å¹´åœ¨å—æ´‹ç†å·¥å¤§å­¦ï¼ˆNTUï¼‰åˆ›ç«‹ã€‚\n",
       "\n",
       "ğŸ”— https://startup.aliyun.com/info/107582.html\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**14. Eureka RoboticsãŒã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’ ...**\n",
       "\n",
       "Dec 13, 2024 ... Eureka Robotics å…±åŒå‰µæ¥­è€…å…¼CEO ãƒ•ã‚¡ãƒ ãƒ»ã‚¯ã‚¢ãƒ³ãƒ»ã‚¯ã‚ªãƒ³ï¼ˆPham Quang Cuongï¼‰ æ°. Eureka Roboticsã®å…±åŒå‰µæ¥­è€…å…¼CEOã®ãƒ•ã‚¡ãƒ ãƒ»ã‚¯ã‚¢ãƒ³ãƒ»ã‚¯ã‚ªãƒ³ï¼ˆå·¦Â ...\n",
       "\n",
       "ğŸ”— https://robotstart.info/article/2024/12/13/365453.html\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**15. Eureka Robotics Co-founder: 5 Thoughts on Robot Technology ...**\n",
       "\n",
       "Jan 17, 2022 ... KrASIA (Kr): What is the origin of Eureka Robotics? Pham Quang Cuong (PQC): I came to Singapore in 2013 as an assistant professor at NTUÂ ...\n",
       "\n",
       "ğŸ”— https://www.alibabacloud.com/blog/eureka-robotics-co-founder-5-thoughts-on-robot-technology_598481\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**16. Ice Breakers with Pham Quang Cuong**\n",
       "\n",
       "Sep 7, 2023 ... Pham Quang Cuong is the co-founder and CEO of Eureka Robotics, a ... We've edited this interview for clarity. Subscribe to ourÂ ...\n",
       "\n",
       "ğŸ”— https://www.backscoop.com/newsletter-posts/ice-breakers-with-pham-quang-cuong\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**17. 5 thoughts from Eureka Robotics co-founder on robot technology**\n",
       "\n",
       "Dec 23, 2021 ... KrASIA (Kr): What is the origin of Eureka Robotics? Pham Quang Cuong (PQC): I came to Singapore in 2013 as an assistant professor at NTU. When IÂ ...\n",
       "\n",
       "ğŸ”— https://kr-asia.com/5-thoughts-from-eureka-robotics-co-founder-on-robot-technology\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**18. Eureka Robotics' new robotic arm is designed for optical lenses and ...**\n",
       "\n",
       "Oct 9, 2019 ... Photo 1 Assoc Prof Pham Quang Cuong working with lead engineer Dr Pham Tien Hung who. Eureka Robotics' new robotic arm is designed for opticalÂ ...\n",
       "\n",
       "ğŸ”— https://techcrunch.com/2019/10/09/eureka-robotics-new-robotic-arm-is-designed-for-optical-lenses-and-mirrors/\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**19. Latest News | Innovation and Entrepreneurship | NTU Singapore**\n",
       "\n",
       "Interviews; Case Studies; White Papers. Alumni; Giving. Filter Reset. Search ... Dr Pham Quang Cuong founded Eureka Robotics to improve manufacturing processes.\n",
       "\n",
       "ğŸ”— https://www.ntu.edu.sg/innovates/news-events/news\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**20. Singapore's Eureka Robotics raises $10.5 in Series A funding round ...**\n",
       "\n",
       "Dec 13, 2024 ... Pham Quang Cuong, Eureka Robotics Co-founder and Chief Executive Officer Dr. ... Q&A and interviews Â· Startup profiles Â· Thought leadership\n",
       "\n",
       "ğŸ”— https://technode.global/2024/12/13/singapores-eureka-robotics-raises-10-5-in-series-a-funding-led-by-b-capital/\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**21. Eureka Robotics' Archimedes | Interview with Pham Quang Cuong ...**\n",
       "\n",
       "Oct 20, 2019 ... Asian Scientist Magazine interviews Pham Quang Cuong, who shares about Eureka Robotics' newly launched robot, Archimedes, which possesses aÂ ...\n",
       "\n",
       "ğŸ”— https://www.youtube.com/watch?v=yM1L3dFbfF8\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**22. Eureka Robotics on Instagram: \" Eureka Tokyo is growing fast ...**\n",
       "\n",
       "Jun 27, 2025 ... ... interview with our CEO Pham Quang Cuong a few weeks ago. The ... CEOã® Pham Quang CuongãŒã€ã¾ãšEureka Roboticsã®æˆã‚Šç«‹ã¡ã‚„æŠ€è¡“çš„ç‹¬è‡ªÂ ...\n",
       "\n",
       "ğŸ”— https://www.instagram.com/p/DLZXxs0SjQ2/\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**23. Eureka Robotics | Singapore Singapore**\n",
       "\n",
       "... Eureka Robotics following an interview with our CEO Pham Quang Cuong a few weeks ago. The article discusses one of the industry's outstanding challengesÂ ...\n",
       "\n",
       "ğŸ”— https://www.facebook.com/eurekarobotics/\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**24. Eureka Robotics Pte. Ltd.ï½œOur Companiesï½œUTEC-The University ...**\n",
       "\n",
       "Eureka Robotics Pte. Ltd.ï½œOur Companies of Introduction.UTEC is a seed ... Pham Quang Cuong is an Associate Professor of Robotics at NTU (on leave), aÂ ...\n",
       "\n",
       "ğŸ”— https://www.ut-ec.co.jp/english/our_companies/eureka-robotics/\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**25. Physical AIã¯ç¾å ´ã§å®Œæˆã™ã‚‹ â€• Eureka RoboticsãŒé¸ã¶é“ï½œæ ªå¼ ...**\n",
       "\n",
       "4 hours ago ... ... Pham Quang Cuong ï¼‰ã•ã‚“ï¼ˆä»¥ä¸‹ã€ã‚¯ã‚ªãƒ³ã•ã‚“ï¼‰ã‚’è¿ãˆã€TORCHä»£è¡¨ã®å±±å†… ... Eureka Roboticsã«ã¨ã£ã¦ã€æ—¥æœ¬å¸‚å ´ã¸ã®é€²å‡ºçŠ¶æ³ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ï¼Ÿ\n",
       "\n",
       "ğŸ”— https://note.com/torch_inc/n/n2ab26d800197\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3. Retrieve Top Results via Google CSE (Multi-site discovery, no LinkedIn deep-dive)\n",
    "# ============================================================\n",
    "# Purpose:\n",
    "# Run a small set of base queries via Google CSE and collect top results (title/snippet/url).\n",
    "# Then run a second wave of *multi-site* discovery queries to broaden coverage across:\n",
    "# - news / press releases\n",
    "# - conferences / events / webinars\n",
    "# - podcasts / video (YouTube)\n",
    "# - blogs / note / Medium\n",
    "# - company pages / partner pages\n",
    "#\n",
    "# Key idea:\n",
    "# - LinkedIn may appear in results, but we do NOT \"deep dive\" LinkedIn via site-fixed queries.\n",
    "# - We optimize for diversity and breadth of sources, while keeping payload lightweight.\n",
    "#\n",
    "# Output:\n",
    "# - search_results_df: deduped table of results with metadata\n",
    "# - Human-readable preview (Title / Snippet / URL)\n",
    "# ============================================================\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3-1. Load inputs\n",
    "# ----------------------------\n",
    "ctx = get_input_context()\n",
    "base_queries = get_search_queries()\n",
    "\n",
    "display(Markdown(\"### 3. Google CSE Retrieval\"))\n",
    "display(Markdown(f\"Running **{len(base_queries)}** base queries and collecting top results.\"))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3-2. CSE request helper\n",
    "# ----------------------------\n",
    "def cse_search(query: str, api_key: str, cx: str, num: int = 5, start: int = 1) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Google Programmable Search Engine (CSE) call.\n",
    "    num: 1..10\n",
    "    start: 1, 1+num, 1+2*num, ... (1-based index)\n",
    "    \"\"\"\n",
    "    import requests\n",
    "\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"cx\": cx,\n",
    "        \"q\": query,\n",
    "        \"num\": max(1, min(num, 10)),\n",
    "        \"start\": start,\n",
    "    }\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json().get(\"items\", [])\n",
    "\n",
    "\n",
    "def get_domain(url: str) -> str:\n",
    "    try:\n",
    "        return (urlparse(url).netloc or \"\").lower().replace(\"www.\", \"\")\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3-3. Filtering rules (lightweight)\n",
    "# ----------------------------\n",
    "def is_low_signal_url(url: str) -> bool:\n",
    "    \"\"\"\n",
    "    Filter out pages that are usually not useful for bio/interview discovery.\n",
    "    Adjust as needed.\n",
    "    \"\"\"\n",
    "    u = (url or \"\").lower()\n",
    "\n",
    "    # LinkedIn directory pages (high noise)\n",
    "    if \"linkedin.com/pub/dir\" in u or \"/pub/dir\" in u:\n",
    "        return True\n",
    "\n",
    "    # Generic search pages\n",
    "    if \"google.com/search\" in u:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3-4. Retrieval parameters\n",
    "# ----------------------------\n",
    "TOP_K_PER_PAGE = 5\n",
    "MAX_PAGES_PER_QUERY = 2\n",
    "MAX_TOTAL_RESULTS = 80\n",
    "MAX_PER_DOMAIN = 5\n",
    "SLEEP_SEC = 0.25\n",
    "\n",
    "rows = []\n",
    "seen_urls = set()\n",
    "domain_counter = {}\n",
    "\n",
    "\n",
    "def can_add_domain(domain: str) -> bool:\n",
    "    return domain_counter.get(domain, 0) < MAX_PER_DOMAIN\n",
    "\n",
    "\n",
    "def add_items_to_rows(items: list[dict], qi: int, q: str, start_rank: int, wave: str):\n",
    "    \"\"\"\n",
    "    Add CSE items to rows with dedup + domain cap.\n",
    "    \"\"\"\n",
    "    for rank, it in enumerate(items, start=start_rank):\n",
    "        url = (it.get(\"link\") or \"\").strip()\n",
    "        if not url or url in seen_urls:\n",
    "            continue\n",
    "        if is_low_signal_url(url):\n",
    "            continue\n",
    "\n",
    "        domain = get_domain(url)\n",
    "        if not can_add_domain(domain):\n",
    "            continue\n",
    "\n",
    "        seen_urls.add(url)\n",
    "        domain_counter[domain] = domain_counter.get(domain, 0) + 1\n",
    "\n",
    "        rows.append({\n",
    "            \"wave\": wave,  # \"base\" or \"second\"\n",
    "            \"query_idx\": qi,\n",
    "            \"query\": q,\n",
    "            \"rank_in_query\": rank,\n",
    "            \"title\": (it.get(\"title\") or \"\")[:250],\n",
    "            \"snippet\": (it.get(\"snippet\") or \"\")[:900],\n",
    "            \"url\": url,\n",
    "            \"domain\": domain,\n",
    "        })\n",
    "\n",
    "        if len(rows) >= MAX_TOTAL_RESULTS:\n",
    "            break\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3-5. Base wave\n",
    "# ----------------------------\n",
    "for qi, q in enumerate(base_queries, start=1):\n",
    "    for page in range(MAX_PAGES_PER_QUERY):\n",
    "        start = 1 + page * TOP_K_PER_PAGE\n",
    "        try:\n",
    "            items = cse_search(\n",
    "                q,\n",
    "                GOOGLE_API_KEY,\n",
    "                GOOGLE_CSE_CX,\n",
    "                num=TOP_K_PER_PAGE,\n",
    "                start=start,\n",
    "            )\n",
    "            print(f\"[DEBUG] base q='{q}' page={page} start={start} items={len(items)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[CSE ERROR] base q='{q}' start={start} error={e}\")\n",
    "            continue\n",
    "\n",
    "        add_items_to_rows(items, qi=qi, q=q, start_rank=start, wave=\"base\")\n",
    "        time.sleep(SLEEP_SEC)\n",
    "\n",
    "        if len(rows) >= MAX_TOTAL_RESULTS:\n",
    "            break\n",
    "    if len(rows) >= MAX_TOTAL_RESULTS:\n",
    "        break\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3-6. Second wave: multi-site discovery\n",
    "# ----------------------------\n",
    "def build_multisite_second_wave_queries(ctx) -> list[str]:\n",
    "    \"\"\"\n",
    "    Broaden discovery across multiple content types and platforms.\n",
    "    Keep queries compact and intent-driven.\n",
    "    \"\"\"\n",
    "    name = ctx.person_name.strip()\n",
    "    company = (ctx.company_name or \"\").strip()\n",
    "    role = (ctx.role_hint or \"\").strip()\n",
    "\n",
    "    base = f'\"{name}\"'\n",
    "    company_clause = f' \"{company}\"' if company else \"\"\n",
    "    role_clause = f' \"{role}\"' if role else \"\"\n",
    "\n",
    "    # Intent keywords: interviews / talks / press / profiles\n",
    "    intents = [\n",
    "        \"interview\", \"ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼\",\n",
    "        \"speaker\", \"ç™»å£‡\", \"è¬›æ¼”\", \"webinar\", \"ã‚»ãƒŸãƒŠãƒ¼\",\n",
    "        \"profile\", \"çµŒæ­´\", \"ç•¥æ­´\",\n",
    "        \"podcast\", \"YouTube\",\n",
    "    ]\n",
    "\n",
    "    # Site targets: add selectively (not mandatory, but helps diversify)\n",
    "    # Use domain-level site filters (not path-level).\n",
    "    sites = [\n",
    "        \"site:prtimes.jp\",\n",
    "        \"site:note.com\",\n",
    "        \"site:medium.com\",\n",
    "        \"site:youtube.com\",\n",
    "        \"site:podcasts.apple.com\",\n",
    "        \"site:spotify.com\",\n",
    "        \"site:nikkan.co.jp\",\n",
    "    ]\n",
    "\n",
    "    queries = []\n",
    "\n",
    "    # Generic high-signal queries (no site constraint)\n",
    "    queries += [\n",
    "        f\"{base}{company_clause}{role_clause} interview\",\n",
    "        f\"{base}{company_clause}{role_clause} ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼\",\n",
    "        f\"{base}{company_clause} ç™»å£‡\",\n",
    "        f\"{base}{company_clause} speaker\",\n",
    "        f\"{base}{company_clause} çµŒæ­´\",\n",
    "        f\"{base} çµŒæ­´\",\n",
    "    ]\n",
    "\n",
    "    # Site-targeted diversification (lightweight)\n",
    "    for s in sites:\n",
    "        queries.append(f\"{s} {base}{company_clause} ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼\")\n",
    "        queries.append(f\"{s} {base}{company_clause} ç™»å£‡\")\n",
    "        queries.append(f\"{s} {base}{company_clause} profile\")\n",
    "\n",
    "    # De-duplicate preserving order\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for q in queries:\n",
    "        q2 = \" \".join(q.split())\n",
    "        if q2 not in seen:\n",
    "            out.append(q2)\n",
    "            seen.add(q2)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "second_queries = build_multisite_second_wave_queries(ctx)\n",
    "\n",
    "display(Markdown(\"### 3.2 Second-wave retrieval (multi-site discovery)\"))\n",
    "display(Markdown(f\"Running **{len(second_queries)}** second-wave queries to broaden coverage.\"))\n",
    "\n",
    "qi_offset = len(base_queries)\n",
    "\n",
    "# Keep second wave relatively light\n",
    "SECOND_WAVE_TOP_K = 5\n",
    "SECOND_WAVE_PAGES = 1\n",
    "\n",
    "for j, q2 in enumerate(second_queries, start=1):\n",
    "    qi2 = qi_offset + j\n",
    "\n",
    "    for page in range(SECOND_WAVE_PAGES):\n",
    "        start = 1 + page * SECOND_WAVE_TOP_K\n",
    "        try:\n",
    "            items = cse_search(\n",
    "                q2,\n",
    "                GOOGLE_API_KEY,\n",
    "                GOOGLE_CSE_CX,\n",
    "                num=SECOND_WAVE_TOP_K,\n",
    "                start=start,\n",
    "            )\n",
    "            print(f\"[DEBUG] 2nd q='{q2}' start={start} items={len(items)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[CSE ERROR] 2nd q='{q2}' start={start} error={e}\")\n",
    "            continue\n",
    "\n",
    "        add_items_to_rows(items, qi=qi2, q=q2, start_rank=start, wave=\"second\")\n",
    "        time.sleep(SLEEP_SEC)\n",
    "\n",
    "        if len(rows) >= MAX_TOTAL_RESULTS:\n",
    "            break\n",
    "\n",
    "    if len(rows) >= MAX_TOTAL_RESULTS:\n",
    "        break\n",
    "\n",
    "\n",
    "search_results_df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3-7. Summary + preview\n",
    "# ----------------------------\n",
    "display(Markdown(\n",
    "    f\"#### Collected results: **{len(search_results_df)}** \"\n",
    "    f\"(deduped, max {MAX_PER_DOMAIN} per domain)\"\n",
    "))\n",
    "\n",
    "if not search_results_df.empty:\n",
    "    display(search_results_df[[\"wave\", \"query_idx\", \"rank_in_query\", \"domain\", \"title\", \"url\"]].head(30))\n",
    "else:\n",
    "    display(Markdown(\"âš ï¸ No results collected. Check CSE credentials and queries.\"))\n",
    "\n",
    "\n",
    "def render_search_results_preview(df: pd.DataFrame, max_items: int = 25):\n",
    "    display(Markdown(\"### ğŸ” Search Results Preview (Title / Snippet / URL)\"))\n",
    "    if df.empty:\n",
    "        display(Markdown(\"âš ï¸ No results to display.\"))\n",
    "        return\n",
    "\n",
    "    for k, (_, row) in enumerate(df.head(max_items).iterrows(), start=1):\n",
    "        title = row.get(\"title\") or \"(no title)\"\n",
    "        snippet = row.get(\"snippet\") or \"(no snippet)\"\n",
    "        url = row.get(\"url\") or \"\"\n",
    "        display(Markdown(f\"\"\"\n",
    "**{k}. {title}**\n",
    "\n",
    "{snippet}\n",
    "\n",
    "ğŸ”— {url}\n",
    "\n",
    "---\n",
    "\"\"\"))\n",
    "\n",
    "render_search_results_preview(search_results_df, max_items=25)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3-8. Accessor\n",
    "# ----------------------------\n",
    "def get_search_results_df() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns the CSE top results as a DataFrame.\n",
    "    \"\"\"\n",
    "    return search_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c33fc5f5-f5e3-41c3-bed8-95ace75eae10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 3.5 Fetch & Parse"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Fetching **15** URLs (top-15)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_idx</th>\n",
       "      <th>rank_in_query</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>creators.spotify.com</td>\n",
       "      <td>#1 æ—¥æœ¬æœ€å¼·ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é›†å›£ALGO ARTISã€‚æ¥µé™ã¾ã§è‡ªç”±ã«è€ƒãˆã‚‹çŸ¥ ...</td>\n",
       "      <td>https://creators.spotify.com/pod/profile/utec/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>jp.linkedin.com</td>\n",
       "      <td>Eureka Robotics | LinkedIn</td>\n",
       "      <td>https://jp.linkedin.com/company/eurekarobotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>scholar.google.es</td>\n",
       "      <td>â€ªJingyi Yangâ€¬ - â€ªGoogle Scholarâ€¬</td>\n",
       "      <td>https://scholar.google.es/citations?user=AEINg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>scholar.google.com</td>\n",
       "      <td>Shohei Fujii - Google Scholar</td>\n",
       "      <td>https://scholar.google.com/citations?user=fh3r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>instagram.com</td>\n",
       "      <td>NTU College of Engineering (@ntucoe) Â· Singapo...</td>\n",
       "      <td>https://www.instagram.com/ntucoe/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>ut-ec.co.jp</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>https://www.ut-ec.co.jp/admin/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>sg.linkedin.com</td>\n",
       "      <td>Eureka Robotics | LinkedIn</td>\n",
       "      <td>https://sg.linkedin.com/company/eurekarobotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ut-ec.co.jp</td>\n",
       "      <td>Eureka Robotics Pte. Ltd.ï½œæŠ•è³‡å…ˆä¼æ¥­ï½œUTEC-æ±äº¬å¤§å­¦ã‚¨ãƒƒã‚¸ ...</td>\n",
       "      <td>https://www.ut-ec.co.jp/our_companies/eureka-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>startupclass.co.jp</td>\n",
       "      <td>Eureka Roboticsæ ªå¼ä¼šç¤¾ã®è»¢è·ãƒ»æ±‚äººæƒ…å ± | ã‚¹ã‚¿ã‚¯ãƒ©</td>\n",
       "      <td>https://startupclass.co.jp/online/companies/1742/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>prtimes.jp</td>\n",
       "      <td>Eureka Roboticsã€ã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1,050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’ ...</td>\n",
       "      <td>https://prtimes.jp/main/html/rd/p/000000001.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_idx  rank_in_query                domain  \\\n",
       "0          1              1  creators.spotify.com   \n",
       "1          1              2       jp.linkedin.com   \n",
       "2          1              3     scholar.google.es   \n",
       "3          1              4    scholar.google.com   \n",
       "4          1              5         instagram.com   \n",
       "5          1              6           ut-ec.co.jp   \n",
       "6          2              1       sg.linkedin.com   \n",
       "7          2              2           ut-ec.co.jp   \n",
       "8          2              3    startupclass.co.jp   \n",
       "9          2              4            prtimes.jp   \n",
       "\n",
       "                                               title  \\\n",
       "0           #1 æ—¥æœ¬æœ€å¼·ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é›†å›£ALGO ARTISã€‚æ¥µé™ã¾ã§è‡ªç”±ã«è€ƒãˆã‚‹çŸ¥ ...   \n",
       "1                         Eureka Robotics | LinkedIn   \n",
       "2                   â€ªJingyi Yangâ€¬ - â€ªGoogle Scholarâ€¬   \n",
       "3                      Shohei Fujii - Google Scholar   \n",
       "4  NTU College of Engineering (@ntucoe) Â· Singapo...   \n",
       "5                                           Untitled   \n",
       "6                         Eureka Robotics | LinkedIn   \n",
       "7   Eureka Robotics Pte. Ltd.ï½œæŠ•è³‡å…ˆä¼æ¥­ï½œUTEC-æ±äº¬å¤§å­¦ã‚¨ãƒƒã‚¸ ...   \n",
       "8                 Eureka Roboticsæ ªå¼ä¼šç¤¾ã®è»¢è·ãƒ»æ±‚äººæƒ…å ± | ã‚¹ã‚¿ã‚¯ãƒ©   \n",
       "9       Eureka Roboticsã€ã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1,050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’ ...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://creators.spotify.com/pod/profile/utec/...  \n",
       "1     https://jp.linkedin.com/company/eurekarobotics  \n",
       "2  https://scholar.google.es/citations?user=AEINg...  \n",
       "3  https://scholar.google.com/citations?user=fh3r...  \n",
       "4                  https://www.instagram.com/ntucoe/  \n",
       "5  https://www.ut-ec.co.jp/admin/wp-content/uploa...  \n",
       "6     https://sg.linkedin.com/company/eurekarobotics  \n",
       "7  https://www.ut-ec.co.jp/our_companies/eureka-r...  \n",
       "8  https://startupclass.co.jp/online/companies/1742/  \n",
       "9  https://prtimes.jp/main/html/rd/p/000000001.00...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Fetched pages: **7** success / **15** total"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fetch_ok</th>\n",
       "      <th>fetch_reason</th>\n",
       "      <th>domain</th>\n",
       "      <th>encoding</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>ok</td>\n",
       "      <td>creators.spotify.com</td>\n",
       "      <td>utf-8</td>\n",
       "      <td>#1 æ—¥æœ¬æœ€å¼·ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é›†å›£ALGO ARTISã€‚æ¥µé™ã¾ã§è‡ªç”±ã«è€ƒãˆã‚‹çŸ¥ã®å®Ÿé¨“ã€ã‚²ã‚¹ãƒˆï¼šAL...</td>\n",
       "      <td>https://creators.spotify.com/pod/profile/utec/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>blocked_domain</td>\n",
       "      <td>jp.linkedin.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://jp.linkedin.com/company/eurekarobotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>robots_disallow</td>\n",
       "      <td>scholar.google.es</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://scholar.google.es/citations?user=AEINg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>robots_disallow</td>\n",
       "      <td>scholar.google.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://scholar.google.com/citations?user=fh3r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>blocked_domain</td>\n",
       "      <td>instagram.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.instagram.com/ntucoe/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>non_html_asset</td>\n",
       "      <td>ut-ec.co.jp</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.ut-ec.co.jp/admin/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>robots_disallow</td>\n",
       "      <td>sg.linkedin.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://sg.linkedin.com/company/eurekarobotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>ok</td>\n",
       "      <td>ut-ec.co.jp</td>\n",
       "      <td>utf-8</td>\n",
       "      <td>Eureka Robotics Pte. Ltd.ï½œæŠ•è³‡å…ˆä¼æ¥­ï½œUTEC-æ±äº¬å¤§å­¦ã‚¨ãƒƒã‚¸ã‚­ãƒ£...</td>\n",
       "      <td>https://www.ut-ec.co.jp/our_companies/eureka-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>ok</td>\n",
       "      <td>startupclass.co.jp</td>\n",
       "      <td>utf-8</td>\n",
       "      <td>Eureka Roboticsæ ªå¼ä¼šç¤¾ã®è»¢è·ãƒ»æ±‚äººæƒ…å ± | ã‚¹ã‚¿ã‚¯ãƒ©</td>\n",
       "      <td>https://startupclass.co.jp/online/companies/1742/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>ok</td>\n",
       "      <td>prtimes.jp</td>\n",
       "      <td>utf-8</td>\n",
       "      <td>Eureka Roboticsã€ã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1,050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’å®Ÿæ–½ | ã‚¨...</td>\n",
       "      <td>https://prtimes.jp/main/html/rd/p/000000001.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>blocked_domain</td>\n",
       "      <td>x.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://x.com/ThinkSpection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>non_html_asset</td>\n",
       "      <td>pdf.irpocket.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://pdf.irpocket.com/C7128/PEbr/A4ef/OHYp.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>ok</td>\n",
       "      <td>startup.aliyun.com</td>\n",
       "      <td>utf-8</td>\n",
       "      <td>çœ‹è§äºšæ´²ä¹‹æ˜Ÿï¼šEureka Roboticsè”åˆåˆ›å§‹äººå¯¹æœºå™¨äººç§‘æŠ€çš„5ä¸ªæ€è€ƒ</td>\n",
       "      <td>https://startup.aliyun.com/info/107582.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>ok</td>\n",
       "      <td>robotstart.info</td>\n",
       "      <td>utf-8</td>\n",
       "      <td>Eureka RoboticsãŒã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’å®Ÿæ–½ã€€ã‚·ãƒ³ã‚¬ãƒ...</td>\n",
       "      <td>https://robotstart.info/article/2024/12/13/365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>ok</td>\n",
       "      <td>alibabacloud.com</td>\n",
       "      <td>utf-8</td>\n",
       "      <td>Eureka Robotics Co-founder: 5 Thoughts on Robo...</td>\n",
       "      <td>https://www.alibabacloud.com/blog/eureka-robot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fetch_ok     fetch_reason                domain encoding  \\\n",
       "0       True               ok  creators.spotify.com    utf-8   \n",
       "1      False   blocked_domain       jp.linkedin.com            \n",
       "2      False  robots_disallow     scholar.google.es            \n",
       "3      False  robots_disallow    scholar.google.com            \n",
       "4      False   blocked_domain         instagram.com            \n",
       "5      False   non_html_asset           ut-ec.co.jp            \n",
       "6      False  robots_disallow       sg.linkedin.com            \n",
       "7       True               ok           ut-ec.co.jp    utf-8   \n",
       "8       True               ok    startupclass.co.jp    utf-8   \n",
       "9       True               ok            prtimes.jp    utf-8   \n",
       "10     False   blocked_domain                 x.com            \n",
       "11     False   non_html_asset      pdf.irpocket.com            \n",
       "12      True               ok    startup.aliyun.com    utf-8   \n",
       "13      True               ok       robotstart.info    utf-8   \n",
       "14      True               ok      alibabacloud.com    utf-8   \n",
       "\n",
       "                                                title  \\\n",
       "0   #1 æ—¥æœ¬æœ€å¼·ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é›†å›£ALGO ARTISã€‚æ¥µé™ã¾ã§è‡ªç”±ã«è€ƒãˆã‚‹çŸ¥ã®å®Ÿé¨“ã€ã‚²ã‚¹ãƒˆï¼šAL...   \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "5                                                       \n",
       "6                                                       \n",
       "7   Eureka Robotics Pte. Ltd.ï½œæŠ•è³‡å…ˆä¼æ¥­ï½œUTEC-æ±äº¬å¤§å­¦ã‚¨ãƒƒã‚¸ã‚­ãƒ£...   \n",
       "8                  Eureka Roboticsæ ªå¼ä¼šç¤¾ã®è»¢è·ãƒ»æ±‚äººæƒ…å ± | ã‚¹ã‚¿ã‚¯ãƒ©   \n",
       "9   Eureka Roboticsã€ã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1,050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’å®Ÿæ–½ | ã‚¨...   \n",
       "10                                                      \n",
       "11                                                      \n",
       "12             çœ‹è§äºšæ´²ä¹‹æ˜Ÿï¼šEureka Roboticsè”åˆåˆ›å§‹äººå¯¹æœºå™¨äººç§‘æŠ€çš„5ä¸ªæ€è€ƒ   \n",
       "13  Eureka RoboticsãŒã‚·ãƒªãƒ¼ã‚ºï¼¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§1050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’å®Ÿæ–½ã€€ã‚·ãƒ³ã‚¬ãƒ...   \n",
       "14  Eureka Robotics Co-founder: 5 Thoughts on Robo...   \n",
       "\n",
       "                                                  url  \n",
       "0   https://creators.spotify.com/pod/profile/utec/...  \n",
       "1      https://jp.linkedin.com/company/eurekarobotics  \n",
       "2   https://scholar.google.es/citations?user=AEINg...  \n",
       "3   https://scholar.google.com/citations?user=fh3r...  \n",
       "4                   https://www.instagram.com/ntucoe/  \n",
       "5   https://www.ut-ec.co.jp/admin/wp-content/uploa...  \n",
       "6      https://sg.linkedin.com/company/eurekarobotics  \n",
       "7   https://www.ut-ec.co.jp/our_companies/eureka-r...  \n",
       "8   https://startupclass.co.jp/online/companies/1742/  \n",
       "9   https://prtimes.jp/main/html/rd/p/000000001.00...  \n",
       "10                        https://x.com/ThinkSpection  \n",
       "11  https://pdf.irpocket.com/C7128/PEbr/A4ef/OHYp.pdf  \n",
       "12        https://startup.aliyun.com/info/107582.html  \n",
       "13  https://robotstart.info/article/2024/12/13/365...  \n",
       "14  https://www.alibabacloud.com/blog/eureka-robot...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Pages payload for LLM: **7** pages"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Showing the first payload item (truncated):"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://creators.spotify.com/pod/profile/utec/episodes/2-ALGO-ARTISALGO-ARTIS-e2l0qs7',\n",
       " 'domain': 'creators.spotify.com',\n",
       " 'title': '#1 æ—¥æœ¬æœ€å¼·ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é›†å›£ALGO ARTISã€‚æ¥µé™ã¾ã§è‡ªç”±ã«è€ƒãˆã‚‹çŸ¥ã®å®Ÿé¨“ã€ã‚²ã‚¹ãƒˆï¼šALGO ARTIS æ°¸ç”°å¥å¤ªéƒæ°ã€‘ by Tech Startupã®èˆå°è£',\n",
       " 'snippet': 'ã‚²ã‚¹ãƒˆçµŒæ­´ä¸­æ²¢å†¬èŠ½1998å¹´ç”Ÿã¾ã‚Œã€‚é•·é‡çœŒæ¾æœ¬å¸‚å‡ºèº«ã€‚ æ±äº¬å¤§å­¦æ³•å­¦éƒ¨åœ¨å­¦ä¸­ã« ... We are thrilled to have Dr. Pham Quang Cuong, CEO of Eureka Robotics, the\\xa0...',\n",
       " 'extracted_text': '#1 æ—¥æœ¬æœ€å¼·ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é›†å›£ALGO ARTISã€‚æ¥µé™ã¾ã§è‡ªç”±ã«è€ƒãˆã‚‹çŸ¥ã®å®Ÿé¨“ã€ã‚²ã‚¹ãƒˆï¼šALGO ARTIS æ°¸ç”°å¥å¤ªéƒæ°ã€‘\\næ±è¨¼ã‚°ãƒ­ãƒ¼ã‚¹å¸‚å ´ã®æ–°ã—ã„ä¸Šå ´ç¶­æŒåŸºæº–ã€Œ5å¹´ã§æ™‚ä¾¡ç·é¡100å„„å††ã€ã‚’èµ·ç‚¹ã«ã€IPOã®å‰æãŒã©ã†å¤‰ã‚ã‚‹ã®ã‹ã‚’UTECå†…ã§ã–ã£ãã°ã‚‰ã‚“ã«æ•´ç†ã€‚çŸ­æœŸã®ç—›ã¿ã¨ä¸­é•·æœŸã®æ„ç¾©ã€IPOæº–å‚™ã®â€œå…¥ã‚Šå£ã®é«˜ã•â€ã®å¤‰åŒ–ã€M&Aãƒ»ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ¼ã‚’å«ã‚€å‡ºå£ã®å¤šæ§˜åŒ–ã€ãã—ã¦VCã«æ±‚ã‚ã‚‰ã‚Œã‚‹ã‚±ã‚¤ãƒ‘ãƒ“ãƒªãƒ†ã‚£ã®å¤‰åŒ–ã¾ã§ã€å®Ÿå‹™ç›®ç·šã§èªã£ã¦ã¿ã¾ã™ã€‚\\nã€Œ5å¹´ã§100å„„ã€ã£ã¦ã€è¦ã¯ä½•ãŒå¤‰ã‚ã‚‹ï¼Ÿ\\nã€Œã‚¢ãƒ¡ãƒªã‚«ã¨æ¯”ã¹ã™ãå•é¡Œã€ã‚’ã©ã†è€ƒãˆã‚‹ã‹\\nâ€œã„ã„IPOâ€ã£ã¦ã€ç«‹å ´ã«ã‚ˆã£ã¦è¦‹ãˆæ–¹ãŒé•ã†ã‚ˆã­ã€ã¨ã„ã†è©±\\nä¸Šå ´å¾Œã«ä¼¸ã³ã¦ã„ã‚‹ä¼šç¤¾ã«å…±é€šã—ã¦ã„ã‚‹ã“ã¨\\nVCè‡ªèº«ã‚‚ã‚„ã‚Šæ–¹ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹å¿…è¦ã‚ã‚‹ï¼Ÿ\\nã‚¹ãƒ”ãƒ¼ãƒ€ https://initial.inc/articles/growth-market-post-ipo\\nJETRO https://www.jetro.go.jp/world/reports/2025/02/8d88f1c5f60ab2b1.html\\nâ˜…UTECã¸ã®æŠ•è³‡ãƒ»èµ·æ¥­ã®ã”ç›¸è«‡ã¯ã“ã¡ã‚‰\\nhttps://share.hsforms.com/1_WfJXAagSWmKnsxVxSalXQc3fla\\nâ˜…UTECæŠ•è³‡å…ˆå‚ç”»ã‚„ç ”ç©¶æ©Ÿé–¢ç™ºã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã‚¤ãƒ³ã‚­ãƒ¥ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æ”¯æ´ã«é–¢å¿ƒã®ã‚ã‚‹æ–¹å‘ã‘ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£SOCï¼ˆStartup Opportunity Clubï¼‰ã«ã¤ã„ã¦\\nhttps://www.ut-ec.co.jp/recruit/soc/\\nå‰µæ¥­å¾Œã‚ãšã‹æ•°å¹´ã§ã€å›½å†…å¤–ã®è£½é€ ç¾å ´ã«æ¬¡ã€…ã¨å°å…¥ã•ã‚Œã‚‹TriOrbã€‚ å±•ç¤ºä¼šã‚’ãã£ã‹ã‘ã«å‰å€’ã—ã§é€²ã‚ãŸè³‡é‡‘èª¿é”ã€100å°è¦æ¨¡ã‚’è¦‹æ®ãˆãŸã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ§‹ç¯‰ã€ç±³å›½ã§ã®æŒ‘æˆ¦ã¨æ¡ç”¨æˆ¦ç•¥ã‚’ã€å®Ÿè·µè¦–ç‚¹ã§æ˜ã‚Šä¸‹ã’ã¾ã™ã€‚ ä¸­å¿ƒãƒˆãƒ”ãƒƒã‚¯\\nå‰µæ¥­åˆæœŸã«ç›´é¢ã—ãŸã€Œç ”ç©¶è€…â†’çµŒå–¶è€…ã€ã¸ã®è»¢æ›\\n1å°è©•ä¾¡ã‹ã‚‰è¤‡æ•°å°å°å…¥ã¸åºƒãŒã‚‹ã‚¹ã‚±ãƒ¼ãƒ«æˆ¦ç•¥\\nç±³å›½å±•é–‹ã§å•ã‚ã‚ŒãŸâ€œè¦šæ‚Ÿâ€ã¨ç¾åœ°ã§ã®å®Ÿè£…ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\\nã‚·ãƒªãƒ¼ã‚ºBã«å‘ã‘ãŸæ¡ç”¨ãƒ»çµ„ç¹”æ‹¡å¤§ã¨æ¬¡ã®æˆé•·ãƒ†ãƒ¼ãƒ\\nã‚²ã‚¹ãƒˆï¼šTriOrbä»£è¡¨å–ç· å½¹CEO çŸ³ç”° ç§€ä¸€ ä¹å·å·¥æ¥­å¤§å­¦å¤§å­¦é™¢ç”Ÿå‘½ä½“å·¥å­¦ç ”ç©¶ç§‘åšå£«å¾ŒæœŸèª²ç¨‹ä¿®äº†ã€‚æ—¥æœ¬æœ€å¤§ç´šã®å…¬çš„ç ”ç©¶æ©Ÿé–¢ã§ã‚ã‚‹ç”£ç·ç ”ã§è£½é€ æ¥­å‘ã‘ã®ç”Ÿç”£ã‚·ã‚¹ãƒ†ãƒ /ãƒ—ãƒ­ã‚»ã‚¹è©•ä¾¡ã«é–¢ã™ã‚‹ç ”ç©¶ã«10å¹´å–ã‚Šçµ„ã‚€ã€‚è‡ªå¾‹ç§»å‹•ãƒ­ãƒœãƒƒãƒˆã®ä¸–ç•Œçš„ãªç«¶æŠ€ä¼šã§ã‚ã‚‹RoboCup Soccerã§ãƒãƒ¼ãƒ ä»£è¡¨ã¨ã—ã¦æ—¥æœ¬å¤§ä¼šå„ªå‹ã€ä¸–ç•Œå¤§ä¼šæŠ€è¡“éƒ¨é–€2ä½ã‚’å—è³ã€‚\\nhttps://triorb.co.jp/\\nhttps://newspicks.com/news/14017765/body/\\nâ˜…UTECã¸ã®æŠ•è³‡ãƒ»èµ·æ¥­ã®ã”ç›¸è«‡ã¯ã“ã¡ã‚‰\\nhttps://share.hsforms.com/1_WfJXAagSWmKnsxVxSalXQc3fla\\nâ˜…UTECæŠ•è³‡å…ˆå‚ç”»ã‚„ç ”ç©¶æ©Ÿé–¢ç™ºã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã‚¤ãƒ³ã‚­ãƒ¥ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æ”¯æ´ã«é–¢å¿ƒã®ã‚ã‚‹æ–¹å‘ã‘ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£SOCï¼ˆStartup Opportunity Clubï¼‰ã«ã¤ã„ã¦\\nhttps://www.ut-ec.co.jp/recruit/soc/\\nä»Šå›ã¯ã€ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ç®¡ç†éƒ¨çµŒé¨“ãŒè±Šå¯Œã§ã€ç¾åœ¨ã¯(æ ª)TYLåŸ·è¡Œå½¹å“¡ã®æœéƒ¨æ•°é¦¬ã•ã‚“ã‚’ã‚²ã‚¹ãƒˆã«ãŠè¿ãˆã—ã¦ã„ã¾ã™ã€‚ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ç®¡ç†éƒ¨ã®è£å´ã«ã¤ã„ã¦ã€ã“ã‚Œã‹ã‚‰æ¡ç”¨ã—ãŸã„çµŒå–¶è€…ã®æ–¹ã€ç®¡ç†éƒ¨ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’ç›®æŒ‡ã™æ–¹åŒæ–¹ãŒæ°—ã«ãªã‚‹æƒ…å ±ã‚’è‰²ã€…èã„ã¦ã¿ã¾ã—ãŸï¼\\nã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã®ç®¡ç†éƒ¨ã§å½¹ã«ç«‹ã£ãŸçµŒé¨“ã‚„ã‚¹ã‚­ãƒ«\\nå‘¨å›²ã®ç®¡ç†éƒ¨æ¥­å‹™ã¸ã®ç†è§£åº¦ãŒä½ã„ã“ã¨ã«ã‚ˆã‚Šç”Ÿã¾ã‚Œã‚‹ã€æœŸå¾…å€¤ã‚®ãƒ£ãƒƒãƒ—\\nâ€æ”»ã‚â€ã®ç®¡ç†ã¨â€å®ˆã‚Šâ€ã®ç®¡ç†ã£ã¦å…·ä½“çš„ã«ãªã«ï¼Ÿã©ã¡ã‚‰ã‹ã‚‰æ‰‹ã‚’ä»˜ã‘ã‚‹ã¹ãï¼Ÿ\\næ¥­å‹™å§”è¨—ã‚„å¤–æ³¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ´»ç”¨ã™ã¹ãã€ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚„æ¥­å‹™å†…å®¹\\nã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã®ç®¡ç†éƒ¨é•·ã«å‘ã„ã¦ã„ã‚‹ã®ã¯ã€ã€Œäººã«å¯¾ã—ã¦èˆˆå‘³ãŒã‚ã‚‹äººã€ã€Œã‚­ãƒ£ãƒªã‚¢ã®ä¸€è²«æ€§ãŒãªã„äººã€ï¼ï¼Ÿ\\nè‡ªåˆ†ã«åˆã†ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã®æ¢ã—æ–¹ã€é¢æ¥ã¸ã®è‡¨ã¿æ–¹\\nå…¬èªä¼šè¨ˆå£«ã€‚æ ªå¼ä¼šç¤¾TYL ç®¡ç†éƒ¨éƒ¨é•·ã€‚1983å¹´ç”Ÿã€‚2007å¹´å…¬èªä¼šè¨ˆå£«è©¦é¨“åˆæ ¼ã€æœ‰é™è²¬ä»»ç›£æŸ»æ³•äººãƒˆãƒ¼ãƒãƒ„å…¥ç¤¾ã€‚ä¸Šå ´ä¼æ¥­ã€ä¸Šå ´æº–å‚™ä¼æ¥­ã€SPCã€å­¦æ ¡æ³•äººç­‰ã€ç›£æŸ»æ¥­å‹™ã«å¾“äº‹ã€‚2012å¹´ NPOæ³•äººvery50ï¼ˆç¾/ èªå®šNPOæ³•äººvery50) å‰¯ä»£è¡¨ / ç†äº‹ã¨ã—ã¦è¨­ç«‹ã«å‚ç”»ã€‚1å¹´ã®ã†ã¡ã€3-4ãƒ¶æœˆé–“ã‚’ã‚¢ã‚¸ã‚¢å„å›½ã«ã¦æ¥­å‹™ã«å¾“äº‹ã€‚2014å¹´ãˆ±FiNCã«ãƒ“ã‚¸ãƒã‚¹ã‚µã‚¤ãƒ‰2äººç›®ã®ç¤¾å“¡ã¨ã—ã¦ã€æ–°è¦äº‹æ¥­é–‹ç™ºã€äººäº‹æ¡ç”¨ã€ç®¡ç†éƒ¨é–€ç«‹ã¡ä¸Šã’ã€è³‡é‡‘èª¿é”ã«å¾“äº‹ã€‚2016å¹´ ãˆ±ãƒ•ãƒ¼ãƒ‡ã‚£ã‚½ãƒ³å…¥ç¤¾ã€‚å‚µæ¨©å›åã€è³‡é‡‘èª¿é”ã€ç®¡ç†æ¥­å‹™ã«å¾“äº‹ã€‚2018å¹´ãˆ±VAZå…¥ç¤¾ã€å–ç· å½¹CFOã¨ã—ã¦ä¸Šå ´æº–å‚™ã€è³‡é‡‘èª¿é”ã€å†…éƒ¨ç®¡ç†ä½“åˆ¶æ§‹ç¯‰ã€è¨´è¨Ÿç´›äº‰ã€çµ„ç¹”æ”¹é©ã€ãƒªã‚¹ãƒˆãƒ©ã€Mï¼†Aã«å¾“äº‹ã€‚2020å¹´10æœˆã«æˆç«‹ã—ãŸMï¼†Aã§ã¯ã€6ãƒ¶æœˆé–“ã«åŠã¶æ ªä¸»äº¤æ¸‰ã‚’å§‹ã‚ã¨ã—ã¦ã€çµŒå–¶æ¨©ã®äº¤ä»£ã‚’ãƒªãƒ¼ãƒ‰ã€‚çµŒå–¶æ¨©äº¤ä»£å¾Œã€ç¶šæŠ•ã™ã‚‹å”¯ä¸€ã®å½¹å“¡ã¨ã—ã¦ã€çµŒå–¶å†å»ºã€PMIã«å¾“äº‹ã—ã€ä¸Šå ´ä¼æ¥­ã®å­ä¼šç¤¾åŒ–ã‚’æ©Ÿã«å½¹å“¡é€€ä»»ã€‚2022å¹´ãˆ±TYLå…¥ç¤¾ã€åŸ·è¡Œå½¹å“¡ ç®¡ç†é ˜åŸŸé•· å…¼ è²¡å‹™éƒ¨é•· ã¨ã—ã¦ç®¡ç†éƒ¨é–€çµ±æ‹¬ã€çµŒå–¶ç®¡ç†/è²¡å‹™ç®¡ç†ã€ä¸Šå ´æº–å‚™æ¥­å‹™ã«å¾“äº‹ã€‚\\nTYL Websiteï¼š https://pet-tyl.co.jp/\\næœéƒ¨ã•ã‚“X: https://x.com/HatKaz1983\\nâ˜…UTECã¸ã®æŠ•è³‡ãƒ»èµ·æ¥­ã®ã”ç›¸è«‡ã¯ã“ã¡ã‚‰\\nhttps://share.hsforms.com/1_WfJXAagSWmKnsxVxSalXQc3fla\\nâ˜…UTECæŠ•è³‡å…ˆå‚ç”»ã‚„ç ”ç©¶æ©Ÿé–¢ç™ºã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã‚¤ãƒ³ã‚­ãƒ¥ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æ”¯æ´ã«é–¢å¿ƒã®ã‚ã‚‹æ–¹å‘ã‘ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£SOCï¼ˆStartup Opportunity Clubï¼‰ã«ã¤ã„ã¦\\nhttps://www.ut-ec.co.jp/recruit/soc/\\nè£½é€ ç¾å ´ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã¨ä½œæ¥­è¨­è¨ˆã‚’ã€\"ãƒ©ã‚¤ãƒ³è‡ªä½“ãŒå‹•ã\"ã¨ã„ã†ç™ºæƒ³ã‹ã‚‰å†å®šç¾©ã™ã‚‹TriOrbã€‚\\nçƒä½“é§†å‹•ï¼ˆå…¨æ–¹å‘ç§»å‹•æ©Ÿæ§‹ï¼‰ã‚’1tç´šã§æˆç«‹ã•ã›ãŸèƒŒæ™¯ã€å­¦è¡“ã‹ã‚‰ç”£æ¥­å¿œç”¨ã¸ã®è»¢æ›ã€è€ä¹…ãƒ»å®‰å…¨ãƒ»é‡ç”£æ€§ã‚’ä¸¡ç«‹ã•ã›ãŸè¨­è¨ˆæ€æƒ³ã‚’ã€çŸ³ç”°CEOã¨UTECã®è¦–ç‚¹ã§æŒ¯ã‚Šè¿”ã‚Šã¾ã™ã€‚\\nå…¨æ–¹å‘ç§»å‹•æ©Ÿæ§‹ã®ç”£æ¥­å®Ÿè£…ã«ç«‹ã¡ã¯ã ã‹ã£ãŸèª²é¡Œã¨çªç ´å£\\nçƒä½“é§†å‹•ã®ãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã¨300kgâ†’1tã¸ã®é€²åŒ–\\nRoboCupã§åŸ¹ã£ãŸåˆ¶å¾¡æŠ€è¡“ã¨æ—¥æœ¬çš„ã€Œç²¾ç·»ãªå‹•ãã€ã®å¼·ã¿\\nç ”ç©¶ã‹ã‚‰äº‹æ¥­åŒ–ã¸ï¼šä¹å·¥å¤§ãƒ»ç”£ç·ç ”ãƒ»JSTãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®è»Œè·¡\\nã‚²ã‚¹ãƒˆï¼šTriOrbä»£è¡¨å–ç· å½¹CEO çŸ³ç”° ç§€ä¸€ ä¹å·å·¥æ¥­å¤§å­¦å¤§å­¦é™¢ç”Ÿå‘½ä½“å·¥å­¦ç ”ç©¶ç§‘åšå£«å¾ŒæœŸèª²ç¨‹ä¿®äº†ã€‚æ—¥æœ¬æœ€å¤§ç´šã®å…¬çš„ç ”ç©¶æ©Ÿé–¢ã§ã‚ã‚‹ç”£ç·ç ”ã§è£½é€ æ¥­å‘ã‘ã®ç”Ÿç”£ã‚·ã‚¹ãƒ†ãƒ /ãƒ—ãƒ­ã‚»ã‚¹è©•ä¾¡ã«é–¢ã™ã‚‹ç ”ç©¶ã«10å¹´å–ã‚Šçµ„ã‚€ã€‚è‡ªå¾‹ç§»å‹•ãƒ­ãƒœãƒƒãƒˆã®ä¸–ç•Œçš„ãªç«¶æŠ€ä¼šã§ã‚ã‚‹RoboCup Soccerã§ãƒãƒ¼ãƒ ä»£è¡¨ã¨ã—ã¦æ—¥æœ¬å¤§ä¼šå„ªå‹ã€ä¸–ç•Œå¤§ä¼šæŠ€è¡“éƒ¨é–€2ä½ã‚’å—è³ã€‚\\nhttps://triorb.co.jp/\\nâ˜…UTECã¸ã®æŠ•è³‡ãƒ»èµ·æ¥­ã®ã”ç›¸è«‡ã¯ã“ã¡ã‚‰\\nhttps://share.hsforms.com/1_WfJXAagSWmKnsxVxSalXQc3fla\\nâ˜…UTECæŠ•è³‡å…ˆå‚ç”»ã‚„ç ”ç©¶æ©Ÿé–¢ç™ºã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã‚¤ãƒ³ã‚­ãƒ¥ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æ”¯æ´ã«é–¢å¿ƒã®ã‚ã‚‹æ–¹å‘ã‘ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£SOCï¼ˆStartup Opportunity Clubï¼‰ã«ã¤ã„ã¦\\nhttps://www.ut-ec.co.jp/recruit/soc/\\nå‰åŠã«ç¶šãã€AL\\n...[truncated]'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3.5 Fetch & Parse (Lightweight Crawler for Crawl-friendly Sites)\n",
    "# ============================================================\n",
    "# Purpose:\n",
    "# Convert a subset of CSE results (URL list) into richer evidence by fetching\n",
    "# the page HTML and extracting main text (no heavy crawling).\n",
    "#\n",
    "# Philosophy:\n",
    "# - Only fetch a small number of URLs (top-N) to control time/cost.\n",
    "# - Avoid sites that are usually login-walled / anti-bot (LinkedIn, X, Facebook).\n",
    "# - Be polite: robots.txt check + rate limiting + clear User-Agent.\n",
    "#\n",
    "# Input:\n",
    "# - search_results_df from Section 3\n",
    "#\n",
    "# Output:\n",
    "# - pages_df: table with fetched text per URL (url, domain, title, extracted_text, status, etc.)\n",
    "# - pages_payload: compact list for LLM (url, title, snippet, extracted_text excerpt)\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3.5-1. Config\n",
    "# ----------------------------\n",
    "FETCH_TOP_N = 15              # how many URLs to fetch (top rows of search_results_df)\n",
    "MAX_TEXT_CHARS = 6000         # cap extracted text per page (for LLM payload)\n",
    "TIMEOUT_SEC = 20\n",
    "SLEEP_BETWEEN_REQ_SEC = 0.8   # be polite\n",
    "USER_AGENT = \"researchOSv2/1.0 (contact: you@example.com)\"  # customize if you want\n",
    "\n",
    "\n",
    "# Blocklist: high-friction / login-walled / unstable for text extraction\n",
    "BLOCKLIST_DOMAINS = {\n",
    "    \"linkedin.com\", \"jp.linkedin.com\",\n",
    "    \"facebook.com\", \"m.facebook.com\",\n",
    "    \"x.com\", \"twitter.com\",\n",
    "    \"instagram.com\",\n",
    "}\n",
    "\n",
    "# Optionally: if you want strict allowlist mode, set ALLOWLIST_DOMAINS to a non-empty set.\n",
    "# Example:\n",
    "# ALLOWLIST_DOMAINS = {\"prtimes.jp\", \"yourcompany.com\", \"nikkan.co.jp\"}\n",
    "ALLOWLIST_DOMAINS = set()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3.5-2. Helpers\n",
    "# ----------------------------\n",
    "def decode_html_response(r: requests.Response) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Decode HTML response bytes into text with best-effort encoding detection.\n",
    "    Returns: (decoded_text, encoding_used)\n",
    "    \"\"\"\n",
    "    raw = r.content or b\"\"\n",
    "    ct = (r.headers.get(\"Content-Type\") or \"\").lower()\n",
    "\n",
    "    # 1) Content-Type charset\n",
    "    enc = None\n",
    "    m = re.search(r\"charset=([a-z0-9\\-\\_]+)\", ct)\n",
    "    if m:\n",
    "        enc = m.group(1).strip()\n",
    "\n",
    "    # 2) requests guess\n",
    "    if not enc:\n",
    "        try:\n",
    "            enc = r.apparent_encoding  # uses chardet/charset-normalizer underneath\n",
    "        except Exception:\n",
    "            enc = None\n",
    "\n",
    "    # 3) Try decode with candidates\n",
    "    candidates = []\n",
    "    if enc:\n",
    "        candidates.append(enc)\n",
    "    candidates += [\"utf-8\", \"cp932\", \"shift_jis\", \"euc-jp\"]\n",
    "\n",
    "    last_err = None\n",
    "    for e in candidates:\n",
    "        try:\n",
    "            text = raw.decode(e, errors=\"replace\")\n",
    "            return text, e\n",
    "        except Exception as ex:\n",
    "            last_err = ex\n",
    "            continue\n",
    "\n",
    "    # Final fallback (should rarely happen)\n",
    "    return raw.decode(\"utf-8\", errors=\"replace\"), \"utf-8(fallback)\"\n",
    "\n",
    "\n",
    "def normalize_domain(d: str) -> str:\n",
    "    return (d or \"\").lower().replace(\"www.\", \"\").strip()\n",
    "\n",
    "\n",
    "def domain_of(url: str) -> str:\n",
    "    try:\n",
    "        return normalize_domain(urlparse(url).netloc)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def should_fetch_url(url: str) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Decide whether to fetch a URL.\n",
    "    Returns: (bool, reason)\n",
    "    \"\"\"\n",
    "    dom = domain_of(url)\n",
    "\n",
    "    if not url or not dom:\n",
    "        return False, \"missing_url_or_domain\"\n",
    "\n",
    "    if dom in BLOCKLIST_DOMAINS:\n",
    "        return False, \"blocked_domain\"\n",
    "\n",
    "    if ALLOWLIST_DOMAINS and dom not in ALLOWLIST_DOMAINS:\n",
    "        return False, \"not_in_allowlist\"\n",
    "\n",
    "    # Skip obvious non-HTML endpoints (optional)\n",
    "    lower = url.lower()\n",
    "    if any(lower.endswith(ext) for ext in [\".pdf\", \".jpg\", \".jpeg\", \".png\", \".gif\", \".zip\"]):\n",
    "        return False, \"non_html_asset\"\n",
    "\n",
    "    return True, \"ok\"\n",
    "\n",
    "\n",
    "def robots_allows(url: str, user_agent: str = USER_AGENT) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Lightweight robots.txt check using urllib.robotparser.\n",
    "    If robots cannot be fetched/parsed, we default to allow (soft-fail) but record reason.\n",
    "    \"\"\"\n",
    "    import urllib.robotparser as robotparser\n",
    "\n",
    "    try:\n",
    "        p = urlparse(url)\n",
    "        robots_url = urljoin(f\"{p.scheme}://{p.netloc}\", \"/robots.txt\")\n",
    "        rp = robotparser.RobotFileParser()\n",
    "        rp.set_url(robots_url)\n",
    "        rp.read()\n",
    "        allowed = rp.can_fetch(user_agent, url)\n",
    "        return allowed, \"robots_ok\" if allowed else \"robots_disallow\"\n",
    "    except Exception as e:\n",
    "        return True, f\"robots_check_failed:{type(e).__name__}\"\n",
    "\n",
    "\n",
    "def extract_visible_text_simple(html: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract readable-ish text from HTML without heavy dependencies.\n",
    "    Strategy:\n",
    "      - remove script/style/noscript/svg\n",
    "      - prefer <article> or <main> if available\n",
    "      - else collect <p>, <li>, <h1-3> text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from bs4 import BeautifulSoup\n",
    "    except ImportError:\n",
    "        # Fallback: strip tags crudely (less ideal)\n",
    "        text = re.sub(r\"<[^>]+>\", \" \", html)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        return text\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # drop noisy nodes\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\", \"svg\", \"header\", \"footer\", \"nav\", \"form\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    # prefer main/article\n",
    "    main = soup.find(\"article\") or soup.find(\"main\")\n",
    "    scope = main if main else soup.body if soup.body else soup\n",
    "\n",
    "    parts = []\n",
    "    for el in scope.find_all([\"h1\", \"h2\", \"h3\", \"p\", \"li\"]):\n",
    "        t = el.get_text(\" \", strip=True)\n",
    "        if t and len(t) >= 20:\n",
    "            parts.append(t)\n",
    "\n",
    "    text = \"\\n\".join(parts)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def truncate_text(text: str, max_chars: int) -> str:\n",
    "    t = (text or \"\").strip()\n",
    "    if len(t) <= max_chars:\n",
    "        return t\n",
    "    return t[:max_chars].rstrip() + \"\\n...[truncated]\"\n",
    "\n",
    "\n",
    "def fetch_one(url: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch a single URL and extract text.\n",
    "    Returns a row dict with status and extracted text.\n",
    "    \"\"\"\n",
    "    ok, reason = should_fetch_url(url)\n",
    "    if not ok:\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"domain\": domain_of(url),\n",
    "            \"fetch_ok\": False,\n",
    "            \"fetch_reason\": reason,\n",
    "            \"http_status\": None,\n",
    "            \"content_type\": None,\n",
    "            \"encoding\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"extracted_text\": \"\",\n",
    "        }\n",
    "\n",
    "    allow, robots_reason = robots_allows(url)\n",
    "    if not allow:\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"domain\": domain_of(url),\n",
    "            \"fetch_ok\": False,\n",
    "            \"fetch_reason\": robots_reason,\n",
    "            \"http_status\": None,\n",
    "            \"content_type\": None,\n",
    "            \"encoding\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"extracted_text\": \"\",\n",
    "        }\n",
    "\n",
    "    headers = {\"User-Agent\": USER_AGENT, \"Accept\": \"text/html,application/xhtml+xml\"}\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=TIMEOUT_SEC)\n",
    "        ct = (r.headers.get(\"Content-Type\") or \"\").lower()\n",
    "        status = r.status_code\n",
    "\n",
    "        if status >= 400:\n",
    "            return {\n",
    "                \"url\": url,\n",
    "                \"domain\": domain_of(url),\n",
    "                \"fetch_ok\": False,\n",
    "                \"fetch_reason\": f\"http_{status}\",\n",
    "                \"http_status\": status,\n",
    "                \"content_type\": ct,\n",
    "                \"encoding\": \"\",\n",
    "                \"title\": \"\",\n",
    "                \"extracted_text\": \"\",\n",
    "            }\n",
    "\n",
    "        # Only parse HTML-ish\n",
    "        if \"text/html\" not in ct and \"application/xhtml+xml\" not in ct and ct:\n",
    "            return {\n",
    "                \"url\": url,\n",
    "                \"domain\": domain_of(url),\n",
    "                \"fetch_ok\": False,\n",
    "                \"fetch_reason\": \"non_html_content_type\",\n",
    "                \"http_status\": status,\n",
    "                \"content_type\": ct,\n",
    "                \"encoding\": \"\",\n",
    "                \"title\": \"\",\n",
    "                \"extracted_text\": \"\",\n",
    "            }\n",
    "\n",
    "        html_text, enc_used = decode_html_response(r)\n",
    "\n",
    "        extracted = extract_visible_text_simple(html_text)\n",
    "        extracted = truncate_text(extracted, MAX_TEXT_CHARS)\n",
    "\n",
    "        # title (best-effort)\n",
    "        title = \"\"\n",
    "        try:\n",
    "            from bs4 import BeautifulSoup\n",
    "            soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "            title = (soup.title.get_text(strip=True) if soup.title else \"\")[:200]\n",
    "        except Exception:\n",
    "            title = \"\"\n",
    "\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"domain\": domain_of(url),\n",
    "            \"fetch_ok\": True,\n",
    "            \"fetch_reason\": \"ok\",\n",
    "            \"http_status\": status,\n",
    "            \"content_type\": ct,\n",
    "            \"encoding\": enc_used,\n",
    "            \"title\": title,\n",
    "            \"extracted_text\": extracted,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"domain\": domain_of(url),\n",
    "            \"fetch_ok\": False,\n",
    "            \"fetch_reason\": f\"exception:{type(e).__name__}\",\n",
    "            \"http_status\": None,\n",
    "            \"content_type\": None,\n",
    "            \"encoding\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"extracted_text\": \"\",\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3.5-3. Run fetch on top-N CSE results\n",
    "# ----------------------------\n",
    "search_results_df = get_search_results_df()\n",
    "\n",
    "display(Markdown(\"### 3.5 Fetch & Parse\"))\n",
    "if search_results_df.empty:\n",
    "    raise ValueError(\"search_results_df is empty. Run Section 3 first.\")\n",
    "\n",
    "# Select top-N URLs (you can change ordering if you want)\n",
    "to_fetch_df = search_results_df.dropna(subset=[\"url\"]).head(FETCH_TOP_N).copy()\n",
    "\n",
    "display(Markdown(f\"Fetching **{len(to_fetch_df)}** URLs (top-{FETCH_TOP_N}).\"))\n",
    "display(to_fetch_df[[\"query_idx\", \"rank_in_query\", \"domain\", \"title\", \"url\"]].head(10))\n",
    "\n",
    "fetched_rows = []\n",
    "for i, row in to_fetch_df.iterrows():\n",
    "    url = row[\"url\"]\n",
    "    out = fetch_one(url)\n",
    "\n",
    "    # Carry snippet/title from CSE for context\n",
    "    out[\"cse_title\"] = row.get(\"title\", \"\")\n",
    "    out[\"cse_snippet\"] = row.get(\"snippet\", \"\")\n",
    "    out[\"query_idx\"] = row.get(\"query_idx\", None)\n",
    "    out[\"rank_in_query\"] = row.get(\"rank_in_query\", None)\n",
    "\n",
    "    fetched_rows.append(out)\n",
    "    time.sleep(SLEEP_BETWEEN_REQ_SEC)\n",
    "\n",
    "pages_df = pd.DataFrame(fetched_rows)\n",
    "\n",
    "display(Markdown(\n",
    "    f\"#### Fetched pages: **{pages_df['fetch_ok'].sum()}** success / **{len(pages_df)}** total\"\n",
    "))\n",
    "display(pages_df[[\"fetch_ok\", \"fetch_reason\", \"domain\", \"encoding\", \"title\", \"url\"]].head(20))\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3.5-4. Build payload for LLM (snippet + extracted text)\n",
    "# ----------------------------\n",
    "def build_pages_payload(pages_df: pd.DataFrame, max_pages: int = 10, max_text_chars: int = 3000) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Build a compact payload for the LLM using:\n",
    "    - url\n",
    "    - CSE title/snippet\n",
    "    - extracted_text (truncated)\n",
    "    \"\"\"\n",
    "    df = pages_df.copy()\n",
    "    df = df[df[\"fetch_ok\"] == True].copy()\n",
    "\n",
    "    # Optional: prioritize longer extracted text (more content)\n",
    "    df[\"text_len\"] = df[\"extracted_text\"].fillna(\"\").map(len)\n",
    "    df = df.sort_values([\"text_len\"], ascending=False).head(max_pages)\n",
    "\n",
    "    payload = []\n",
    "    for _, r in df.iterrows():\n",
    "        payload.append({\n",
    "            \"url\": r[\"url\"],\n",
    "            \"domain\": r[\"domain\"],\n",
    "            \"title\": (r[\"title\"] or r.get(\"cse_title\") or \"\")[:250],\n",
    "            \"snippet\": (r.get(\"cse_snippet\") or \"\")[:800],\n",
    "            \"extracted_text\": truncate_text(r.get(\"extracted_text\") or \"\", max_text_chars),\n",
    "        })\n",
    "    return payload\n",
    "\n",
    "\n",
    "pages_payload = build_pages_payload(pages_df, max_pages=10, max_text_chars=3000)\n",
    "\n",
    "display(Markdown(f\"#### Pages payload for LLM: **{len(pages_payload)}** pages\"))\n",
    "if pages_payload:\n",
    "    display(Markdown(\"Showing the first payload item (truncated):\"))\n",
    "    display(pages_payload[0])\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3.5-5. Accessors\n",
    "# ----------------------------\n",
    "def get_pages_df() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns fetched pages and extracted text.\n",
    "    \"\"\"\n",
    "    return pages_df\n",
    "\n",
    "def get_pages_payload() -> list[dict]:\n",
    "    \"\"\"\n",
    "    Returns compact payload to enrich LLM input (snippet + extracted text).\n",
    "    \"\"\"\n",
    "    return pages_payload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c81d63a6-35ae-4df2-a608-ed70c69d6399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 4. LLM Synthesis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Using **7** fetched pages (snippet + extracted text)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### LLM output preview"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"profile_summary\": {\\n    \"current_role\": \"CEO\",\\n    \"background_overview\": \"ãƒ•ã‚¡ãƒ ãƒ»ã‚¯ã‚¢ãƒ³ãƒ»ã‚¯ã‚ªãƒ³æ°ã¯ã€ã‚·ãƒ³ã‚¬ãƒãƒ¼ãƒ«å—æ´‹ç†å·¥å¤§å­¦ï¼ˆNTUï¼‰ã§ç¥çµŒç§‘å­¦ã¨ãƒ­ãƒœãƒƒãƒˆå·¥å­¦ã®åšå£«å·ã‚’å–å¾—ã—ã€2018å¹´ã«Eureka Roboticsã‚’å…±åŒå‰µæ¥­ã—ã¾ã—ãŸã€‚\"\\n  },\\n  \"career_highlights\": [\\n    {\\n      \"point\": \"Eureka Roboticsã¯ã‚·ãƒªãƒ¼ã‚ºAãƒ©ã‚¦ãƒ³ãƒ‰ã§1,050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚\",\\n      \"sources\": [\\n        \"https://prtimes.jp/main/html/rd/p/000000001.000153512.html\",\\n        \"https://robotstart.info/article/2024/12/13/365453.html\"\\n      ]\\n    },\\n    {\\n      \"point\": \"Eureka Roboticsã¯ã€ä¸»ã«è£½é€ æ¥­å‘ã‘ã«é«˜ç²¾åº¦ãªãƒ­ãƒœãƒƒãƒˆåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚\",\\n      \"sources\": [\\n        \"https://ut-ec.co.jp/our_companies/eureka-robotics/\"\\n      ]\\n    }\\n  ],\\n  \"public_themes\": [\\n    {\\n      \"theme\": \"è£½é€ æ¥­ã«ãŠã‘ã‚‹ãƒ­ãƒœãƒƒã‚¯ã‚¹ã®è‡ªå‹•åŒ–\",\\n      \"evidence\": [\\n        \"https://robotstart.info/article/2024/12/13/365453.html\"\\n      ]\\n    }\\n  ],\\n  \"hypotheses\": [\\n    {\\n      \"hypothesis\": \"ãƒ•ã‚¡ãƒ ãƒ»ã‚¯ã‚¢ãƒ³ãƒ»ã‚¯ã‚ªãƒ³æ°ã¯ã€å°†æ¥çš„ã«Eureka Roboticsã‚’ã•ã‚‰ã«æˆé•·ã•ã›ã‚‹ãŸã‚ã«ã€æŠ€è¡“é©æ–°ã«æ³¨åŠ›ã™ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚\",\\n      \"rationale\": \"è³‡é‡‘èª¿é”ã«ã‚ˆã‚Šæ–°æŠ€è¡“ã®é–‹ç™ºã¨å¸‚å ´å‚å…¥ã‚’åŠ é€Ÿã™ã‚‹ãŸã‚ã€‚\",\\n      \"sources\": [\\n        \"https://prtimes.jp/main/html/rd/p/000000001.000153512.html\"\\n      ],\\n      \"confidence\": 0.8\\n    }\\n  ],\\n  \"talking_points\": [\\n    {\\n      \"question\": \"ä»Šå¾Œã®Eureka Roboticsã®æŠ€è¡“é©æ–°ã®æ–¹å‘æ€§ã¯ï¼Ÿ\",\\n      \"intent\": \"Eureka Roboticsã®å°†æ¥æ€§ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’å¾—ã‚‹ãŸã‚ã€‚\",\\n      \"related_hypothesis\": \"ãƒ•ã‚¡ãƒ ãƒ»ã‚¯ã‚¢ãƒ³ãƒ»ã‚¯ã‚ªãƒ³æ°ã¯ã€å°†æ¥çš„ã«Eureka Roboticsã‚’ã•ã‚‰ã«æˆé•·ã•ã›ã‚‹ãŸã‚ã«ã€æŠ€è¡“é©æ–°ã«æ³¨åŠ›ã™ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚\"\\n    }\\n  ],\\n  \"information_gaps\": [\\n    \"ãƒ•ã‚¡ãƒ ãƒ»ã‚¯ã‚¢ãƒ³ãƒ»ã‚¯ã‚ªãƒ³æ°ã®å…·ä½“çš„ãªçµŒæ­´ã‚„ãã®ä»–ã®å®Ÿç¸¾ã«ã¤ã„ã¦ã®è©³ç´°æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚\"\\n  ]\\n}'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. Pass Results to LLM (pages_payload-first)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4-2. Load inputs\n",
    "# ----------------------------\n",
    "ctx = get_input_context()\n",
    "search_results_df = get_search_results_df()\n",
    "\n",
    "display(Markdown(\"### 4. LLM Synthesis\"))\n",
    "\n",
    "if pages_payload and len(pages_payload) > 0:\n",
    "    display(Markdown(f\"Using **{len(pages_payload)}** fetched pages (snippet + extracted text).\"))\n",
    "else:\n",
    "    display(Markdown(\n",
    "        f\"No fetched-page payload found. Falling back to **{len(search_results_df)}** search results (title/snippet only).\"\n",
    "    ))\n",
    "\n",
    "if (not pages_payload or len(pages_payload) == 0) and search_results_df.empty:\n",
    "    raise ValueError(\"No evidence available. Run Section 3 (and optionally 3.5) first.\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4-3. Prepare payload for LLM\n",
    "# ----------------------------\n",
    "def build_llm_payload_from_search_results(df, max_items: int = 25):\n",
    "    \"\"\"\n",
    "    Fallback payload: title/snippet/url only.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    if df is None or df.empty:\n",
    "        return out\n",
    "\n",
    "    for _, row in df.head(max_items).iterrows():\n",
    "        out.append({\n",
    "            \"url\": row.get(\"url\", \"\"),\n",
    "            \"domain\": row.get(\"domain\", \"\"),\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"snippet\": row.get(\"snippet\", \"\"),\n",
    "            \"query_idx\": int(row.get(\"query_idx\", 0)) if str(row.get(\"query_idx\", \"\")).isdigit() else None,\n",
    "            \"rank_in_query\": int(row.get(\"rank_in_query\", 0)) if str(row.get(\"rank_in_query\", \"\")).isdigit() else None,\n",
    "            \"extracted_text\": \"\",  # none in fallback\n",
    "        })\n",
    "    return out\n",
    "\n",
    "\n",
    "# Preferred: pages_payload already has extracted_text\n",
    "if pages_payload and len(pages_payload) > 0:\n",
    "    llm_payload = pages_payload\n",
    "else:\n",
    "    llm_payload = build_llm_payload_from_search_results(search_results_df, max_items=25)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4-4. Prompt construction\n",
    "# ----------------------------\n",
    "def normalize_lang(lang: str) -> str:\n",
    "    l = (lang or \"\").strip().lower()\n",
    "    if l in [\"ja\", \"jp\", \"japanese\", \"æ—¥æœ¬èª\"]:\n",
    "        return \"ja\"\n",
    "    if l in [\"en\", \"english\", \"è‹±èª\"]:\n",
    "        return \"en\"\n",
    "    return \"ja\"  # default\n",
    "\n",
    "\n",
    "def build_llm_prompt(ctx, llm_payload):\n",
    "    lang = normalize_lang(getattr(ctx, \"language_preference\", \"ja\"))\n",
    "\n",
    "    output_language_instruction = (\n",
    "        \"Write ALL human-readable text values in Japanese.\"\n",
    "        if lang == \"ja\"\n",
    "        else \"Write ALL human-readable text values in English.\"\n",
    "    )\n",
    "\n",
    "    # Also enforce that JSON keys remain in English (structure fixed)\n",
    "    structure_instruction = (\n",
    "        \"Keep the JSON keys exactly as specified (English keys). \"\n",
    "        \"Only the string VALUES should follow the output language rule.\"\n",
    "    )\n",
    "\n",
    "    return f\"\"\"\n",
    "You are assisting with preparation for an initial business meeting.\n",
    "\n",
    "Target person:\n",
    "- Name: {ctx.person_name}\n",
    "- Company: {ctx.company_name}\n",
    "- Role hint (if any): {ctx.role_hint or \"(not provided)\"}\n",
    "\n",
    "Meeting context:\n",
    "{ctx.meeting_context or \"(not provided)\"}\n",
    "\n",
    "Output language rule:\n",
    "- {output_language_instruction}\n",
    "- {structure_instruction}\n",
    "\n",
    "Task:\n",
    "Using ONLY the evidence records provided below (title/snippet/url and, when available, extracted_text),\n",
    "produce a structured, meeting-ready briefing.\n",
    "\n",
    "Important assumptions:\n",
    "- Evidence may include items that are weakly related or not related to the target person.\n",
    "- You are NOT required to use all evidence.\n",
    "- Prefer precision over coverage.\n",
    "- It is acceptable to ignore evidence that is not clearly about the target person.\n",
    "\n",
    "Rules:\n",
    "- Do NOT invent facts.\n",
    "- If information is not clearly supported by evidence, set it to \"not found\".\n",
    "- Every factual statement must reference one or more URLs (put URLs in \"sources\"/\"evidence\").\n",
    "- Hypotheses must be labeled as hypotheses, not conclusions.\n",
    "- Avoid generic statements that could apply to anyone.\n",
    "- If evidence is thin or ambiguous, state that explicitly.\n",
    "\n",
    "Return ONLY valid JSON matching this schema exactly:\n",
    "\n",
    "{{\n",
    "  \"profile_summary\": {{\n",
    "    \"current_role\": \"... or 'not found'\",\n",
    "    \"background_overview\": \"... (brief, factual)\"\n",
    "  }},\n",
    "  \"career_highlights\": [\n",
    "    {{\n",
    "      \"point\": \"...\",\n",
    "      \"sources\": [\"url1\", \"url2\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"public_themes\": [\n",
    "    {{\n",
    "      \"theme\": \"...\",\n",
    "      \"evidence\": [\"url1\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"hypotheses\": [\n",
    "    {{\n",
    "      \"hypothesis\": \"...\",\n",
    "      \"rationale\": \"...\",\n",
    "      \"sources\": [\"url1\"],\n",
    "      \"confidence\": 0.0\n",
    "    }}\n",
    "  ],\n",
    "  \"talking_points\": [\n",
    "    {{\n",
    "      \"question\": \"...\",\n",
    "      \"intent\": \"...\",\n",
    "      \"related_hypothesis\": \"...\"\n",
    "    }}\n",
    "  ],\n",
    "  \"information_gaps\": [\n",
    "    \"...\"\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Evidence records:\n",
    "{json.dumps(llm_payload, ensure_ascii=False, indent=2)}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "prompt = build_llm_prompt(ctx, llm_payload)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4-5. Call OpenAI API (robust JSON parsing)\n",
    "# ----------------------------\n",
    "def call_llm_json(prompt: str, model: str = None) -> dict:\n",
    "    \"\"\"\n",
    "    Call OpenAI and parse JSON robustly.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "\n",
    "    # If your model supports it, prefer JSON response format.\n",
    "    # If not supported, fallback to regex extraction.\n",
    "    try:\n",
    "        resp = client.responses.create(\n",
    "            model=model,\n",
    "            input=prompt,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "        raw = (resp.output_text or \"\").strip()\n",
    "        return json.loads(raw)\n",
    "    except Exception:\n",
    "        # Fallback: extract JSON block defensively\n",
    "        resp = client.responses.create(model=model, input=prompt)\n",
    "        raw_text = (resp.output_text or \"\").strip()\n",
    "\n",
    "        import re\n",
    "        match = re.search(r\"\\{.*\\}\", raw_text, flags=re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(\"LLM output does not contain valid JSON.\")\n",
    "        return json.loads(match.group(0))\n",
    "\n",
    "\n",
    "llm_output = call_llm_json(prompt)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4-6. Inspect output\n",
    "# ----------------------------\n",
    "display(Markdown(\"#### LLM output preview\"))\n",
    "display(json.dumps(llm_output, indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4-7. Accessor\n",
    "# ----------------------------\n",
    "def get_llm_output() -> dict:\n",
    "    return llm_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "198449cb-c658-424e-b1e4-a8bb63dffd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 5. Output"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Rendering output in **JA**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Initial Meeting Brief\n",
       "**Name:** Pham Quang Cuong\n",
       "**Company:** Eureka Robotics\n",
       "\n",
       "## ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æ¦‚è¦\n",
       "- **Current role:** CEO\n",
       "- ãƒ•ã‚¡ãƒ ãƒ»ã‚¯ã‚¢ãƒ³ãƒ»ã‚¯ã‚ªãƒ³æ°ã¯ã€ã‚·ãƒ³ã‚¬ãƒãƒ¼ãƒ«å—æ´‹ç†å·¥å¤§å­¦ï¼ˆNTUï¼‰ã§ç¥çµŒç§‘å­¦ã¨ãƒ­ãƒœãƒƒãƒˆå·¥å­¦ã®åšå£«å·ã‚’å–å¾—ã—ã€2018å¹´ã«Eureka Roboticsã‚’å…±åŒå‰µæ¥­ã—ã¾ã—ãŸã€‚\n",
       "\n",
       "## ä¸»ãªçµŒæ­´ãƒ»ãƒã‚¤ãƒ©ã‚¤ãƒˆ\n",
       "- Eureka Roboticsã¯ã‚·ãƒªãƒ¼ã‚ºAãƒ©ã‚¦ãƒ³ãƒ‰ã§1,050ä¸‡ãƒ‰ãƒ«ã®è³‡é‡‘èª¿é”ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚\n",
       "  - https://prtimes.jp/main/html/rd/p/000000001.000153512.html\n",
       "  - https://robotstart.info/article/2024/12/13/365453.html\n",
       "- Eureka Roboticsã¯ã€ä¸»ã«è£½é€ æ¥­å‘ã‘ã«é«˜ç²¾åº¦ãªãƒ­ãƒœãƒƒãƒˆåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚\n",
       "  - https://ut-ec.co.jp/our_companies/eureka-robotics/\n",
       "\n",
       "## å¯¾å¤–çš„ã«èªã£ã¦ã„ã‚‹ãƒ†ãƒ¼ãƒ\n",
       "- è£½é€ æ¥­ã«ãŠã‘ã‚‹ãƒ­ãƒœãƒƒãƒˆã®è‡ªå‹•åŒ–\n",
       "  - https://robotstart.info/article/2024/12/13/365453.html\n",
       "\n",
       "## ä»®èª¬ï¼ˆè¦æ¤œè¨¼ï¼‰\n",
       "- **Hypothesis:** ãƒ•ã‚¡ãƒ ãƒ»ã‚¯ã‚¢ãƒ³ãƒ»ã‚¯ã‚ªãƒ³æ°ã¯ã€å°†æ¥çš„ã«Eureka Roboticsã‚’ã•ã‚‰ã«æˆé•·ã•ã›ã‚‹ãŸã‚ã«ã€æŠ€è¡“é©æ–°ã«æ³¨åŠ›ã™ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚\n",
       "  - Rationale: è³‡é‡‘èª¿é”ã«ã‚ˆã‚Šæ–°æŠ€è¡“ã®é–‹ç™ºã¨å¸‚å ´å‚å…¥ã‚’åŠ é€Ÿã™ã‚‹ãŸã‚ã€‚\n",
       "  - ç¢ºåº¦: 0.8\n",
       "  - https://prtimes.jp/main/html/rd/p/000000001.000153512.html\n",
       "\n",
       "## æƒ³å®šãƒˆãƒ¼ã‚­ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆ\n",
       "- ä»Šå¾Œã®Eureka Roboticsã®æŠ€è¡“é©æ–°ã®æ–¹å‘æ€§ã¯ï¼Ÿ\n",
       "  - Intent: Eureka Roboticsã®å°†æ¥æ€§ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’å¾—ã‚‹ãŸã‚ã€‚\n",
       "  - Related hypothesis: ãƒ•ã‚¡ãƒ ãƒ»ã‚¯ã‚¢ãƒ³ãƒ»ã‚¯ã‚ªãƒ³æ°ã¯ã€å°†æ¥çš„ã«Eureka Roboticsã‚’ã•ã‚‰ã«æˆé•·ã•ã›ã‚‹ãŸã‚ã«ã€æŠ€è¡“é©æ–°ã«æ³¨åŠ›ã™ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚\n",
       "\n",
       "## æœªç¢ºèªãƒ»è¿½åŠ ã§èãã¹ãç‚¹\n",
       "- ãƒ•ã‚¡ãƒ ãƒ»ã‚¯ã‚¢ãƒ³ãƒ»ã‚¯ã‚ªãƒ³æ°ã®å…·ä½“çš„ãªçµŒæ­´ã‚„ãã®ä»–ã®å®Ÿç¸¾ã«ã¤ã„ã¦ã®è©³ç´°æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Quick summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "ã€äº‹å‰ã‚µãƒãƒªãƒ¼ã€‘\n",
       "- CEO\n",
       "- ä¸»ãªè«–ç‚¹: è£½é€ æ¥­ã«ãŠã‘ã‚‹ãƒ­ãƒœãƒƒãƒˆã®è‡ªå‹•åŒ–\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5. Output\n",
    "# ============================================================\n",
    "# Purpose:\n",
    "# Render the structured LLM output into human-readable formats\n",
    "# suitable for real-world usage (meeting brief, quick summary).\n",
    "#\n",
    "# Output language follows the user's selection in Section 1.\n",
    "#\n",
    "# This section does NOT add new information.\n",
    "# It only reformats and presents what the LLM has already produced.\n",
    "#\n",
    "# Input:\n",
    "# - llm_output from Section 4\n",
    "# - InputContext (language_preference)\n",
    "#\n",
    "# Output:\n",
    "# - Meeting-ready brief (Markdown)\n",
    "# - Optional short summary for quick sharing\n",
    "# ============================================================\n",
    "\n",
    "def translate_llm_output(llm_output: dict, target_lang: str) -> dict:\n",
    "    \"\"\"\n",
    "    Translate all human-readable fields in llm_output into the target language.\n",
    "    JSON structure and keys must be preserved.\n",
    "    \"\"\"\n",
    "    if target_lang == \"en\":\n",
    "        return llm_output  # no-op\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Translate the following JSON content into Japanese.\n",
    "\n",
    "Rules:\n",
    "- Preserve the JSON structure and keys exactly.\n",
    "- Translate only the string values meant for human reading.\n",
    "- Do NOT add or remove fields.\n",
    "- Keep URLs unchanged.\n",
    "- Use natural business Japanese suitable for meeting preparation.\n",
    "\n",
    "JSON:\n",
    "{json.dumps(llm_output, ensure_ascii=False, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "        input=prompt,\n",
    "    )\n",
    "\n",
    "    text = response.output_text.strip()\n",
    "    import re\n",
    "    m = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"Translation failed: JSON not found\")\n",
    "\n",
    "    return json.loads(m.group(0))\n",
    "# ----------------------------\n",
    "# 5-1. Load inputs\n",
    "# ----------------------------\n",
    "ctx = get_input_context()\n",
    "llm_output_raw = get_llm_output()\n",
    "llm_output = translate_llm_output(llm_output_raw, ctx.language_preference)\n",
    "\n",
    "lang = ctx.language_preference  # \"en\" or \"ja\"\n",
    "\n",
    "display(Markdown(\"### 5. Output\"))\n",
    "display(Markdown(f\"Rendering output in **{lang.upper()}**\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5-2. Language helpers\n",
    "# ----------------------------\n",
    "LABELS = {\n",
    "    \"en\": {\n",
    "        \"profile\": \"Profile summary\",\n",
    "        \"career\": \"Career highlights\",\n",
    "        \"themes\": \"Public themes\",\n",
    "        \"hypotheses\": \"Hypotheses (to validate)\",\n",
    "        \"talking_points\": \"Suggested talking points\",\n",
    "        \"gaps\": \"Information gaps\",\n",
    "        \"sources\": \"Sources\",\n",
    "        \"confidence\": \"Confidence\",\n",
    "    },\n",
    "    \"ja\": {\n",
    "        \"profile\": \"ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æ¦‚è¦\",\n",
    "        \"career\": \"ä¸»ãªçµŒæ­´ãƒ»ãƒã‚¤ãƒ©ã‚¤ãƒˆ\",\n",
    "        \"themes\": \"å¯¾å¤–çš„ã«èªã£ã¦ã„ã‚‹ãƒ†ãƒ¼ãƒ\",\n",
    "        \"hypotheses\": \"ä»®èª¬ï¼ˆè¦æ¤œè¨¼ï¼‰\",\n",
    "        \"talking_points\": \"æƒ³å®šãƒˆãƒ¼ã‚­ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆ\",\n",
    "        \"gaps\": \"æœªç¢ºèªãƒ»è¿½åŠ ã§èãã¹ãç‚¹\",\n",
    "        \"sources\": \"å‚ç…§URL\",\n",
    "        \"confidence\": \"ç¢ºåº¦\",\n",
    "    },\n",
    "}\n",
    "\n",
    "L = LABELS[lang]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5-3. Render meeting brief\n",
    "# ----------------------------\n",
    "def render_meeting_brief(llm_output: dict, lang: str) -> str:\n",
    "    L = LABELS[lang]\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    # --- Header ---\n",
    "    lines.append(f\"# Initial Meeting Brief\")\n",
    "    lines.append(f\"**Name:** {ctx.person_name}\")\n",
    "    if ctx.company_name:\n",
    "        lines.append(f\"**Company:** {ctx.company_name}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # --- Profile summary ---\n",
    "    ps = llm_output.get(\"profile_summary\", {})\n",
    "    lines.append(f\"## {L['profile']}\")\n",
    "    lines.append(f\"- **Current role:** {ps.get('current_role', 'not found')}\")\n",
    "    lines.append(f\"- {ps.get('background_overview', '')}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # --- Career highlights ---\n",
    "    lines.append(f\"## {L['career']}\")\n",
    "    for ch in llm_output.get(\"career_highlights\", []):\n",
    "        lines.append(f\"- {ch['point']}\")\n",
    "        for u in ch.get(\"sources\", []):\n",
    "            lines.append(f\"  - {u}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # --- Public themes ---\n",
    "    lines.append(f\"## {L['themes']}\")\n",
    "    for th in llm_output.get(\"public_themes\", []):\n",
    "        lines.append(f\"- {th['theme']}\")\n",
    "        for u in th.get(\"evidence\", []):\n",
    "            lines.append(f\"  - {u}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # --- Hypotheses ---\n",
    "    lines.append(f\"## {L['hypotheses']}\")\n",
    "    for h in llm_output.get(\"hypotheses\", []):\n",
    "        lines.append(f\"- **Hypothesis:** {h['hypothesis']}\")\n",
    "        lines.append(f\"  - Rationale: {h['rationale']}\")\n",
    "        lines.append(f\"  - {L['confidence']}: {h.get('confidence', '')}\")\n",
    "        for u in h.get(\"sources\", []):\n",
    "            lines.append(f\"  - {u}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # --- Talking points ---\n",
    "    lines.append(f\"## {L['talking_points']}\")\n",
    "    for tp in llm_output.get(\"talking_points\", []):\n",
    "        lines.append(f\"- {tp['question']}\")\n",
    "        lines.append(f\"  - Intent: {tp['intent']}\")\n",
    "        if tp.get(\"related_hypothesis\"):\n",
    "            lines.append(f\"  - Related hypothesis: {tp['related_hypothesis']}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # --- Information gaps ---\n",
    "    lines.append(f\"## {L['gaps']}\")\n",
    "    for g in llm_output.get(\"information_gaps\", []):\n",
    "        lines.append(f\"- {g}\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "meeting_brief_md = render_meeting_brief(llm_output, lang)\n",
    "\n",
    "display(Markdown(meeting_brief_md))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5-4. Render short summary (optional)\n",
    "# ----------------------------\n",
    "def render_short_summary(llm_output: dict, lang: str) -> str:\n",
    "    if lang == \"ja\":\n",
    "        return (\n",
    "            f\"ã€äº‹å‰ã‚µãƒãƒªãƒ¼ã€‘\\n\"\n",
    "            f\"- {llm_output.get('profile_summary', {}).get('current_role', 'å½¹å‰²ä¸æ˜')}\\n\"\n",
    "            f\"- ä¸»ãªè«–ç‚¹: \"\n",
    "            + \", \".join([t[\"theme\"] for t in llm_output.get(\"public_themes\", [])[:3]])\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            f\"[Quick summary]\\n\"\n",
    "            f\"- Role: {llm_output.get('profile_summary', {}).get('current_role', 'not found')}\\n\"\n",
    "            f\"- Key themes: \"\n",
    "            + \", \".join([t[\"theme\"] for t in llm_output.get(\"public_themes\", [])[:3]])\n",
    "        )\n",
    "\n",
    "\n",
    "short_summary = render_short_summary(llm_output, lang)\n",
    "\n",
    "display(Markdown(\"### Quick summary\"))\n",
    "display(Markdown(f\"```\\n{short_summary}\\n```\"))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5-5. Accessors / exports\n",
    "# ----------------------------\n",
    "def get_meeting_brief_markdown() -> str:\n",
    "    \"\"\"\n",
    "    Returns the meeting brief as Markdown text.\n",
    "    \"\"\"\n",
    "    return meeting_brief_md\n",
    "\n",
    "\n",
    "def get_short_summary() -> str:\n",
    "    \"\"\"\n",
    "    Returns a short text summary for quick sharing.\n",
    "    \"\"\"\n",
    "    return short_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbddb88-c222-4de4-9c2a-5763120e5b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
