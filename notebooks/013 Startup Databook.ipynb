{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a73886-bc09-4703-838c-a4b7b63d37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 013 Startup Databook\n",
    "# ============================================================\n",
    "# This notebook provides a reproducible pipeline to discover and profile startups\n",
    "# using only publicly available information.\n",
    "#\n",
    "# It is designed to:\n",
    "#   1) Define a set of country-specific PR / startup-media sources (e.g., PR portals,\n",
    "#      startup news sites) as entry points for discovery.\n",
    "#   2) Allow users to select a target country and year via widgets.\n",
    "#   3) Run lightweight discovery using Google Programmable Search (CSE) to collect\n",
    "#      candidate URLs related to funding announcements and startup activity.\n",
    "#   4) Respect website access policies by performing a light robots.txt / policy check\n",
    "#      and only fetching content from URLs deemed safe to crawl.\n",
    "#   5) Use the OpenAI API to:\n",
    "#        - classify whether a company should be considered a \"startup\" (Yes/No),\n",
    "#        - extract and standardize key company and funding attributes when Yes.\n",
    "#   6) Deduplicate / reconcile entities (company name normalization and record merging).\n",
    "#   7) Export a structured dataset (CSV/Parquet/SQLite) suitable for:\n",
    "#        - investment / BD long-listing,\n",
    "#        - meeting preparation,\n",
    "#        - ecosystem mapping and year-over-year trend analysis.\n",
    "#\n",
    "# Key principles:\n",
    "#   - Public information only (no private data sources).\n",
    "#   - Minimal crawling: fetch only what is necessary, rate-limited, and cached.\n",
    "#   - Transparency: keep source URLs and confidence signals for auditability.\n",
    "#   - Reproducibility: parameters, intermediate outputs, and final outputs are all persisted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4bd763e-43ae-490b-9333-f286225444bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 013-2 Definition of PR / Startup Media Sources by Country\n",
    "# ============================================================\n",
    "# This section defines country-specific PR portals and startup-focused media\n",
    "# that serve as discovery entry points for startup-related announcements.\n",
    "#\n",
    "# These sources are used to identify candidate URLs via Google Programmable\n",
    "# Search (CSE). They are not intended to represent exhaustive or authoritative\n",
    "# datasets.\n",
    "#\n",
    "# Design principles:\n",
    "#   - Use broad, inclusive keywords to maximize recall at the discovery stage.\n",
    "#   - Avoid constraining searches by funding stage (e.g., Series A/B), as\n",
    "#     terminology varies significantly across countries and regions.\n",
    "#   - Defer precise classification (funding round, amounts, investors) to\n",
    "#     later stages using LLM-based extraction.\n",
    "#   - Keep source definitions declarative and easy to extend.\n",
    "#\n",
    "# Each country entry contains:\n",
    "#   - pr_sites: Press-release distribution platforms (if applicable).\n",
    "#   - startup_media_sites: Media outlets that frequently cover startups,\n",
    "#     funding events, and new business launches.\n",
    "#   - discovery_keywords: Broad keywords related to startup activity and\n",
    "#     investment, used to construct CSE queries.\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "COUNTRY_SOURCE_DEFINITIONS = {\n",
    "    \"JP\": {\n",
    "        \"country_name\": \"Japan\",\n",
    "        \"pr_sites\": [\n",
    "            \"prtimes.jp\"\n",
    "        ],\n",
    "        \"startup_media_sites\": [\n",
    "            \"jp.techcrunch.com\",\n",
    "            \"thebridge.jp\"\n",
    "        ],\n",
    "        \"discovery_keywords\": [\n",
    "            \"Ë≥áÈáëË™øÈÅî\",\n",
    "            \"Âá∫Ë≥á\",\n",
    "            \"„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó\",\n",
    "            \"Êñ∞Ë¶è‰∫ãÊ•≠\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"US\": {\n",
    "        \"country_name\": \"United States\",\n",
    "        \"pr_sites\": [\n",
    "            \"prnewswire.com\",\n",
    "            \"businesswire.com\"\n",
    "        ],\n",
    "        \"startup_media_sites\": [\n",
    "            \"techcrunch.com\",\n",
    "            \"venturebeat.com\"\n",
    "        ],\n",
    "        \"discovery_keywords\": [\n",
    "            \"funding\",\n",
    "            \"investment\",\n",
    "            \"startup\",\n",
    "            \"company launch\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"UK\": {\n",
    "        \"country_name\": \"United Kingdom\",\n",
    "        \"pr_sites\": [\n",
    "            \"prnewswire.co.uk\"\n",
    "        ],\n",
    "        \"startup_media_sites\": [\n",
    "            \"sifted.eu\",\n",
    "            \"tech.eu\"\n",
    "        ],\n",
    "        \"discovery_keywords\": [\n",
    "            \"funding\",\n",
    "            \"investment\",\n",
    "            \"startup\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"DE\": {\n",
    "        \"country_name\": \"Germany\",\n",
    "        \"pr_sites\": [\n",
    "            \"presseportal.de\"\n",
    "        ],\n",
    "        \"startup_media_sites\": [\n",
    "            \"gruenderszene.de\",\n",
    "            \"eu-startups.com\"\n",
    "        ],\n",
    "        \"discovery_keywords\": [\n",
    "            \"Finanzierung\",\n",
    "            \"Investition\",\n",
    "            \"Startup\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"FR\": {\n",
    "        \"country_name\": \"France\",\n",
    "        \"pr_sites\": [\n",
    "            \"prnewswire.com\"\n",
    "        ],\n",
    "        \"startup_media_sites\": [\n",
    "            \"frenchweb.fr\"\n",
    "        ],\n",
    "        \"discovery_keywords\": [\n",
    "            \"lev√©e de fonds\",\n",
    "            \"investissement\",\n",
    "            \"startup\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"CN\": {\n",
    "        \"country_name\": \"China\",\n",
    "        \"pr_sites\": [],\n",
    "        \"startup_media_sites\": [\n",
    "            \"36kr.com\"\n",
    "        ],\n",
    "        \"discovery_keywords\": [\n",
    "            \"ËûçËµÑ\",\n",
    "            \"ÊäïËµÑ\",\n",
    "            \"Âàõ‰∏ö\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"IN\": {\n",
    "        \"country_name\": \"India\",\n",
    "        \"pr_sites\": [],\n",
    "        \"startup_media_sites\": [\n",
    "            \"yourstory.com\",\n",
    "            \"inc42.com\"\n",
    "        ],\n",
    "        \"discovery_keywords\": [\n",
    "            \"funding\",\n",
    "            \"investment\",\n",
    "            \"startup\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"SG\": {\n",
    "        \"country_name\": \"Singapore\",\n",
    "        \"pr_sites\": [],\n",
    "        \"startup_media_sites\": [\n",
    "            \"e27.co\",\n",
    "            \"techinasia.com\"\n",
    "        ],\n",
    "        \"discovery_keywords\": [\n",
    "            \"funding\",\n",
    "            \"investment\",\n",
    "            \"startup\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"IL\": {\n",
    "        \"country_name\": \"Israel\",\n",
    "        \"pr_sites\": [],\n",
    "        \"startup_media_sites\": [\n",
    "            \"calcalistech.com\"\n",
    "        ],\n",
    "        \"discovery_keywords\": [\n",
    "            \"funding\",\n",
    "            \"investment\",\n",
    "            \"startup\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# These source definitions are consumed by later steps to dynamically\n",
    "# generate country- and year-specific CSE queries while keeping the\n",
    "# discovery stage broad and recall-oriented.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f86b716-0503-41cf-9fbe-a237b0b377b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1de20e9c03648f49491c3caffaf5044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>Pipeline Parameters</h4>'), HBox(children=(SelectMultiple(description='Country'‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 013-3 Input UI (ipywidgets)\n",
    "# ============================================================\n",
    "# This section defines the interactive UI for selecting:\n",
    "#   - Target country (one or multiple)\n",
    "#   - Target period with year (2010‚Äì2030) and month (Jan‚ÄìDec)\n",
    "#\n",
    "# Default period:\n",
    "#   - Start: Jan 2025\n",
    "#   - End:   Feb 2025\n",
    "#\n",
    "# The selected parameters are consolidated into a single RUN_CONFIG\n",
    "# dictionary that is reused throughout the notebook.\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helpers\n",
    "# ------------------------------------------------------------\n",
    "MONTH_NAMES = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "               \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "MONTH_TO_NUM = {m: i + 1 for i, m in enumerate(MONTH_NAMES)}\n",
    "\n",
    "def _validate_period(sy, sm, ey, em):\n",
    "    return (ey, MONTH_TO_NUM[em]) >= (sy, MONTH_TO_NUM[sm])\n",
    "\n",
    "def _expand_months(sy, sm, ey, em):\n",
    "    out = []\n",
    "    y, m = sy, MONTH_TO_NUM[sm]\n",
    "    ey_num = MONTH_TO_NUM[em]\n",
    "    while (y < ey) or (y == ey and m <= ey_num):\n",
    "        out.append(f\"{y:04d}-{m:02d}\")\n",
    "        m += 1\n",
    "        if m == 13:\n",
    "            m = 1\n",
    "            y += 1\n",
    "    return out\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Widget definitions\n",
    "# ------------------------------------------------------------\n",
    "YEAR_OPTIONS = list(range(2010, 2031))\n",
    "\n",
    "country_options = [(f\"{v['country_name']} ({k})\", k)\n",
    "                   for k, v in COUNTRY_SOURCE_DEFINITIONS.items()]\n",
    "\n",
    "country_select = widgets.SelectMultiple(\n",
    "    options=country_options,\n",
    "    value=(\"JP\",),\n",
    "    description=\"Country\",\n",
    "    rows=min(10, len(country_options))\n",
    ")\n",
    "\n",
    "start_year = widgets.Dropdown(\n",
    "    options=YEAR_OPTIONS,\n",
    "    value=2025,\n",
    "    description=\"Start Year\"\n",
    ")\n",
    "\n",
    "start_month = widgets.Dropdown(\n",
    "    options=MONTH_NAMES,\n",
    "    value=\"Jan\",\n",
    "    description=\"Start Month\"\n",
    ")\n",
    "\n",
    "end_year = widgets.Dropdown(\n",
    "    options=YEAR_OPTIONS,\n",
    "    value=2025,\n",
    "    description=\"End Year\"\n",
    ")\n",
    "\n",
    "end_month = widgets.Dropdown(\n",
    "    options=MONTH_NAMES,\n",
    "    value=\"Feb\",\n",
    "    description=\"End Month\"\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(\n",
    "    description=\"Set Parameters\",\n",
    "    button_style=\"primary\",\n",
    "    icon=\"check\"\n",
    ")\n",
    "\n",
    "status = widgets.HTML(value=\"\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# State container\n",
    "# ------------------------------------------------------------\n",
    "RUN_CONFIG = {}\n",
    "\n",
    "def _on_run_clicked(_):\n",
    "    global RUN_CONFIG\n",
    "    with output:\n",
    "        clear_output()\n",
    "\n",
    "        countries = list(country_select.value)\n",
    "        sy, sm = start_year.value, start_month.value\n",
    "        ey, em = end_year.value, end_month.value\n",
    "\n",
    "        if not countries:\n",
    "            status.value = \"<b style='color:#b00020'>Please select at least one country.</b>\"\n",
    "            return\n",
    "\n",
    "        if not _validate_period(sy, sm, ey, em):\n",
    "            status.value = \"<b style='color:#b00020'>Invalid period: end must be later than or equal to start.</b>\"\n",
    "            return\n",
    "\n",
    "        months = _expand_months(sy, sm, ey, em)\n",
    "\n",
    "        RUN_CONFIG = {\n",
    "            \"countries\": countries,\n",
    "            \"start_year\": sy,\n",
    "            \"start_month\": sm,\n",
    "            \"end_year\": ey,\n",
    "            \"end_month\": em,\n",
    "            \"months\": months\n",
    "        }\n",
    "\n",
    "        status.value = \"<b style='color:#0b6'>Parameters set successfully.</b>\"\n",
    "\n",
    "        print(\"RUN_CONFIG:\")\n",
    "        for k, v in RUN_CONFIG.items():\n",
    "            if k == \"months\":\n",
    "                print(f\"  {k}: {v[0]} ... {v[-1]} (n={len(v)})\")\n",
    "            else:\n",
    "                print(f\"  {k}: {v}\")\n",
    "\n",
    "run_button.on_click(_on_run_clicked)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Layout\n",
    "# ------------------------------------------------------------\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"<h4>Pipeline Parameters</h4>\"),\n",
    "    widgets.HBox([\n",
    "        country_select,\n",
    "        widgets.VBox([\n",
    "            start_year, start_month,\n",
    "            end_year, end_month,\n",
    "            run_button,\n",
    "            status\n",
    "        ])\n",
    "    ]),\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a912cf27-6c36-4860-9b1e-45b2b04e2803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OPENAI_API_KEY loaded successfully\n",
      "‚úÖ Google CSE credentials loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 013-4 OpenAI & Google CSE API Setup and Lightweight Discovery\n",
    "# ============================================================\n",
    "# This section defines external API clients and implements a lightweight\n",
    "# discovery layer using Google Programmable Search (CSE).\n",
    "#\n",
    "# Purpose:\n",
    "#   - OpenAI API:\n",
    "#       Used later for startup classification and structured information\n",
    "#       extraction from article text.\n",
    "#   - Google CSE:\n",
    "#       Used here for *lightweight discovery only* ‚Äî identifying candidate\n",
    "#       URLs from PR portals and startup media without crawling sites directly.\n",
    "#\n",
    "# Design principles:\n",
    "#   - Centralize API configuration in one place.\n",
    "#   - Fail fast if credentials are missing.\n",
    "#   - Keep CSE usage minimal (URL, title, snippet only).\n",
    "#   - Defer crawling and heavy processing to later steps.\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# ----------------------------\n",
    "# 4-0. Load API Keys\n",
    "# ----------------------------\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load env.txt explicitly\n",
    "load_dotenv(\"env.txt\")\n",
    "\n",
    "# --- OpenAI ---\n",
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY could not be loaded from env.txt.\")\n",
    "else:\n",
    "    print(\"‚úÖ OPENAI_API_KEY loaded successfully\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# --- Google CSE ---\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_CSE_CX = os.getenv(\"GOOGLE_CSE_CX\")\n",
    "\n",
    "if GOOGLE_API_KEY is None or GOOGLE_CSE_CX is None:\n",
    "    raise ValueError(\"GOOGLE_API_KEY or GOOGLE_CSE_CX is missing in env.txt\")\n",
    "else:\n",
    "    print(\"‚úÖ Google CSE credentials loaded successfully\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4-1. Google CSE Helper Functions\n",
    "# ----------------------------\n",
    "# The functions below wrap Google CSE calls and return a normalized\n",
    "# list of search results.\n",
    "#\n",
    "# Only metadata is retrieved at this stage:\n",
    "#   - URL\n",
    "#   - Title\n",
    "#   - Snippet\n",
    "#   - Display link\n",
    "#\n",
    "# No page content is fetched here.\n",
    "\n",
    "import requests\n",
    "from typing import List, Dict\n",
    "\n",
    "def run_cse_search(\n",
    "    query: str,\n",
    "    num_results: int = 5,\n",
    "    start_index: int = 1\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Execute a single Google CSE query.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        Search query string.\n",
    "    num_results : int\n",
    "        Number of results to return (max 10 per request).\n",
    "    start_index : int\n",
    "        Start index for pagination (1-based).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[Dict]\n",
    "        List of search result metadata dictionaries.\n",
    "    \"\"\"\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        \"key\": GOOGLE_API_KEY,\n",
    "        \"cx\": GOOGLE_CSE_CX,\n",
    "        \"q\": query,\n",
    "        \"num\": min(num_results, 10),\n",
    "        \"start\": start_index\n",
    "    }\n",
    "\n",
    "    resp = requests.get(url, params=params, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    items = data.get(\"items\", [])\n",
    "    results = []\n",
    "    for item in items:\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"title\": item.get(\"title\"),\n",
    "            \"snippet\": item.get(\"snippet\"),\n",
    "            \"url\": item.get(\"link\"),\n",
    "            \"display_link\": item.get(\"displayLink\")\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# ----------------------------\n",
    "# 4-2. Query Construction Logic\n",
    "# ----------------------------\n",
    "# This helper generates country-, site-, keyword-, and month-specific\n",
    "# queries using:\n",
    "#   - COUNTRY_SOURCE_DEFINITIONS\n",
    "#   - RUN_CONFIG (selected countries and months)\n",
    "#\n",
    "# Example generated query:\n",
    "#   site:prtimes.jp Ë≥áÈáëË™øÈÅî 2025-01\n",
    "\n",
    "def build_cse_queries(country_code: str, year_month: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Build a list of CSE queries for a given country and month.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    country_code : str\n",
    "        ISO-like country code (e.g., 'JP', 'US').\n",
    "    year_month : str\n",
    "        Target month in 'YYYY-MM' format.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        List of query strings.\n",
    "    \"\"\"\n",
    "    cfg = COUNTRY_SOURCE_DEFINITIONS[country_code]\n",
    "    sites = cfg[\"pr_sites\"] + cfg[\"startup_media_sites\"]\n",
    "    keywords = cfg[\"discovery_keywords\"]\n",
    "\n",
    "    queries = []\n",
    "    for site in sites:\n",
    "        for kw in keywords:\n",
    "            queries.append(f\"site:{site} {kw} {year_month}\")\n",
    "\n",
    "    return queries\n",
    "\n",
    "# ----------------------------\n",
    "# 4-3. Lightweight Discovery Runner\n",
    "# ----------------------------\n",
    "# This function runs CSE searches for all selected countries and months\n",
    "# and aggregates raw candidate URLs.\n",
    "#\n",
    "# IMPORTANT:\n",
    "#   - This step intentionally favors recall over precision.\n",
    "#   - Deduplication and filtering are handled in later steps.\n",
    "\n",
    "def discover_candidate_urls(run_config: dict, max_results_per_query: int = 5):\n",
    "    \"\"\"\n",
    "    Run Google CSE discovery for all selected countries and months.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    run_config : dict\n",
    "        RUN_CONFIG generated by the input UI.\n",
    "    max_results_per_query : int\n",
    "        Number of CSE results to fetch per query.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[Dict]\n",
    "        Raw list of candidate URL records.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    for country in run_config[\"countries\"]:\n",
    "        for ym in run_config[\"months\"]:\n",
    "            queries = build_cse_queries(country, ym)\n",
    "            for q in queries:\n",
    "                try:\n",
    "                    results = run_cse_search(q, num_results=max_results_per_query)\n",
    "                    for r in results:\n",
    "                        r[\"country\"] = country\n",
    "                        r[\"year_month\"] = ym\n",
    "                        all_results.append(r)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è CSE query failed: {q} | {e}\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# At this point, the output of discover_candidate_urls(...)\n",
    "# represents a raw, recall-oriented set of candidate URLs.\n",
    "# Subsequent sections will handle:\n",
    "#   - URL normalization and filtering\n",
    "#   - robots.txt / policy checks\n",
    "#   - content fetching\n",
    "#   - startup classification and structuring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce66cc1e-56c6-496a-bbfd-e1a86e149224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 013-5 Pre-processing of Candidate URLs\n",
    "# ============================================================\n",
    "# This section cleans and normalizes the raw Google CSE outputs and prepares a\n",
    "# high-quality candidate URL table for downstream steps.\n",
    "#\n",
    "# Goals:\n",
    "#   1) Normalize URLs (remove tracking parameters, unify canonical forms).\n",
    "#   2) Drop obvious noise (non-http(s), missing URLs, unwanted file types).\n",
    "#   3) Deduplicate aggressively (same URL returned by multiple queries).\n",
    "#   4) Attach lightweight metadata (country, year_month, source_domain).\n",
    "#\n",
    "# Optional (if supported / desired):\n",
    "#   - Time filtering at the CSE stage can be approximated using query modifiers.\n",
    "#     Google CSE does not provide a universal \"date range\" parameter in the API,\n",
    "#     but two practical approaches are:\n",
    "#       (a) Add query operators such as `after:` / `before:` (works variably).\n",
    "#       (b) Add explicit month tokens (we already do: YYYY-MM) to bias results.\n",
    "#   - Therefore, this notebook uses:\n",
    "#       - month tokens (YYYY-MM) in queries for recall\n",
    "#       - post-filtering heuristics here to enforce the selected period.\n",
    "#\n",
    "# Output:\n",
    "#   - candidate_urls_df: normalized, deduplicated URL candidates\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import re\n",
    "from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# 5-1. Utilities\n",
    "# ----------------------------\n",
    "TRACKING_PARAMS = {\n",
    "    \"utm_source\", \"utm_medium\", \"utm_campaign\", \"utm_term\", \"utm_content\",\n",
    "    \"fbclid\", \"gclid\", \"yclid\", \"mc_cid\", \"mc_eid\", \"ref\", \"src\"\n",
    "}\n",
    "\n",
    "UNWANTED_EXTENSIONS = (\".pdf\", \".jpg\", \".jpeg\", \".png\", \".gif\", \".svg\", \".zip\", \".rar\", \".7z\", \".mp4\", \".mp3\")\n",
    "\n",
    "def normalize_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a URL by:\n",
    "      - enforcing scheme+netloc+path normalization\n",
    "      - removing tracking parameters (utm_*, gclid, fbclid, etc.)\n",
    "      - removing URL fragments\n",
    "      - sorting remaining query parameters for stable deduplication\n",
    "    \"\"\"\n",
    "    if not isinstance(url, str) or not url.strip():\n",
    "        return None\n",
    "\n",
    "    url = url.strip()\n",
    "\n",
    "    # Ensure it looks like http(s)\n",
    "    if not (url.startswith(\"http://\") or url.startswith(\"https://\")):\n",
    "        return None\n",
    "\n",
    "    p = urlparse(url)\n",
    "\n",
    "    # Remove fragment\n",
    "    fragment = \"\"\n",
    "\n",
    "    # Filter and sort query params\n",
    "    q = []\n",
    "    for k, v in parse_qsl(p.query, keep_blank_values=True):\n",
    "        if k.lower() in TRACKING_PARAMS:\n",
    "            continue\n",
    "        q.append((k, v))\n",
    "    q.sort()\n",
    "\n",
    "    normalized = urlunparse((\n",
    "        p.scheme.lower(),\n",
    "        p.netloc.lower(),\n",
    "        p.path.rstrip(\"/\") or \"/\",\n",
    "        p.params,\n",
    "        urlencode(q, doseq=True),\n",
    "        fragment\n",
    "    ))\n",
    "    return normalized\n",
    "\n",
    "def extract_domain(url: str) -> str:\n",
    "    try:\n",
    "        return urlparse(url).netloc.lower()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def is_unwanted_url(url: str) -> bool:\n",
    "    \"\"\"Return True if URL should be filtered out (file types, etc.).\"\"\"\n",
    "    if not url:\n",
    "        return True\n",
    "    u = url.lower()\n",
    "    if any(u.endswith(ext) for ext in UNWANTED_EXTENSIONS):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def ym_in_text(year_month: str, text: str) -> bool:\n",
    "    \"\"\"\n",
    "    Heuristic: check if the target YYYY-MM token appears in title/snippet.\n",
    "    This helps enforce the selected month when CSE returns loosely-matched results.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    return year_month in text\n",
    "\n",
    "# ----------------------------\n",
    "# 5-2. Build a Candidate URL DataFrame\n",
    "# ----------------------------\n",
    "# Expected input: `raw_results` from discover_candidate_urls(...)\n",
    "#\n",
    "# Example:\n",
    "# raw_results = discover_candidate_urls(RUN_CONFIG, max_results_per_query=5)\n",
    "#\n",
    "# This cell converts to a DataFrame and applies cleaning + dedup.\n",
    "\n",
    "def preprocess_candidate_urls(raw_results: list, run_config: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess raw CSE results into a cleaned candidate URL DataFrame.\n",
    "    \"\"\"\n",
    "    if not raw_results:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(raw_results).copy()\n",
    "\n",
    "    # Basic sanity checks\n",
    "    for col in [\"url\", \"title\", \"snippet\", \"country\", \"year_month\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    # Normalize URLs\n",
    "    df[\"url_raw\"] = df[\"url\"]\n",
    "    df[\"url\"] = df[\"url\"].apply(normalize_url)\n",
    "\n",
    "    # Drop invalid / unwanted\n",
    "    df = df[df[\"url\"].notna()]\n",
    "    df = df[~df[\"url\"].apply(is_unwanted_url)]\n",
    "\n",
    "    # Attach domain\n",
    "    df[\"domain\"] = df[\"url\"].apply(extract_domain)\n",
    "\n",
    "    # Optional month enforcement (heuristic):\n",
    "    # Keep rows where YYYY-MM appears in either title or snippet OR in the URL itself.\n",
    "    # This is conservative and can be relaxed if recall is too low.\n",
    "    df[\"month_match\"] = df.apply(\n",
    "        lambda r: (\n",
    "            ym_in_text(r[\"year_month\"], r.get(\"title\")) or\n",
    "            ym_in_text(r[\"year_month\"], r.get(\"snippet\")) or\n",
    "            (r[\"year_month\"] in (r[\"url\"] or \"\"))\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # If you prefer higher recall, set this to False or comment out the filter.\n",
    "    ENFORCE_MONTH_MATCH = False\n",
    "    if ENFORCE_MONTH_MATCH:\n",
    "        df = df[df[\"month_match\"] == True]\n",
    "\n",
    "    # Deduplicate by normalized URL (keep the first occurrence)\n",
    "    df = df.sort_values(by=[\"country\", \"year_month\"]).drop_duplicates(subset=[\"url\"], keep=\"first\")\n",
    "\n",
    "    # Reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Minimal output schema\n",
    "    out_cols = [\n",
    "        \"country\", \"year_month\", \"domain\",\n",
    "        \"url\", \"url_raw\", \"title\", \"snippet\",\n",
    "        \"display_link\", \"query\", \"month_match\"\n",
    "    ]\n",
    "    out_cols = [c for c in out_cols if c in df.columns]\n",
    "    return df[out_cols]\n",
    "\n",
    "# Usage:\n",
    "# candidate_urls_df = preprocess_candidate_urls(raw_results, RUN_CONFIG)\n",
    "# candidate_urls_df.head()\n",
    "#\n",
    "# Next steps:\n",
    "#   - robots.txt / policy checks (domain-level)\n",
    "#   - fetch article text for allowed URLs only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b004d4-826c-48fa-9645-eed0b2e8d158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw results: 240\n",
      "Candidate URLs after preprocessing: 214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00f9d98c9e24689b832449a45522eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching allowed pages:   0%|          | 0/100 [00:00<?, ?url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000005.000125075.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000021.000091867.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000267.000010548.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000022.000051834.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000008.000118415.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000021.000044156.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000977.000016451.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000172.000025017.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000397.000000204.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000079.000040785.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000012.000053340.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000152.000048792.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000019.000055047.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000006.000075596.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000013.000125542.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000709.000016550.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000044.000040560.html\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/legal-agent-a-legal-tech-startup-secures-funding-from-anri-and-boostcapital\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/05/education-dx-platform-manabie-raises-approximately-3-3-billion-yen-in-total-funding\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/medteria-a-healthcare-communication-platform-raises-100-million-yen-in-funding\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/firstshift-the-operator-of-the-ai-matching-platform-secures-50-million-yen-in-funding\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/swap-the-developer-of-the-onboarding-focused-ai-service-offhack-raises-funding-in-a-pre-series-a-round\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/01/regional-fish-secures-40-million-in-series-c-funding-to-develop-climate-resilient-aquaculture-species-and-enhance-production\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/01/creww-launches-new-company-creww-capital-to-support-cvc-and-startup-investments-globally\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/01/fundit-secures-series-b-funding-to-accelerate-smb-it-business-rollups-raised-from-mizuho-bank\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/01/xksk-led-by-keisuke-honda-establishes-a-15-3-billion-yen-fund\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/xksk-led-by-keisuke-honda-establishes-a-15-3-billion-yen-fund\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/07/fukuokas-strategy-to-challenge-tokyo-centric-japan-from-startup-visas-to-ramen-tech\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/aroom-cyberagentcapital-insight\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/pokecazilla-cyberagentcapital-insight\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/happy-new-year-2025\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/03/ceatec2024-spinoff-newbiz-pitch-01booster\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/03/01bcf2024-newbizdev-ibr-01booster\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/innovators-go-global-the-challenge-of-do%E3%83%BBchange-an-internal-venture-born-from-shimizu-corporation-pioneering-new-business-development-in-the-global-south\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/03/01bcf2024-spinoff-01booster\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000021.000069778.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000053.000065073.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000057.000047724.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000001.000156507.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000050.000069887.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000157.000025017.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000345.000078927.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000075.000045441.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000020.000108918.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000042.000056734.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000017.000069506.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000089.000026987.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000038.000071723.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000018.000101722.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000086.000017470.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000033.000078441.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000003134.000014571.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000048.000014739.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000167.000033909.html\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/aeterlink-stanford-born-wireless-charging-technology-raises-additional-2-8-billion-yen\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/ec-focused-installment-payment-saas-respo-raises-120-million-yen-in-funding\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/hobby-platform-goopass-raises-funds-in-series-c-round\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/cellid-raises-2-billion-yen-to-enhance-ar-glasses-display-development\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/coffee-subscription-service-postcoffee-secures-funding-from-singapore-based-vc-plans-global-expansion-focusing-on-asia\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/ai-powered-financial-management-agent-zaimo-receives-investment-from-delight-ventures-and-deepcore-ceo-kojo-discusses-the-democratization-of-business-management\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/02/josanshes-a-company-providing-services-in-the-prenatal-and-postnatal-care-sector-raises-150-million-yen-in-pre-series-a-funding\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/02/boston-medical-sciences-raises-930-million-yen-in-series-a-funding\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/dgdv-portfolio-company-allara-health-raises-26-million-in-series-b-funding-led-by-index-ventures\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/japanese-startups-pioneering-a-massive-market-of-660-million-people-challenging-the-global-south-in-latin-america-and-the-caribbean-tsubasa2025\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/startup-ma-is-not-unusual-newmo-and-kanmu-discuss-new-growth-strategies\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/ceatec2024-spinoff-talk-01booster\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/how-toda-corporation-achieves-startup-co-creation-successes-as-an-lp-gb-universe\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/beauty-medical-platform-tribu-raises-2-3-billion-yen-in-series-c-its-strategy-for-survival-and-growth\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/she-raises-1-75-billion-yen-in-series-c-funding-moon-creative-ventures-and-marui-group-join-as-new-investors-total-funding-reaches-4-4-billion-yen\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/apt09-demoday-01booster\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/a-founders-vision-creates-unicorns-trust-smith-capital-ceo-ando-discusses-the-true-value-of-the-new-fund\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000117.000015549.html\n",
      "‚úÖ FETCHED (3041 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000015.000120323.html\n",
      "‚úÖ FETCHED (4072 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000128.000048083.html\n",
      "‚úÖ FETCHED (2399 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000017.000123554.html\n",
      "‚úÖ FETCHED (2476 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000249.000028531.html\n",
      "‚úÖ FETCHED (6510 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000158.000025017.html\n",
      "‚úÖ FETCHED (5089 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000036.000102678.html\n",
      "‚úÖ FETCHED (1638 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000120.000049509.html\n",
      "‚úÖ FETCHED (3810 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000056.000040191.html\n",
      "‚úÖ FETCHED (6533 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000020.000038111.html\n",
      "‚úÖ FETCHED (1389 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000049.000049702.html\n",
      "‚úÖ FETCHED (5484 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000101.000074198.html\n",
      "‚úÖ FETCHED (1810 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000099.000022779.html\n",
      "‚úÖ FETCHED (3987 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000146.000090165.html\n",
      "‚úÖ FETCHED (2366 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000033.000058890.html\n",
      "‚úÖ FETCHED (2165 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000711.000037194.html\n",
      "‚úÖ FETCHED (4299 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000040.000057483.html\n",
      "‚úÖ FETCHED (2796 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000053.000012991.html\n",
      "‚úÖ FETCHED (7383 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000022.000110065.html\n",
      "‚úÖ FETCHED (2533 chars)\n",
      "üåê FETCHING: https://prtimes.jp/main/html/rd/p/000000015.000085091.html\n",
      "‚úÖ FETCHED (1997 chars)\n",
      "üåê FETCHING: https://thebridge.jp/2025/03/sustainableme-secures-funding-from-east-ventures-to-promote-well-being-centered-corporate-management\n",
      "‚úÖ FETCHED (3009 chars)\n",
      "üåê FETCHING: https://thebridge.jp/2025/03/umee-technologies-the-developer-of-the-conversational-ai-front-agent-raises-300-million-yen-in-series-a-funding\n",
      "‚úÖ FETCHED (2563 chars)\n",
      "üåê FETCHING: https://thebridge.jp/2025/03/customized-ai-for-enterprises-ai-ceo-developed-tha-secures-funding-from-delight-ventures\n",
      "‚úÖ FETCHED (2581 chars)\n",
      "üåê FETCHING: https://thebridge.jp/2025/03/carstay-secures-additional-funding-to-deploy-campervans-to-disaster-stricken-areas-in-times-of-emergency\n",
      "‚úÖ FETCHED (2757 chars)\n",
      "üåê FETCHING: https://thebridge.jp/2025/03/tayori-operator-of-an-end-of-life-messaging-service-raises-funding-with-investment-from-east-ventures-and-others\n",
      "‚úÖ FETCHED (2595 chars)\n",
      "üåê FETCHING: https://thebridge.jp/en/2025/03/health-tech-startup-ubie-raises-funding-from-japan-post-capital\n",
      "‚úÖ FETCHED (2496 chars)\n",
      "üåê FETCHING: https://thebridge.jp/2025/03/japan-post-capital-invests-in-us-based-humanoid-robotics-company-apptronik\n",
      "‚úÖ FETCHED (2535 chars)\n",
      "üåê FETCHING: https://thebridge.jp/2025/03/zero-cost-donation-app-givearth-raises-tens-of-millions-of-yen-from-taimees-founder-and-others\n",
      "‚úÖ FETCHED (2677 chars)\n",
      "üåê FETCHING: https://thebridge.jp/2025/03/tokyu-construction-invests-in-u-s-based-twelve-benefit-corporation-a-manufacturer-of-low-carbon-synthetic-fuels\n",
      "‚úÖ FETCHED (2566 chars)\n",
      "\n",
      "‚úÖ Completed: 100 URLs processed\n",
      "fetched\n",
      "True    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 013-6 Lightweight robots.txt Check & Content Fetching (Allowed URLs Only)\n",
    "# ============================================================\n",
    "# This section performs:\n",
    "#   (1) A lightweight robots.txt permission check per domain, and\n",
    "#   (2) Fetches article HTML / text only for URLs that appear crawl-allowed.\n",
    "#\n",
    "# IMPORTANT DISCLAIMER\n",
    "# --------------------\n",
    "# This notebook is designed for research and analysis using public information.\n",
    "# Always respect:\n",
    "#   - robots.txt directives (minimum requirement)\n",
    "#   - each website's Terms of Use (may impose stricter limitations than robots.txt)\n",
    "#   - rate limits and server load (polite crawling)\n",
    "#\n",
    "# This step intentionally stays conservative:\n",
    "#   - If robots.txt cannot be fetched, we default to \"unknown\" and SKIP\n",
    "#     (you can relax this if you have explicit permission).\n",
    "#   - Only fetch a minimal subset of pages and cache results locally.\n",
    "#\n",
    "# Output:\n",
    "#   - fetch_df: URL-level table with robots status and extracted text (if fetched)\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from urllib.robotparser import RobotFileParser\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "# ----------------------------\n",
    "# 6-1. Polite crawling settings\n",
    "# ----------------------------\n",
    "USER_AGENT = \"researchOS-bot/0.1 (+contact: you@example.com)\"  # update contact if desired\n",
    "HEADERS = {\"User-Agent\": USER_AGENT}\n",
    "\n",
    "# Rate limiting (seconds). Adjust based on your risk tolerance.\n",
    "SLEEP_MIN = 1.5\n",
    "SLEEP_MAX = 4.0\n",
    "\n",
    "# Local cache directory (HTML/text)\n",
    "CACHE_DIR = Path(\"./cache_pages\")\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _sleep():\n",
    "    time.sleep(random.uniform(SLEEP_MIN, SLEEP_MAX))\n",
    "\n",
    "def _hash_key(s: str) -> str:\n",
    "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()[:24]\n",
    "\n",
    "# ----------------------------\n",
    "# 6-2. robots.txt checker (domain-level)\n",
    "# ----------------------------\n",
    "_robots_cache = {}  # in-memory cache by domain\n",
    "\n",
    "def can_fetch_url(url: str, user_agent: str = USER_AGENT, timeout: int = 15) -> dict:\n",
    "    \"\"\"\n",
    "    Check whether robots.txt allows fetching the given URL.\n",
    "    Returns a dict with:\n",
    "      - robots_ok: True/False/None (None = unknown)\n",
    "      - robots_url: robots.txt URL\n",
    "      - robots_error: error message if any\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return {\"robots_ok\": None, \"robots_url\": None, \"robots_error\": \"empty_url\"}\n",
    "\n",
    "    p = urlparse(url)\n",
    "    domain = p.netloc.lower()\n",
    "    robots_url = f\"{p.scheme}://{domain}/robots.txt\"\n",
    "\n",
    "    if domain in _robots_cache:\n",
    "        rp = _robots_cache[domain]\n",
    "        if rp is None:\n",
    "            return {\"robots_ok\": None, \"robots_url\": robots_url, \"robots_error\": \"robots_unavailable_cached\"}\n",
    "        return {\"robots_ok\": rp.can_fetch(user_agent, url), \"robots_url\": robots_url, \"robots_error\": None}\n",
    "\n",
    "    rp = RobotFileParser()\n",
    "    rp.set_url(robots_url)\n",
    "\n",
    "    try:\n",
    "        # RobotFileParser internally fetches robots.txt when read() is called,\n",
    "        # but it uses urllib and does not set headers. To keep control, we fetch\n",
    "        # robots.txt ourselves and parse it manually.\n",
    "        resp = requests.get(robots_url, headers=HEADERS, timeout=timeout)\n",
    "        if resp.status_code != 200:\n",
    "            _robots_cache[domain] = None\n",
    "            return {\"robots_ok\": None, \"robots_url\": robots_url, \"robots_error\": f\"robots_http_{resp.status_code}\"}\n",
    "\n",
    "        rp.parse(resp.text.splitlines())\n",
    "        _robots_cache[domain] = rp\n",
    "        return {\"robots_ok\": rp.can_fetch(user_agent, url), \"robots_url\": robots_url, \"robots_error\": None}\n",
    "\n",
    "    except Exception as e:\n",
    "        _robots_cache[domain] = None\n",
    "        return {\"robots_ok\": None, \"robots_url\": robots_url, \"robots_error\": str(e)}\n",
    "\n",
    "# ----------------------------\n",
    "# 6-3. Minimal HTML fetch + text extraction\n",
    "# ----------------------------\n",
    "def fetch_html(url: str, timeout: int = 30) -> str:\n",
    "    \"\"\"\n",
    "    Fetch HTML for a single URL, with basic error handling.\n",
    "    Returns HTML string or None.\n",
    "    \"\"\"\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=timeout)\n",
    "    resp.raise_for_status()\n",
    "    # Basic guard: only accept HTML-like responses\n",
    "    ctype = (resp.headers.get(\"Content-Type\") or \"\").lower()\n",
    "    if \"text/html\" not in ctype and \"application/xhtml\" not in ctype:\n",
    "        return None\n",
    "    return resp.text\n",
    "\n",
    "def extract_main_text(html: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract a readable text representation from HTML.\n",
    "    This is a simple heuristic approach; you may replace with `trafilatura`\n",
    "    or `readability-lxml` later for better extraction.\n",
    "    \"\"\"\n",
    "    if not html:\n",
    "        return \"\"\n",
    "\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    # Remove non-content elements\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\", \"header\", \"footer\", \"svg\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    text = soup.get_text(separator=\"\\n\")\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n",
    "    return text\n",
    "\n",
    "# ----------------------------\n",
    "# 6-4. On-disk caching\n",
    "# ----------------------------\n",
    "def cache_paths(url: str):\n",
    "    key = _hash_key(url)\n",
    "    return (\n",
    "        CACHE_DIR / f\"{key}.meta.json\",\n",
    "        CACHE_DIR / f\"{key}.html\",\n",
    "        CACHE_DIR / f\"{key}.txt\",\n",
    "    )\n",
    "\n",
    "def load_from_cache(url: str):\n",
    "    meta_p, html_p, txt_p = cache_paths(url)\n",
    "    if meta_p.exists() and txt_p.exists():\n",
    "        meta = json.loads(meta_p.read_text(encoding=\"utf-8\"))\n",
    "        txt = txt_p.read_text(encoding=\"utf-8\")\n",
    "        html = html_p.read_text(encoding=\"utf-8\") if html_p.exists() else None\n",
    "        return meta, html, txt\n",
    "    return None, None, None\n",
    "\n",
    "def save_to_cache(url: str, meta: dict, html: str, txt: str):\n",
    "    meta_p, html_p, txt_p = cache_paths(url)\n",
    "    meta_p.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    if html is not None:\n",
    "        html_p.write_text(html, encoding=\"utf-8\")\n",
    "    txt_p.write_text(txt or \"\", encoding=\"utf-8\")\n",
    "\n",
    "raw_results = discover_candidate_urls(\n",
    "    RUN_CONFIG,\n",
    "    max_results_per_query=5\n",
    ")\n",
    "\n",
    "print(f\"Raw results: {len(raw_results)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6-5. Main runner: robots check + fetch allowed\n",
    "# ----------------------------\n",
    "def check_and_fetch(candidate_urls_df: pd.DataFrame,\n",
    "                    max_pages: int = 200,\n",
    "                    skip_if_robots_unknown: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each candidate URL:\n",
    "      - check robots.txt permission\n",
    "      - fetch + extract text only if allowed\n",
    "      - cache all fetched results\n",
    "    \"\"\"\n",
    "    if candidate_urls_df is None or candidate_urls_df.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    n = min(len(candidate_urls_df), max_pages)\n",
    "\n",
    "    for i in range(n):\n",
    "        r = candidate_urls_df.iloc[i]\n",
    "        url = r[\"url\"]\n",
    "\n",
    "        # robots check\n",
    "        robots_info = can_fetch_url(url)\n",
    "\n",
    "        robots_ok = robots_info[\"robots_ok\"]\n",
    "        if robots_ok is None and skip_if_robots_unknown:\n",
    "            rows.append({**r.to_dict(), **robots_info, \"fetched\": False, \"text\": None, \"fetch_error\": \"robots_unknown_skip\"})\n",
    "            continue\n",
    "        if robots_ok is False:\n",
    "            rows.append({**r.to_dict(), **robots_info, \"fetched\": False, \"text\": None, \"fetch_error\": \"robots_disallow\"})\n",
    "            continue\n",
    "\n",
    "        # cache lookup\n",
    "        meta_cached, html_cached, txt_cached = load_from_cache(url)\n",
    "        if txt_cached is not None:\n",
    "            rows.append({\n",
    "                **r.to_dict(),\n",
    "                **robots_info,\n",
    "                \"fetched\": True,\n",
    "                \"from_cache\": True,\n",
    "                \"text\": txt_cached,\n",
    "                \"fetch_error\": None\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # fetch\n",
    "        try:\n",
    "            _sleep()\n",
    "            html = fetch_html(url)\n",
    "            if html is None:\n",
    "                rows.append({**r.to_dict(), **robots_info, \"fetched\": False, \"from_cache\": False, \"text\": None, \"fetch_error\": \"non_html\"})\n",
    "                continue\n",
    "\n",
    "            txt = extract_main_text(html)\n",
    "            meta = {\n",
    "                \"url\": url,\n",
    "                \"fetched_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "                \"user_agent\": USER_AGENT,\n",
    "                \"domain\": r.get(\"domain\"),\n",
    "                \"country\": r.get(\"country\"),\n",
    "                \"year_month\": r.get(\"year_month\"),\n",
    "            }\n",
    "            save_to_cache(url, meta, html, txt)\n",
    "\n",
    "            rows.append({\n",
    "                **r.to_dict(),\n",
    "                **robots_info,\n",
    "                \"fetched\": True,\n",
    "                \"from_cache\": False,\n",
    "                \"text\": txt,\n",
    "                \"fetch_error\": None\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            rows.append({**r.to_dict(), **robots_info, \"fetched\": False, \"from_cache\": False, \"text\": None, \"fetch_error\": str(e)})\n",
    "\n",
    "    fetch_df = pd.DataFrame(rows)\n",
    "\n",
    "    # Keep only a minimal but useful schema\n",
    "    keep_cols = [\n",
    "        \"country\", \"year_month\", \"domain\",\n",
    "        \"url\", \"title\", \"snippet\",\n",
    "        \"robots_ok\", \"robots_url\", \"robots_error\",\n",
    "        \"fetched\", \"from_cache\", \"fetch_error\",\n",
    "        \"text\"\n",
    "    ]\n",
    "    keep_cols = [c for c in keep_cols if c in fetch_df.columns]\n",
    "    return fetch_df[keep_cols]\n",
    "\n",
    "# Usage example:\n",
    "# fetch_df = check_and_fetch(candidate_urls_df, max_pages=200, skip_if_robots_unknown=True)\n",
    "# fetch_df.head()\n",
    "#\n",
    "# Next steps:\n",
    "#   - OpenAI startup classification (Yes/No)\n",
    "#   - Structured extraction for Yes cases\n",
    "\n",
    "candidate_urls_df = preprocess_candidate_urls(\n",
    "    raw_results,\n",
    "    RUN_CONFIG\n",
    ")\n",
    "\n",
    "print(f\"Candidate URLs after preprocessing: {len(candidate_urls_df)}\")\n",
    "candidate_urls_df.head()\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def check_and_fetch_with_progress(\n",
    "    candidate_urls_df: pd.DataFrame,\n",
    "    max_pages: int = 200,\n",
    "    skip_if_robots_unknown: bool = True,\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    robots.txt check + content fetch with visible progress.\n",
    "\n",
    "    Progress indicators:\n",
    "      - tqdm progress bar (overall)\n",
    "      - short per-URL status messages (optional)\n",
    "    \"\"\"\n",
    "    if candidate_urls_df is None or candidate_urls_df.empty:\n",
    "        print(\"‚ö†Ô∏è No candidate URLs to process.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    n = min(len(candidate_urls_df), max_pages)\n",
    "\n",
    "    iterator = tqdm(\n",
    "        range(n),\n",
    "        desc=\"Fetching allowed pages\",\n",
    "        unit=\"url\"\n",
    "    )\n",
    "\n",
    "    for i in iterator:\n",
    "        r = candidate_urls_df.iloc[i]\n",
    "        url = r[\"url\"]\n",
    "\n",
    "        iterator.set_postfix_str(url[:60] + (\"‚Ä¶\" if len(url) > 60 else \"\"))\n",
    "\n",
    "        # ----------------------------\n",
    "        # robots.txt check\n",
    "        # ----------------------------\n",
    "        robots_info = can_fetch_url(url)\n",
    "        robots_ok = robots_info[\"robots_ok\"]\n",
    "\n",
    "        if robots_ok is None and skip_if_robots_unknown:\n",
    "            if verbose:\n",
    "                print(f\"‚è≠Ô∏è  SKIP (robots unknown): {url}\")\n",
    "            rows.append({\n",
    "                **r.to_dict(),\n",
    "                **robots_info,\n",
    "                \"fetched\": False,\n",
    "                \"from_cache\": False,\n",
    "                \"text\": None,\n",
    "                \"fetch_error\": \"robots_unknown_skip\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        if robots_ok is False:\n",
    "            if verbose:\n",
    "                print(f\"üö´ DISALLOWED by robots.txt: {url}\")\n",
    "            rows.append({\n",
    "                **r.to_dict(),\n",
    "                **robots_info,\n",
    "                \"fetched\": False,\n",
    "                \"from_cache\": False,\n",
    "                \"text\": None,\n",
    "                \"fetch_error\": \"robots_disallow\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # ----------------------------\n",
    "        # cache lookup\n",
    "        # ----------------------------\n",
    "        meta_cached, html_cached, txt_cached = load_from_cache(url)\n",
    "        if txt_cached is not None:\n",
    "            if verbose:\n",
    "                print(f\"üì¶ CACHE HIT: {url}\")\n",
    "            rows.append({\n",
    "                **r.to_dict(),\n",
    "                **robots_info,\n",
    "                \"fetched\": True,\n",
    "                \"from_cache\": True,\n",
    "                \"text\": txt_cached,\n",
    "                \"fetch_error\": None\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # ----------------------------\n",
    "        # fetch & extract\n",
    "        # ----------------------------\n",
    "        try:\n",
    "            if verbose:\n",
    "                print(f\"üåê FETCHING: {url}\")\n",
    "\n",
    "            _sleep()\n",
    "            html = fetch_html(url)\n",
    "            if html is None:\n",
    "                if verbose:\n",
    "                    print(f\"‚ö†Ô∏è  NON-HTML content skipped: {url}\")\n",
    "                rows.append({\n",
    "                    **r.to_dict(),\n",
    "                    **robots_info,\n",
    "                    \"fetched\": False,\n",
    "                    \"from_cache\": False,\n",
    "                    \"text\": None,\n",
    "                    \"fetch_error\": \"non_html\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            text = extract_main_text(html)\n",
    "\n",
    "            meta = {\n",
    "                \"url\": url,\n",
    "                \"fetched_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "                \"user_agent\": USER_AGENT,\n",
    "                \"domain\": r.get(\"domain\"),\n",
    "                \"country\": r.get(\"country\"),\n",
    "                \"year_month\": r.get(\"year_month\"),\n",
    "            }\n",
    "\n",
    "            save_to_cache(url, meta, html, text)\n",
    "\n",
    "            rows.append({\n",
    "                **r.to_dict(),\n",
    "                **robots_info,\n",
    "                \"fetched\": True,\n",
    "                \"from_cache\": False,\n",
    "                \"text\": text,\n",
    "                \"fetch_error\": None\n",
    "            })\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"‚úÖ FETCHED ({len(text)} chars)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"‚ùå ERROR fetching {url}: {e}\")\n",
    "            rows.append({\n",
    "                **r.to_dict(),\n",
    "                **robots_info,\n",
    "                \"fetched\": False,\n",
    "                \"from_cache\": False,\n",
    "                \"text\": None,\n",
    "                \"fetch_error\": str(e)\n",
    "            })\n",
    "\n",
    "    fetch_df = pd.DataFrame(rows)\n",
    "\n",
    "    keep_cols = [\n",
    "        \"country\", \"year_month\", \"domain\",\n",
    "        \"url\", \"title\", \"snippet\",\n",
    "        \"robots_ok\", \"robots_url\",\n",
    "        \"fetched\", \"from_cache\", \"fetch_error\",\n",
    "        \"text\"\n",
    "    ]\n",
    "    keep_cols = [c for c in keep_cols if c in fetch_df.columns]\n",
    "\n",
    "    print(f\"\\n‚úÖ Completed: {len(fetch_df)} URLs processed\")\n",
    "    print(fetch_df[\"fetched\"].value_counts(dropna=False))\n",
    "\n",
    "    return fetch_df[keep_cols]\n",
    "\n",
    "fetch_df = check_and_fetch_with_progress(\n",
    "    candidate_urls_df,\n",
    "    max_pages=100,\n",
    "    skip_if_robots_unknown=True,\n",
    "    verbose=True   # False „Å´„Åô„Çã„Å® tqdm „ÅÆ„Åø\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c482a3-5315-431b-a694-f0461d6510c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40cdc000c994b6292f7b460d1929b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LLM classify & extract:   0%|          | 0/100 [00:00<?, ?url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000005.000125075.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000021.000091867.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000267.000010548.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000022.000051834.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000008.000118415.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000021.000044156.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000977.000016451.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000172.000025017.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000397.000000204.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000079.000040785.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000012.000053340.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000152.000048792.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000019.000055047.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000006.000075596.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000013.000125542.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000709.000016550.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000044.000040560.html\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/legal-agent-a-legal-tech-startu‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/05/education-dx-platform-manabie-r‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/medteria-a-healthcare-communica‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/firstshift-the-operator-of-the-‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/swap-the-developer-of-the-onboa‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/01/regional-fish-secures-40-mil‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/01/creww-launches-new-company-c‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/01/fundit-secures-series-b-fund‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/01/xksk-led-by-keisuke-honda-es‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/xksk-led-by-keisuke-honda-estab‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/07/fukuokas-strategy-to-challenge-‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/aroom-cyberagentcapital-insight\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/pokecazilla-cyberagentcapital-i‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/happy-new-year-2025\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/03/ceatec2024-spinoff-newbiz-pitch‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/03/01bcf2024-newbizdev-ibr-01boost‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/01/innovators-go-global-the-challe‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/03/01bcf2024-spinoff-01booster\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000021.000069778.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000053.000065073.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000057.000047724.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000001.000156507.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000050.000069887.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000157.000025017.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000345.000078927.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000075.000045441.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000020.000108918.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000042.000056734.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000017.000069506.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000089.000026987.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000038.000071723.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000018.000101722.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000086.000017470.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000033.000078441.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000003134.000014571.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000048.000014739.html\n",
      "üì¶ CACHE HIT: https://prtimes.jp/main/html/rd/p/000000167.000033909.html\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/aeterlink-stanford-born-wireles‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/ec-focused-installment-payment-‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/hobby-platform-goopass-raises-f‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/cellid-raises-2-billion-yen-to-‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/coffee-subscription-service-pos‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/ai-powered-financial-management‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/02/josanshes-a-company-providin‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/en/2025/02/boston-medical-sciences-rais‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/dgdv-portfolio-company-allara-h‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/japanese-startups-pioneering-a-‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/startup-ma-is-not-unusual-newmo‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/ceatec2024-spinoff-talk-01boost‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/how-toda-corporation-achieves-s‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/beauty-medical-platform-tribu-r‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/she-raises-1-75-billion-yen-in-‚Ä¶\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/apt09-demoday-01booster\n",
      "üì¶ CACHE HIT: https://thebridge.jp/2025/02/a-founders-vision-creates-unico‚Ä¶\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000117.000015549.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000015.000120323.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000128.000048083.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000017.000123554.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000249.000028531.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000158.000025017.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000036.000102678.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000120.000049509.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000056.000040191.html\n",
      "‚úÖ SUCCESS | is_startup=No | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000020.000038111.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000049.000049702.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000101.000074198.html\n",
      "‚úÖ SUCCESS | is_startup=No | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000099.000022779.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000146.000090165.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000033.000058890.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000711.000037194.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000040.000057483.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000053.000012991.html\n",
      "‚úÖ SUCCESS | is_startup=No | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000022.000110065.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://prtimes.jp/main/html/rd/p/000000015.000085091.html\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://thebridge.jp/2025/03/sustainableme-secures-funding-f‚Ä¶\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://thebridge.jp/2025/03/umee-technologies-the-developer‚Ä¶\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://thebridge.jp/2025/03/customized-ai-for-enterprises-a‚Ä¶\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://thebridge.jp/2025/03/carstay-secures-additional-fund‚Ä¶\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://thebridge.jp/2025/03/tayori-operator-of-an-end-of-li‚Ä¶\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://thebridge.jp/en/2025/03/health-tech-startup-ubie-rai‚Ä¶\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://thebridge.jp/2025/03/japan-post-capital-invests-in-u‚Ä¶\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://thebridge.jp/2025/03/zero-cost-donation-app-givearth‚Ä¶\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "ü§ñ CALL OpenAI: https://thebridge.jp/2025/03/tokyu-construction-invests-in-u‚Ä¶\n",
      "‚úÖ SUCCESS | is_startup=Yes | confidence=0.5\n",
      "\n",
      "üìä Startup classification summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "is_startup\n",
       "Yes    80\n",
       "No     20\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Cache usage:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_from_cache\n",
       "True     71\n",
       "False    29\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 013-7 (Improved) OpenAI Startup Classification with Logs\n",
    "# ============================================================\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "from typing import Optional\n",
    "\n",
    "def call_openai_for_startup_structuring(\n",
    "    url: str,\n",
    "    country: Optional[str],\n",
    "    year_month: Optional[str],\n",
    "    title: Optional[str],\n",
    "    text: Optional[str],\n",
    "    model: str = \"gpt-4.1-mini\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Call OpenAI to classify whether the content represents a startup,\n",
    "    and extract structured information if applicable.\n",
    "    \"\"\"\n",
    "\n",
    "    if not text or not isinstance(text, str):\n",
    "        raise ValueError(\"Empty or invalid text input\")\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "You are an expert startup analyst.\n",
    "\n",
    "Your task:\n",
    "1. Decide whether the content describes a startup company.\n",
    "2. If YES, extract structured startup information.\n",
    "3. If NO, clearly explain why.\n",
    "\n",
    "Definition of a startup:\n",
    "- A relatively young company or venture\n",
    "- Typically innovation-driven or growth-oriented\n",
    "- Often mentions fundraising, venture capital, new products, or early-stage expansion\n",
    "\n",
    "Output rules:\n",
    "- Output MUST be valid JSON.\n",
    "- Do NOT include markdown.\n",
    "- Do NOT include commentary outside JSON.\n",
    "- Use null for unknown values.\n",
    "- Use empty arrays [] where appropriate.\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "URL: {url}\n",
    "Country: {country}\n",
    "Year-Month: {year_month}\n",
    "\n",
    "Title:\n",
    "{title}\n",
    "\n",
    "Content:\n",
    "{text[:12000]}\n",
    "\n",
    "Instructions:\n",
    "- First decide if this is a startup.\n",
    "- If not a startup, set \"is_startup\" to \"No\" and explain briefly.\n",
    "- If a startup, set \"is_startup\" to \"Yes\" and fill all applicable fields.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "            {\"role\": \"user\", \"content\": user_prompt.strip()}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    raw = response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Invalid JSON from OpenAI: {e}\\nRaw output:\\n{raw}\")\n",
    "\n",
    "    # ---- Minimal schema normalization ----\n",
    "    result = {\n",
    "        \"is_startup\": data.get(\"is_startup\", \"No\"),\n",
    "        \"confidence\": float(data.get(\"confidence\", 0.5)),\n",
    "\n",
    "        \"decision_rationale\": data.get(\"decision_rationale\"),\n",
    "\n",
    "        \"company_name\": data.get(\"company_name\"),\n",
    "        \"country\": country,\n",
    "\n",
    "        \"business_summary\": data.get(\"business_summary\"),\n",
    "        \"service_or_product\": data.get(\"service_or_product\"),\n",
    "        \"target_market\": data.get(\"target_market\"),\n",
    "        \"customer_segments\": data.get(\"customer_segments\"),\n",
    "\n",
    "        \"funding_round\": data.get(\"funding_round\"),\n",
    "        \"funding_amount\": data.get(\"funding_amount\"),\n",
    "        \"funding_amount_currency\": data.get(\"funding_amount_currency\"),\n",
    "        \"total_funding_to_date\": data.get(\"total_funding_to_date\"),\n",
    "        \"valuation\": data.get(\"valuation\"),\n",
    "\n",
    "        \"investors\": data.get(\"investors\", []) or [],\n",
    "        \"announcement_date\": data.get(\"announcement_date\"),\n",
    "\n",
    "        \"source_urls\": [url]\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "LLM_CACHE_DIR = Path(\"./cache_llm\")\n",
    "LLM_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _llm_cache_key(url: str) -> str:\n",
    "    return hashlib.sha256(url.encode(\"utf-8\")).hexdigest()[:24]\n",
    "\n",
    "def _llm_cache_path(url: str) -> Path:\n",
    "    return LLM_CACHE_DIR / f\"{_llm_cache_key(url)}.json\"\n",
    "\n",
    "def load_llm_cache(url: str):\n",
    "    \"\"\"\n",
    "    Load cached LLM result for a URL.\n",
    "    Returns dict or None.\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return None\n",
    "    p = _llm_cache_path(url)\n",
    "    if not p.exists():\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def save_llm_cache(url: str, payload: dict):\n",
    "    \"\"\"\n",
    "    Save LLM result payload to cache.\n",
    "    \"\"\"\n",
    "    if not url or payload is None:\n",
    "        return\n",
    "\n",
    "    p = _llm_cache_path(url)\n",
    "    # attach minimal metadata\n",
    "    obj = dict(payload)\n",
    "    obj[\"_cache_saved_at_utc\"] = datetime.utcnow().isoformat() + \"Z\"\n",
    "    obj[\"_cache_url\"] = url\n",
    "\n",
    "    p.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def run_llm_on_fetched_pages_with_logs(\n",
    "    fetch_df: pd.DataFrame,\n",
    "    model: str = \"gpt-4.1-mini\",\n",
    "    max_pages: int = 200,\n",
    "    only_fetched: bool = True,\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run OpenAI classification + extraction with visible logs.\n",
    "\n",
    "    Logs:\n",
    "      - tqdm progress bar (overall)\n",
    "      - per-URL status (cache / call / success / error)\n",
    "    \"\"\"\n",
    "    if fetch_df is None or fetch_df.empty:\n",
    "        print(\"‚ö†Ô∏è fetch_df is empty.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = fetch_df.copy()\n",
    "    if only_fetched:\n",
    "        df = df[df.get(\"fetched\", False) == True].copy()\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"‚ö†Ô∏è No fetched pages to process (fetched==True).\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    n = min(len(df), max_pages)\n",
    "\n",
    "    results = []\n",
    "    iterator = tqdm(range(n), desc=\"LLM classify & extract\", unit=\"url\")\n",
    "\n",
    "    for i in iterator:\n",
    "        row = df.iloc[i]\n",
    "        url = row[\"url\"]\n",
    "        short_url = url[:60] + (\"‚Ä¶\" if len(url) > 60 else \"\")\n",
    "        iterator.set_postfix_str(short_url)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Cache check\n",
    "        # ----------------------------\n",
    "        cached = load_llm_cache(url)\n",
    "        if cached is not None:\n",
    "            if verbose:\n",
    "                print(f\"üì¶ CACHE HIT: {short_url}\")\n",
    "            cached[\"_from_cache\"] = True\n",
    "            results.append(cached)\n",
    "            continue\n",
    "\n",
    "        # ----------------------------\n",
    "        # OpenAI API call\n",
    "        # ----------------------------\n",
    "        try:\n",
    "            if verbose:\n",
    "                print(f\"ü§ñ CALL OpenAI: {short_url}\")\n",
    "\n",
    "            payload = call_openai_for_startup_structuring(\n",
    "                url=url,\n",
    "                country=row.get(\"country\"),\n",
    "                year_month=row.get(\"year_month\"),\n",
    "                title=row.get(\"title\"),\n",
    "                text=row.get(\"text\"),\n",
    "                model=model\n",
    "            )\n",
    "\n",
    "            payload[\"_from_cache\"] = False\n",
    "            save_llm_cache(url, payload)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"‚úÖ SUCCESS | is_startup={payload.get('is_startup')} \"\n",
    "                      f\"| confidence={payload.get('confidence')}\")\n",
    "\n",
    "            results.append(payload)\n",
    "\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"‚ùå ERROR OpenAI: {short_url} | {e}\")\n",
    "\n",
    "            results.append({\n",
    "                \"is_startup\": \"No\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"decision_rationale\": f\"LLM_ERROR: {e}\",\n",
    "                \"company_name\": None,\n",
    "                \"country\": row.get(\"country\"),\n",
    "                \"business_summary\": None,\n",
    "                \"service_or_product\": None,\n",
    "                \"target_market\": None,\n",
    "                \"customer_segments\": None,\n",
    "                \"funding_round\": None,\n",
    "                \"funding_amount\": None,\n",
    "                \"funding_amount_currency\": None,\n",
    "                \"total_funding_to_date\": None,\n",
    "                \"valuation\": None,\n",
    "                \"investors\": [],\n",
    "                \"announcement_date\": None,\n",
    "                \"source_urls\": [url],\n",
    "                \"_from_cache\": False\n",
    "            })\n",
    "\n",
    "    llm_results_df = pd.DataFrame(results)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Summary\n",
    "    # ----------------------------\n",
    "    print(\"\\nüìä Startup classification summary:\")\n",
    "    display(llm_results_df[\"is_startup\"].value_counts(dropna=False))\n",
    "\n",
    "    print(\"\\nüì¶ Cache usage:\")\n",
    "    display(llm_results_df[\"_from_cache\"].value_counts(dropna=False))\n",
    "\n",
    "    return llm_results_df\n",
    "\n",
    "llm_results_df = run_llm_on_fetched_pages_with_logs(\n",
    "    fetch_df,\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    max_pages=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44c9c495-7373-4c70-b222-39d9b0a85588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>business_summary</th>\n",
       "      <th>funding_round</th>\n",
       "      <th>funding_amount</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>„Éö„É™„Ç™„Çª„É©„Éî„Ç¢Ê†™Âºè‰ºöÁ§æ</td>\n",
       "      <td>A drug discovery venture originating from Osak...</td>\n",
       "      <td>Additional funding round</td>\n",
       "      <td>Á¥Ñ1ÂÑÑÂÜÜ</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>„Ç§„Éé„Éê„Çª„É´Ê†™Âºè‰ºöÁ§æ</td>\n",
       "      <td>Innovacell is a regenerative medicine venture ...</td>\n",
       "      <td>Series D</td>\n",
       "      <td>10.6ÂÑÑÂÜÜ</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bitBiomeÊ†™Âºè‰ºöÁ§æ</td>\n",
       "      <td>bitBiome is a biotechnology company leveraging...</td>\n",
       "      <td>Global Seed Extension Second Close</td>\n",
       "      <td>400,000,000</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æPower Diamond Systems</td>\n",
       "      <td>Power Diamond Systems is a startup conducting ...</td>\n",
       "      <td>Third-party allotment (2nd close)</td>\n",
       "      <td>100000000</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æLegalscape</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æLegalscape provides an AI-powered legal re...</td>\n",
       "      <td>Secondary transaction</td>\n",
       "      <td>160,000,000</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bythen</td>\n",
       "      <td>bythen is an AI technology startup specializin...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà is a startup focused on solving socia...</td>\n",
       "      <td>Not explicitly stated, but funding was raised ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FirstShift</td>\n",
       "      <td>FirstShift operates an AI matching platform 'A...</td>\n",
       "      <td>None</td>\n",
       "      <td>50,000,000</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Manabie International Pte. Ltd.</td>\n",
       "      <td>Manabie is an EdTech startup providing an educ...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>33ÂÑÑÂÜÜ</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Medteria</td>\n",
       "      <td>Medteria provides a healthcare communication c...</td>\n",
       "      <td>Series Unknown (first disclosed round)</td>\n",
       "      <td>100,000,000</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Legal Agent</td>\n",
       "      <td>Legal Agent provides legal services leveraging...</td>\n",
       "      <td>J-KISS convertible note</td>\n",
       "      <td>50,000,000</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æEco-Pork</td>\n",
       "      <td>Eco-Pork provides digital transformation (DX) ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KAICO</td>\n",
       "      <td>KAICO is a bio-venture originating from Kyushu...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>540,000,000</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FUNDiT</td>\n",
       "      <td>FUNDiT specializes in M&amp;A and rollups of small...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>960 million</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Regional Fish</td>\n",
       "      <td>Regional Fish specializes in breeding innovati...</td>\n",
       "      <td>Series C</td>\n",
       "      <td>25.3 Million</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Swap</td>\n",
       "      <td>Swap develops and operates an onboarding-focus...</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Zaimo</td>\n",
       "      <td>Zaimo develops an AI-powered financial managem...</td>\n",
       "      <td>Series unknown (early round)</td>\n",
       "      <td>100 million JPY</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Josan-she‚Äôs</td>\n",
       "      <td>Josan-she‚Äôs provides prenatal and postnatal ca...</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>150 million yen</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Boston Medical Sciences</td>\n",
       "      <td>Developing a virtual endoscopy system to enabl...</td>\n",
       "      <td>Series A</td>\n",
       "      <td>930 million yen</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Allara Health</td>\n",
       "      <td>Allara Health provides a telemedicine platform...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>26 million</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       company_name  \\\n",
       "0                       „Éö„É™„Ç™„Çª„É©„Éî„Ç¢Ê†™Âºè‰ºöÁ§æ   \n",
       "1                         „Ç§„Éé„Éê„Çª„É´Ê†™Âºè‰ºöÁ§æ   \n",
       "3                      bitBiomeÊ†™Âºè‰ºöÁ§æ   \n",
       "4         Ê†™Âºè‰ºöÁ§æPower Diamond Systems   \n",
       "7                    Ê†™Âºè‰ºöÁ§æLegalscape   \n",
       "8                            bythen   \n",
       "10                         Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà   \n",
       "20                       FirstShift   \n",
       "18  Manabie International Pte. Ltd.   \n",
       "19                         Medteria   \n",
       "17                      Legal Agent   \n",
       "37                     Ê†™Âºè‰ºöÁ§æEco-Pork   \n",
       "27                            KAICO   \n",
       "24                           FUNDiT   \n",
       "22                    Regional Fish   \n",
       "21                             Swap   \n",
       "59                            Zaimo   \n",
       "60                      Josan-she‚Äôs   \n",
       "61          Boston Medical Sciences   \n",
       "62                    Allara Health   \n",
       "\n",
       "                                     business_summary  \\\n",
       "0   A drug discovery venture originating from Osak...   \n",
       "1   Innovacell is a regenerative medicine venture ...   \n",
       "3   bitBiome is a biotechnology company leveraging...   \n",
       "4   Power Diamond Systems is a startup conducting ...   \n",
       "7   Ê†™Âºè‰ºöÁ§æLegalscape provides an AI-powered legal re...   \n",
       "8   bythen is an AI technology startup specializin...   \n",
       "10  Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà is a startup focused on solving socia...   \n",
       "20  FirstShift operates an AI matching platform 'A...   \n",
       "18  Manabie is an EdTech startup providing an educ...   \n",
       "19  Medteria provides a healthcare communication c...   \n",
       "17  Legal Agent provides legal services leveraging...   \n",
       "37  Eco-Pork provides digital transformation (DX) ...   \n",
       "27  KAICO is a bio-venture originating from Kyushu...   \n",
       "24  FUNDiT specializes in M&A and rollups of small...   \n",
       "22  Regional Fish specializes in breeding innovati...   \n",
       "21  Swap develops and operates an onboarding-focus...   \n",
       "59  Zaimo develops an AI-powered financial managem...   \n",
       "60  Josan-she‚Äôs provides prenatal and postnatal ca...   \n",
       "61  Developing a virtual endoscopy system to enabl...   \n",
       "62  Allara Health provides a telemedicine platform...   \n",
       "\n",
       "                                        funding_round   funding_amount  \\\n",
       "0                            Additional funding round             Á¥Ñ1ÂÑÑÂÜÜ   \n",
       "1                                            Series D           10.6ÂÑÑÂÜÜ   \n",
       "3                  Global Seed Extension Second Close      400,000,000   \n",
       "4                   Third-party allotment (2nd close)        100000000   \n",
       "7                               Secondary transaction      160,000,000   \n",
       "8                                                None             None   \n",
       "10  Not explicitly stated, but funding was raised ...             None   \n",
       "20                                               None       50,000,000   \n",
       "18                                           Series B             33ÂÑÑÂÜÜ   \n",
       "19             Series Unknown (first disclosed round)      100,000,000   \n",
       "17                            J-KISS convertible note       50,000,000   \n",
       "37                                               None             None   \n",
       "27                                           Series B      540,000,000   \n",
       "24                                           Series B      960 million   \n",
       "22                                           Series C     25.3 Million   \n",
       "21                                       Pre-Series A             None   \n",
       "59                       Series unknown (early round)  100 million JPY   \n",
       "60                                       Pre-Series A  150 million yen   \n",
       "61                                           Series A  930 million yen   \n",
       "62                                           Series B       26 million   \n",
       "\n",
       "    confidence  \n",
       "0         0.95  \n",
       "1         0.95  \n",
       "3         0.95  \n",
       "4         0.95  \n",
       "7         0.95  \n",
       "8         0.95  \n",
       "10        0.95  \n",
       "20        0.95  \n",
       "18        0.95  \n",
       "19        0.95  \n",
       "17        0.95  \n",
       "37        0.95  \n",
       "27        0.95  \n",
       "24        0.95  \n",
       "22        0.95  \n",
       "21        0.95  \n",
       "59        0.95  \n",
       "60        0.95  \n",
       "61        0.95  \n",
       "62        0.95  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "startup_df = llm_results_df[llm_results_df[\"is_startup\"] == \"Yes\"].copy()\n",
    "\n",
    "display(\n",
    "    startup_df[\n",
    "        [\"company_name\", \"business_summary\", \"funding_round\",\n",
    "         \"funding_amount\", \"confidence\"]\n",
    "    ].sort_values(\"confidence\", ascending=False).head(20)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c0b15bb-0fa7-44c8-a35f-9bade4382ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decision_rationale</th>\n",
       "      <th>source_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The company, Ê†™Âºè‰ºöÁ§æ„É¶„Éº„Ç∂„Éô„Éº„Çπ (Uzabase, Inc.), was e...</td>\n",
       "      <td>[https://prtimes.jp/main/html/rd/p/000000267.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The company, Ê†™Âºè‰ºöÁ§æ„Ç§„É≥„Éô„Çπ„Éà„É°„É≥„Éà„Éñ„É™„ÉÉ„Ç∏, was established...</td>\n",
       "      <td>[https://prtimes.jp/main/html/rd/p/000000021.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The company, „Éë„Éº„ÇΩ„É´„Éõ„Éº„É´„Éá„Ç£„É≥„Ç∞„ÇπÊ†™Âºè‰ºöÁ§æ, is a long-estab...</td>\n",
       "      <td>[https://prtimes.jp/main/html/rd/p/000000977.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The source describes the '„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„ÉóÈÉΩÂ∏ÇÊé®ÈÄ≤ÂçîË≠∞‰ºö' (Sta...</td>\n",
       "      <td>[https://prtimes.jp/main/html/rd/p/000000152.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æ„Çº„É≠„ÉØ„É≥„Éñ„Éº„Çπ„Çø„Éº (01Booster) was established in 2...</td>\n",
       "      <td>[https://prtimes.jp/main/html/rd/p/000000709.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Creww was founded in 2012 and has established ...</td>\n",
       "      <td>[https://thebridge.jp/en/2025/01/creww-launche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>X&amp;KSK is a venture capital firm, not a startup...</td>\n",
       "      <td>[https://thebridge.jp/en/2025/01/xksk-led-by-k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The source text describes BRIDGE as a media an...</td>\n",
       "      <td>[https://thebridge.jp/2025/01/happy-new-year-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The source text discusses internal innovation ...</td>\n",
       "      <td>[https://thebridge.jp/2025/03/01bcf2024-newbiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æ„Ç±„ÉÉ„Éó„É´„ÅØ2015Âπ¥Ë®≠Á´ã„ÅßË≥áÊú¨Èáë4ÂÑÑ344‰∏áÂÜÜ„ÅÆÊÉÖÂ†±ÈÄö‰ø°‰ºÅÊ•≠„Åß„ÅÇ„Çä„ÄÅ„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„ÉóÂãï...</td>\n",
       "      <td>[https://prtimes.jp/main/html/rd/p/000000089.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   decision_rationale  \\\n",
       "2   The company, Ê†™Âºè‰ºöÁ§æ„É¶„Éº„Ç∂„Éô„Éº„Çπ (Uzabase, Inc.), was e...   \n",
       "5   The company, Ê†™Âºè‰ºöÁ§æ„Ç§„É≥„Éô„Çπ„Éà„É°„É≥„Éà„Éñ„É™„ÉÉ„Ç∏, was established...   \n",
       "6   The company, „Éë„Éº„ÇΩ„É´„Éõ„Éº„É´„Éá„Ç£„É≥„Ç∞„ÇπÊ†™Âºè‰ºöÁ§æ, is a long-estab...   \n",
       "11  The source describes the '„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„ÉóÈÉΩÂ∏ÇÊé®ÈÄ≤ÂçîË≠∞‰ºö' (Sta...   \n",
       "15  Ê†™Âºè‰ºöÁ§æ„Çº„É≠„ÉØ„É≥„Éñ„Éº„Çπ„Çø„Éº (01Booster) was established in 2...   \n",
       "23  Creww was founded in 2012 and has established ...   \n",
       "25  X&KSK is a venture capital firm, not a startup...   \n",
       "30  The source text describes BRIDGE as a media an...   \n",
       "32  The source text discusses internal innovation ...   \n",
       "46  Ê†™Âºè‰ºöÁ§æ„Ç±„ÉÉ„Éó„É´„ÅØ2015Âπ¥Ë®≠Á´ã„ÅßË≥áÊú¨Èáë4ÂÑÑ344‰∏áÂÜÜ„ÅÆÊÉÖÂ†±ÈÄö‰ø°‰ºÅÊ•≠„Åß„ÅÇ„Çä„ÄÅ„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„ÉóÂãï...   \n",
       "\n",
       "                                          source_urls  \n",
       "2   [https://prtimes.jp/main/html/rd/p/000000267.0...  \n",
       "5   [https://prtimes.jp/main/html/rd/p/000000021.0...  \n",
       "6   [https://prtimes.jp/main/html/rd/p/000000977.0...  \n",
       "11  [https://prtimes.jp/main/html/rd/p/000000152.0...  \n",
       "15  [https://prtimes.jp/main/html/rd/p/000000709.0...  \n",
       "23  [https://thebridge.jp/en/2025/01/creww-launche...  \n",
       "25  [https://thebridge.jp/en/2025/01/xksk-led-by-k...  \n",
       "30  [https://thebridge.jp/2025/01/happy-new-year-2...  \n",
       "32  [https://thebridge.jp/2025/03/01bcf2024-newbiz...  \n",
       "46  [https://prtimes.jp/main/html/rd/p/000000089.0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_df = llm_results_df[llm_results_df[\"is_startup\"] == \"No\"].copy()\n",
    "\n",
    "display(\n",
    "    no_df[\n",
    "        [\"decision_rationale\", \"source_urls\"]\n",
    "    ].head(10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "626add16-65c4-46e5-8b3d-1c68a58a897e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "funding_round\n",
       "None                                                                                                                   48\n",
       "Series B                                                                                                                4\n",
       "Series C                                                                                                                4\n",
       "Pre-Series A                                                                                                            3\n",
       "Series B Extension                                                                                                      2\n",
       "Additional funding round                                                                                                1\n",
       "Global Seed Extension Second Close                                                                                      1\n",
       "Series D                                                                                                                1\n",
       "J-KISS convertible note                                                                                                 1\n",
       "Not explicitly stated, but funding was raised in October 2024 from venture investors, likely a seed or early round.     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startup_df[\"funding_round\"].value_counts(dropna=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb47aa76-bf26-4ef1-b999-6d7254222716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d633eb036b246459c7b056a6c10af48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating business_summary:   0%|          | 0/100 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8982febea0194412bd6ff1e75f08747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating service_or_product:   0%|          | 0/100 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8a8f2c74a14904bd803df5d53f4423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating target_market:   0%|          | 0/100 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23319b82f5134e768ba83b7be9618b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating customer_segments:   0%|          | 0/100 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Translation completed and cached.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 013-7.5 OpenAI API: Translation to English (with Cache)\n",
    "# ============================================================\n",
    "# This section translates Japanese (or non-English) text fields into English\n",
    "# using the OpenAI API.\n",
    "#\n",
    "# Design principles:\n",
    "#   - Preserve original text (no overwrite)\n",
    "#   - Translate only when non-English is detected\n",
    "#   - Cache translations to avoid repeated API costs\n",
    "#   - Use English as the primary display language downstream\n",
    "#\n",
    "# Input:\n",
    "#   - llm_results_df\n",
    "#\n",
    "# Output:\n",
    "#   - llm_results_df (augmented with *_en fields)\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "TRANSLATION_CACHE_DIR = Path(\"./cache_translation\")\n",
    "TRANSLATION_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _translation_cache_path(text: str) -> Path:\n",
    "    key = hashlib.sha256(text.encode(\"utf-8\")).hexdigest()[:24]\n",
    "    return TRANSLATION_CACHE_DIR / f\"{key}.txt\"\n",
    "\n",
    "def load_translation_cache(text: str):\n",
    "    p = _translation_cache_path(text)\n",
    "    if p.exists():\n",
    "        return p.read_text(encoding=\"utf-8\")\n",
    "    return None\n",
    "\n",
    "def save_translation_cache(text: str, translated: str):\n",
    "    p = _translation_cache_path(text)\n",
    "    p.write_text(translated, encoding=\"utf-8\")\n",
    "\n",
    "# Simple non-English heuristic (CJK)\n",
    "_CJK_RE = re.compile(r\"[\\u3040-\\u30ff\\u3400-\\u4dbf\\u4e00-\\u9fff]\")\n",
    "\n",
    "def needs_translation(text: str) -> bool:\n",
    "    if not text or not isinstance(text, str):\n",
    "        return False\n",
    "    return bool(_CJK_RE.search(text))\n",
    "\n",
    "def translate_to_english(text: str, model: str = \"gpt-4.1-mini\") -> str:\n",
    "    cached = load_translation_cache(text)\n",
    "    if cached is not None:\n",
    "        return cached\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Translate the following text into clear, professional English.\n",
    "Preserve the original meaning faithfully.\n",
    "Do NOT add interpretation or extra information.\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional translator.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt.strip()}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    translated = resp.choices[0].message.content.strip()\n",
    "    save_translation_cache(text, translated)\n",
    "    return translated\n",
    "\n",
    "# ----------------------------\n",
    "# Run translation on selected fields\n",
    "# ----------------------------\n",
    "FIELDS_TO_TRANSLATE = [\n",
    "    \"business_summary\",\n",
    "    \"service_or_product\",\n",
    "    \"target_market\",\n",
    "    \"customer_segments\"\n",
    "]\n",
    "\n",
    "df = llm_results_df.copy()\n",
    "\n",
    "for field in FIELDS_TO_TRANSLATE:\n",
    "    en_field = f\"{field}_en\"\n",
    "    translated = []\n",
    "\n",
    "    iterator = tqdm(df[field].fillna(\"\").tolist(), desc=f\"Translating {field}\", unit=\"row\")\n",
    "    for text in iterator:\n",
    "        if needs_translation(text):\n",
    "            translated.append(translate_to_english(text))\n",
    "        else:\n",
    "            translated.append(text or None)\n",
    "\n",
    "    df[en_field] = translated\n",
    "\n",
    "llm_results_df = df\n",
    "\n",
    "print(\"‚úÖ Translation completed and cached.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7895b5d-9d19-4dcc-af59-26c872200377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba97e6a53d2f430b9bc7f04f0ab8ffa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating company names:   0%|          | 0/100 [00:00<?, ?name/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Company name translation completed and cached.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 013-7.6 OpenAI API: Company Name Translation (JP/CJK -> EN) with Cache\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- language detection (self-contained to avoid NameError) ---\n",
    "_CJK_RE = re.compile(r\"[\\u3040-\\u30ff\\u3400-\\u4dbf\\u4e00-\\u9fff]\")\n",
    "\n",
    "def contains_cjk(text: str) -> bool:\n",
    "    return bool(text) and bool(_CJK_RE.search(str(text)))\n",
    "\n",
    "COMPANY_NAME_TRANSLATION_CACHE = Path(\"./cache_company_name_translation\")\n",
    "COMPANY_NAME_TRANSLATION_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _company_name_cache_path(name: str) -> Path:\n",
    "    key = hashlib.sha256(name.encode(\"utf-8\")).hexdigest()[:24]\n",
    "    return COMPANY_NAME_TRANSLATION_CACHE / f\"{key}.txt\"\n",
    "\n",
    "def load_company_name_cache(name: str):\n",
    "    p = _company_name_cache_path(name)\n",
    "    return p.read_text(encoding=\"utf-8\") if p.exists() else None\n",
    "\n",
    "def save_company_name_cache(name: str, translated: str):\n",
    "    p = _company_name_cache_path(name)\n",
    "    p.write_text(translated, encoding=\"utf-8\")\n",
    "\n",
    "def needs_company_name_translation(name: str) -> bool:\n",
    "    if not name or not isinstance(name, str):\n",
    "        return False\n",
    "    # If any CJK exists, we want an English display version.\n",
    "    return contains_cjk(name)\n",
    "\n",
    "def _translate_once(name: str, model: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "Translate the following company name into natural, concise English.\n",
    "\n",
    "Rules:\n",
    "- Do NOT add legal suffixes such as \"Inc.\", \"Ltd.\", etc., unless clearly implied.\n",
    "- If the name is a coined brand name, transliterate appropriately.\n",
    "- Return ONLY the English name (ASCII letters/numbers if possible).\n",
    "\n",
    "Company name:\n",
    "{name}\n",
    "\"\"\".strip()\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional business translator.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "def translate_company_name_to_english(name: str, model: str = \"gpt-4.1-mini\") -> str:\n",
    "    cached = load_company_name_cache(name)\n",
    "    if cached is not None:\n",
    "        return cached\n",
    "\n",
    "    translated = _translate_once(name, model=model)\n",
    "\n",
    "    # If the output still contains CJK, retry once with a stricter instruction.\n",
    "    if contains_cjk(translated):\n",
    "        prompt_retry = f\"\"\"\n",
    "Convert the following Japanese company name into an English rendering.\n",
    "\n",
    "Rules:\n",
    "- Output MUST be in English (no Japanese characters).\n",
    "- If you cannot find an official English name, provide a romanized/transliterated version.\n",
    "- Return ONLY the name.\n",
    "\n",
    "Company name:\n",
    "{name}\n",
    "\"\"\".strip()\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional business translator.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt_retry}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        translated = resp.choices[0].message.content.strip()\n",
    "\n",
    "    save_company_name_cache(name, translated)\n",
    "    return translated\n",
    "\n",
    "# ----------------------------\n",
    "# Run company name translation\n",
    "# ----------------------------\n",
    "df = llm_results_df.copy()\n",
    "\n",
    "translated_names = []\n",
    "iterator = tqdm(df[\"company_name\"].fillna(\"\").tolist(), desc=\"Translating company names\", unit=\"name\")\n",
    "\n",
    "for name in iterator:\n",
    "    name = (name or \"\").strip()\n",
    "    if not name:\n",
    "        translated_names.append(None)\n",
    "        continue\n",
    "\n",
    "    if needs_company_name_translation(name):\n",
    "        translated_names.append(translate_company_name_to_english(name))\n",
    "    else:\n",
    "        # Already non-CJK (likely English), keep as-is\n",
    "        translated_names.append(name)\n",
    "\n",
    "df[\"company_name_english_llm\"] = translated_names\n",
    "llm_results_df = df\n",
    "\n",
    "print(\"‚úÖ Company name translation completed and cached.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "846515a6-8ee7-4002-9b82-846a0e5c9661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ca4931751b4fcf9e46f8c8ec35258e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating company names:   0%|          | 0/80 [00:00<?, ?name/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b13036292fb4a0c89365c2e722f257c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating business_summary:   0%|          | 0/80 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543a0a2a071d4e32b339f93aa5a0c1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating service_or_product:   0%|          | 0/80 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d992cdbc8f6346b5b460a336ca580d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating target_market:   0%|          | 0/80 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a05c7b6beeb45eea195ea820419815e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating customer_segments:   0%|          | 0/80 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL-level startup rows: 52\n",
      "Unique companies: 52\n",
      "\n",
      "‚úÖ Company-level dataset created\n",
      "Companies: 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name_display</th>\n",
       "      <th>funding_round</th>\n",
       "      <th>funding_amount_fmt</th>\n",
       "      <th>funding_amount_currency</th>\n",
       "      <th>max_confidence</th>\n",
       "      <th>num_sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perio Therapia</td>\n",
       "      <td>Additional funding round</td>\n",
       "      <td>100,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inovacell</td>\n",
       "      <td>Series D</td>\n",
       "      <td>1,060,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bitBiome</td>\n",
       "      <td>Global Seed Extension Second Close</td>\n",
       "      <td>400,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Power Diamond Systems</td>\n",
       "      <td>Third-party allotment (2nd close)</td>\n",
       "      <td>100,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Legalscape</td>\n",
       "      <td>Secondary transaction</td>\n",
       "      <td>160,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bythen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sukidayo</td>\n",
       "      <td>Not explicitly stated, but funding was raised ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Legal Agent</td>\n",
       "      <td>J-KISS convertible note</td>\n",
       "      <td>50,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Manabie International Pte. Ltd.</td>\n",
       "      <td>Series B</td>\n",
       "      <td>3,300,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Medteria</td>\n",
       "      <td>Series Unknown (first disclosed round)</td>\n",
       "      <td>100,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FirstShift</td>\n",
       "      <td>None</td>\n",
       "      <td>50,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Swap</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Regional Fish</td>\n",
       "      <td>Series C</td>\n",
       "      <td>25,300,000</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FUNDiT</td>\n",
       "      <td>Series B</td>\n",
       "      <td>960,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KAICO</td>\n",
       "      <td>Series B</td>\n",
       "      <td>540,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CAST</td>\n",
       "      <td>Third-party allocation capital increase</td>\n",
       "      <td>150,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ken Robotech</td>\n",
       "      <td>Series B Extension</td>\n",
       "      <td>180,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Eco-Pork</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lens</td>\n",
       "      <td>Seed</td>\n",
       "      <td>844,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Forest Digital</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>130,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Antler</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sakei</td>\n",
       "      <td>2nd equity crowdfunding round</td>\n",
       "      <td>40,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AstroX</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Aiterlink</td>\n",
       "      <td>Series B Extension</td>\n",
       "      <td>2,800,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Respo</td>\n",
       "      <td>Pre-Series A (First Close)</td>\n",
       "      <td>120,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GOOPASS</td>\n",
       "      <td>Series C</td>\n",
       "      <td>None</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cellid</td>\n",
       "      <td>None</td>\n",
       "      <td>2,000,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>POST COFFEE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Zaimo</td>\n",
       "      <td>Series unknown (early round)</td>\n",
       "      <td>100,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Josan-she‚Äôs</td>\n",
       "      <td>Pre-Series A</td>\n",
       "      <td>150,000,000</td>\n",
       "      <td>JPY</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               company_name_display  \\\n",
       "0                    Perio Therapia   \n",
       "1                         Inovacell   \n",
       "2                          bitBiome   \n",
       "3             Power Diamond Systems   \n",
       "4                        Legalscape   \n",
       "5                            bythen   \n",
       "6                          Sukidayo   \n",
       "7                       Legal Agent   \n",
       "8   Manabie International Pte. Ltd.   \n",
       "9                          Medteria   \n",
       "10                       FirstShift   \n",
       "11                             Swap   \n",
       "12                    Regional Fish   \n",
       "13                           FUNDiT   \n",
       "14                            KAICO   \n",
       "15                             CAST   \n",
       "16                     Ken Robotech   \n",
       "17                         Eco-Pork   \n",
       "18                             Lens   \n",
       "19                   Forest Digital   \n",
       "20                           Antler   \n",
       "21                            Sakei   \n",
       "22                           AstroX   \n",
       "23                        Aiterlink   \n",
       "24                            Respo   \n",
       "25                          GOOPASS   \n",
       "26                           Cellid   \n",
       "27                      POST COFFEE   \n",
       "28                            Zaimo   \n",
       "29                      Josan-she‚Äôs   \n",
       "\n",
       "                                        funding_round funding_amount_fmt  \\\n",
       "0                            Additional funding round        100,000,000   \n",
       "1                                            Series D      1,060,000,000   \n",
       "2                  Global Seed Extension Second Close        400,000,000   \n",
       "3                   Third-party allotment (2nd close)        100,000,000   \n",
       "4                               Secondary transaction        160,000,000   \n",
       "5                                                None               None   \n",
       "6   Not explicitly stated, but funding was raised ...               None   \n",
       "7                             J-KISS convertible note         50,000,000   \n",
       "8                                            Series B      3,300,000,000   \n",
       "9              Series Unknown (first disclosed round)        100,000,000   \n",
       "10                                               None         50,000,000   \n",
       "11                                       Pre-Series A               None   \n",
       "12                                           Series C         25,300,000   \n",
       "13                                           Series B        960,000,000   \n",
       "14                                           Series B        540,000,000   \n",
       "15            Third-party allocation capital increase        150,000,000   \n",
       "16                                 Series B Extension        180,000,000   \n",
       "17                                               None               None   \n",
       "18                                               Seed        844,000,000   \n",
       "19                                       Pre-Series A        130,000,000   \n",
       "20                                               None               None   \n",
       "21                      2nd equity crowdfunding round         40,000,000   \n",
       "22                                               None               None   \n",
       "23                                 Series B Extension      2,800,000,000   \n",
       "24                         Pre-Series A (First Close)        120,000,000   \n",
       "25                                           Series C               None   \n",
       "26                                               None      2,000,000,000   \n",
       "27                                               None               None   \n",
       "28                       Series unknown (early round)        100,000,000   \n",
       "29                                       Pre-Series A        150,000,000   \n",
       "\n",
       "   funding_amount_currency  max_confidence  num_sources  \n",
       "0                      JPY            0.95            1  \n",
       "1                      JPY            0.95            1  \n",
       "2                      JPY            0.95            1  \n",
       "3                      JPY            0.95            1  \n",
       "4                      JPY            0.95            1  \n",
       "5                     None            0.95            1  \n",
       "6                     None            0.95            1  \n",
       "7                      JPY            0.95            1  \n",
       "8                      JPY            0.95            1  \n",
       "9                      JPY            0.95            1  \n",
       "10                     JPY            0.95            1  \n",
       "11                    None            0.95            1  \n",
       "12                     USD            0.95            1  \n",
       "13                     JPY            0.95            1  \n",
       "14                     JPY            0.95            1  \n",
       "15                     JPY            0.95            1  \n",
       "16                     JPY            0.95            1  \n",
       "17                    None            0.95            1  \n",
       "18                     JPY            0.95            1  \n",
       "19                     JPY            0.95            1  \n",
       "20                    None            0.95            1  \n",
       "21                     JPY            0.95            1  \n",
       "22                    None            0.95            1  \n",
       "23                     JPY            0.95            1  \n",
       "24                     JPY            0.95            1  \n",
       "25                     JPY            0.95            1  \n",
       "26                     JPY            0.95            1  \n",
       "27                    None            0.95            1  \n",
       "28                     JPY            0.95            1  \n",
       "29                     JPY            0.95            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with CJK in company_name_display: 0\n",
      "Missing funding_amount_numeric: 23\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 013-8 Entity Resolution, Formatting, and Deduplication\n",
    "# ============================================================\n",
    "# This section consolidates URL-level startup records into a clean company-level dataset by:\n",
    "#   - Normalizing company names (deterministic)\n",
    "#   - Resolving entities (name-based)\n",
    "#   - Deduplicating and aggregating multiple sources per company\n",
    "#   - Parsing funding amounts into numeric values\n",
    "#   - Translating company names and key descriptive fields into English (OpenAI API)\n",
    "#   - Providing display-friendly formatting (e.g., 1,234,567)\n",
    "#\n",
    "# Input:\n",
    "#   - llm_results_df (output of Section 013-7)\n",
    "#\n",
    "# Output:\n",
    "#   - company_level_df (one row per company_key)\n",
    "#\n",
    "# Notes:\n",
    "#   - Original text is always preserved.\n",
    "#   - English translations are stored in separate *_en or *_english_llm fields.\n",
    "#   - Display columns are English-first; `company_name_display` is ENGLISH-ONLY\n",
    "#     (no Japanese/CJK fallback).\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from hashlib import sha1\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ----------------------------\n",
    "# 8-1. Regex helpers (language detection)\n",
    "# ----------------------------\n",
    "_CJK_RE = re.compile(r\"[\\u3040-\\u30ff\\u3400-\\u4dbf\\u4e00-\\u9fff]\")   # JP + CJK\n",
    "_LATIN_RE = re.compile(r\"[A-Za-z]\")\n",
    "\n",
    "def contains_cjk(text: str) -> bool:\n",
    "    return bool(text) and bool(_CJK_RE.search(str(text)))\n",
    "\n",
    "def contains_latin(text: str) -> bool:\n",
    "    return bool(text) and bool(_LATIN_RE.search(str(text)))\n",
    "\n",
    "# ----------------------------\n",
    "# 8-2. Company name normalization (deterministic)\n",
    "# ----------------------------\n",
    "LEGAL_SUFFIX_PATTERNS = [\n",
    "    r\"\\binc\\b\\.?\", r\"\\bincorporated\\b\",\n",
    "    r\"\\bltd\\b\\.?\", r\"\\blimited\\b\",\n",
    "    r\"\\bco\\b\\.?\", r\"\\bcompany\\b\",\n",
    "    r\"\\bcorp\\b\\.?\", r\"\\bcorporation\\b\",\n",
    "    r\"\\bllc\\b\", r\"\\bplc\\b\", r\"\\bgmbh\\b\",\n",
    "    r\"\\bs\\.a\\.?\\b\", r\"\\bs\\.a\\.s\\.?\\b\",\n",
    "    r\"\\bkk\\b\", r\"\\bkaisha\\b\",\n",
    "    r\"Ê†™Âºè‰ºöÁ§æ\", r\"ÔºàÊ†™Ôºâ\", r\"\\(Ê†™\\)\", r\"ÊúâÈôê‰ºöÁ§æ\", r\"ÂêàÂêå‰ºöÁ§æ\"\n",
    "]\n",
    "\n",
    "def split_company_name_bilingual(name: str):\n",
    "    \"\"\"\n",
    "    Split a company name into:\n",
    "      - company_name_local: if it contains Japanese/CJK characters\n",
    "      - company_name_english: if it contains Latin characters\n",
    "    If the input contains both, both fields may be populated.\n",
    "    \"\"\"\n",
    "    if not name:\n",
    "        return None, None\n",
    "    s = unicodedata.normalize(\"NFKC\", str(name)).strip()\n",
    "    return (s if contains_cjk(s) else None), (s if contains_latin(s) else None)\n",
    "\n",
    "def normalize_company_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a company name into a canonical string for deterministic deduplication.\n",
    "    \"\"\"\n",
    "    if not name:\n",
    "        return None\n",
    "\n",
    "    s = unicodedata.normalize(\"NFKC\", str(name)).strip()\n",
    "\n",
    "    # Remove legal suffixes\n",
    "    for pat in LEGAL_SUFFIX_PATTERNS:\n",
    "        s = re.sub(pat, \"\", s, flags=re.IGNORECASE)\n",
    "\n",
    "    # Keep alphanumerics, CJK characters, and spaces only\n",
    "    s = re.sub(r\"[^\\w\\u3040-\\u30ff\\u3400-\\u4dbf\\u4e00-\\u9fff\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip().lower()\n",
    "\n",
    "    return s or None\n",
    "\n",
    "def make_company_key(country: str, company_name_norm: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a stable, deterministic company key using country + normalized name.\n",
    "    \"\"\"\n",
    "    if not company_name_norm:\n",
    "        return None\n",
    "    base = f\"{(country or '').upper()}::{company_name_norm}\"\n",
    "    return sha1(base.encode(\"utf-8\")).hexdigest()[:16]\n",
    "\n",
    "# ----------------------------\n",
    "# 8-3. Funding amount parsing (numeric) + display formatting\n",
    "# ----------------------------\n",
    "MULTIPLIERS = {\n",
    "    \"k\": 1e3, \"m\": 1e6, \"b\": 1e9,\n",
    "    \"million\": 1e6, \"billion\": 1e9,\n",
    "    \"ÂÑÑ\": 1e8, \"‰∏á\": 1e4\n",
    "}\n",
    "\n",
    "def parse_funding_amount_to_number(text: str):\n",
    "    \"\"\"\n",
    "    Best-effort parsing of funding amount text into an integer number.\n",
    "    Returns None if parsing fails.\n",
    "    Examples:\n",
    "      - \"10.6ÂÑÑÂÜÜ\" -> 1,060,000,000 (stored as 1060000000)\n",
    "      - \"4ÂÑÑÂÜÜ\"    -> 400,000,000\n",
    "      - \"USD 12.5M\"-> 12,500,000\n",
    "      - \"¬•500M\"    -> 500,000,000\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    t = text.strip().replace(\",\", \"\")\n",
    "    t_low = t.lower()\n",
    "\n",
    "    # Japanese formats: \"10.6ÂÑÑÂÜÜ\", \"3000‰∏áÂÜÜ\"\n",
    "    m = re.search(r\"([\\d\\.]+)\\s*(ÂÑÑ|‰∏á)\\s*ÂÜÜ\", t_low)\n",
    "    if m:\n",
    "        value = float(m.group(1)) * MULTIPLIERS[m.group(2)]\n",
    "        return int(round(value))\n",
    "\n",
    "    # Western formats: \"12.5M\", \"1.2B\", \"500k\"\n",
    "    m = re.search(r\"([\\d\\.]+)\\s*(k|m|b|million|billion)\\b\", t_low)\n",
    "    if m:\n",
    "        value = float(m.group(1)) * MULTIPLIERS[m.group(2)]\n",
    "        return int(round(value))\n",
    "\n",
    "    # Fallback: extract a large integer token\n",
    "    m = re.search(r\"\\b(\\d{6,})\\b\", t_low)\n",
    "    if m:\n",
    "        try:\n",
    "            return int(m.group(1))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "def format_int_commas(x):\n",
    "    \"\"\"\n",
    "    Format integers with thousand separators: 1234567 -> \"1,234,567\"\n",
    "    \"\"\"\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return None\n",
    "    try:\n",
    "        return f\"{int(x):,}\"\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ----------------------------\n",
    "# 8-4. OpenAI translation layer with caching\n",
    "# ----------------------------\n",
    "# Requirements:\n",
    "#   - `client` must be defined (from Section 013-4 OpenAI setup).\n",
    "#   - Translation is best-effort and NOT guaranteed to match official naming.\n",
    "#   - We cache translations to avoid repeated API cost.\n",
    "#\n",
    "# Translation policy in this cell:\n",
    "#   - Company names: if ANY CJK is present, ALWAYS produce an English display name.\n",
    "#   - Descriptive fields: translate when CJK is present and Latin is not present.\n",
    "\n",
    "TRANSLATION_CACHE_DIR = Path(\"./cache_translation\")\n",
    "TRANSLATION_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "COMPANY_NAME_TRANSLATION_CACHE_DIR = Path(\"./cache_company_name_translation\")\n",
    "COMPANY_NAME_TRANSLATION_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _cache_path_for_text(cache_dir: Path, text: str) -> Path:\n",
    "    key = hashlib.sha256(text.encode(\"utf-8\")).hexdigest()[:24]\n",
    "    return cache_dir / f\"{key}.txt\"\n",
    "\n",
    "def translate_text_to_english(text: str, model: str = \"gpt-4.1-mini\") -> str:\n",
    "    \"\"\"\n",
    "    Translate arbitrary text into English. Uses cache.\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    p = _cache_path_for_text(TRANSLATION_CACHE_DIR, text)\n",
    "    if p.exists():\n",
    "        return p.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Translate the following text into clear, professional English.\n",
    "Preserve the original meaning faithfully.\n",
    "Do NOT add interpretation or extra information.\n",
    "Return ONLY the translated text.\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\"\"\".strip()\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional translator.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    translated = resp.choices[0].message.content.strip()\n",
    "    p.write_text(translated, encoding=\"utf-8\")\n",
    "    return translated\n",
    "\n",
    "def translate_company_name_to_english(name: str, model: str = \"gpt-4.1-mini\") -> str:\n",
    "    \"\"\"\n",
    "    Translate a Japanese/CJK company name into natural English. Uses cache.\n",
    "    Retries once if the output still contains CJK characters.\n",
    "    \"\"\"\n",
    "    if not name or not isinstance(name, str):\n",
    "        return None\n",
    "\n",
    "    p = _cache_path_for_text(COMPANY_NAME_TRANSLATION_CACHE_DIR, name)\n",
    "    if p.exists():\n",
    "        return p.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Translate the following company name into natural, concise English.\n",
    "\n",
    "Rules:\n",
    "- Do NOT add legal suffixes such as \"Inc.\", \"Ltd.\", etc., unless clearly implied.\n",
    "- If the name is a coined brand name, transliterate appropriately.\n",
    "- Return ONLY the English name (no Japanese characters).\n",
    "\n",
    "Company name:\n",
    "{name}\n",
    "\"\"\".strip()\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional business translator.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    translated = resp.choices[0].message.content.strip()\n",
    "\n",
    "    # Retry once if CJK remains\n",
    "    if contains_cjk(translated):\n",
    "        prompt_retry = f\"\"\"\n",
    "Convert the following company name into an English rendering.\n",
    "\n",
    "Rules:\n",
    "- Output MUST be in English (no Japanese characters).\n",
    "- If you cannot find an official English name, provide a romanized/transliterated version.\n",
    "- Return ONLY the name.\n",
    "\n",
    "Company name:\n",
    "{name}\n",
    "\"\"\".strip()\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a professional business translator.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt_retry}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        translated = resp.choices[0].message.content.strip()\n",
    "\n",
    "    p.write_text(translated, encoding=\"utf-8\")\n",
    "    return translated\n",
    "\n",
    "def needs_translation_to_english(text: str) -> bool:\n",
    "    \"\"\"\n",
    "    Translate descriptive fields when the text contains CJK and does not contain Latin characters.\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return False\n",
    "    return contains_cjk(text) and not contains_latin(text)\n",
    "\n",
    "# ----------------------------\n",
    "# 8-5. Prepare URL-level working table (startups only)\n",
    "# ----------------------------\n",
    "df = llm_results_df.copy()\n",
    "df = df[df[\"is_startup\"] == \"Yes\"].copy()\n",
    "\n",
    "expected_cols = [\n",
    "    \"company_name\", \"country\", \"confidence\",\n",
    "    \"business_summary\", \"service_or_product\", \"target_market\", \"customer_segments\",\n",
    "    \"funding_round\", \"funding_amount\", \"funding_amount_currency\",\n",
    "    \"total_funding_to_date\", \"valuation\",\n",
    "    \"investors\", \"source_urls\"\n",
    "]\n",
    "for col in expected_cols:\n",
    "    if col not in df.columns:\n",
    "        df[col] = None\n",
    "\n",
    "# Preserve original company name (avoid turning NaN into string \"nan\")\n",
    "df[\"company_name_original\"] = df[\"company_name\"].where(df[\"company_name\"].notna(), None)\n",
    "\n",
    "# Split bilingual forms if present (from the original string)\n",
    "df[[\"company_name_local\", \"company_name_english\"]] = df[\"company_name\"].apply(\n",
    "    lambda x: pd.Series(split_company_name_bilingual(x))\n",
    ")\n",
    "\n",
    "# ---- Company name translation (ALWAYS if any CJK exists) ----\n",
    "company_name_english_llm = []\n",
    "for name in tqdm(df[\"company_name\"].fillna(\"\").tolist(), desc=\"Translating company names\", unit=\"name\"):\n",
    "    name = (name or \"\").strip()\n",
    "    if not name:\n",
    "        company_name_english_llm.append(None)\n",
    "        continue\n",
    "\n",
    "    if contains_cjk(name):\n",
    "        company_name_english_llm.append(translate_company_name_to_english(name))\n",
    "    else:\n",
    "        # already non-CJK (likely English) -> keep\n",
    "        company_name_english_llm.append(name)\n",
    "\n",
    "df[\"company_name_english_llm\"] = company_name_english_llm\n",
    "\n",
    "# ---- Translate key narrative fields into English (store separately) ----\n",
    "FIELDS_TO_TRANSLATE = [\"business_summary\", \"service_or_product\", \"target_market\", \"customer_segments\"]\n",
    "for field in FIELDS_TO_TRANSLATE:\n",
    "    en_field = f\"{field}_en\"\n",
    "    out = []\n",
    "    for text in tqdm(df[field].fillna(\"\").tolist(), desc=f\"Translating {field}\", unit=\"row\"):\n",
    "        text = (text or \"\").strip()\n",
    "        if not text:\n",
    "            out.append(None)\n",
    "        elif needs_translation_to_english(text):\n",
    "            out.append(translate_text_to_english(text))\n",
    "        else:\n",
    "            # If already English/mixed, keep original as \"display\" later; no translation needed\n",
    "            out.append(None)\n",
    "    df[en_field] = out\n",
    "\n",
    "# Deterministic name normalization + company key\n",
    "df[\"company_name_norm\"] = df[\"company_name\"].apply(normalize_company_name)\n",
    "df[\"company_key\"] = df.apply(\n",
    "    lambda r: make_company_key(r.get(\"country\"), r.get(\"company_name_norm\")),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Funding numeric + formatted display\n",
    "df[\"funding_amount_numeric\"] = df[\"funding_amount\"].apply(parse_funding_amount_to_number)\n",
    "df[\"funding_amount_fmt\"] = df[\"funding_amount_numeric\"].apply(format_int_commas)\n",
    "\n",
    "df = df[df[\"company_key\"].notna()].reset_index(drop=True)\n",
    "\n",
    "print(\"URL-level startup rows:\", len(df))\n",
    "print(\"Unique companies:\", df[\"company_key\"].nunique())\n",
    "\n",
    "# ----------------------------\n",
    "# 8-6. Aggregation helpers\n",
    "# ----------------------------\n",
    "def merge_unique_lists(series):\n",
    "    seen, out = set(), []\n",
    "    for x in series.dropna():\n",
    "        items = x if isinstance(x, list) else [x]\n",
    "        for item in items:\n",
    "            if item is None:\n",
    "                continue\n",
    "            item = str(item).strip()\n",
    "            if not item or item in seen:\n",
    "                continue\n",
    "            seen.add(item)\n",
    "            out.append(item)\n",
    "    return out\n",
    "\n",
    "def pick_highest_confidence_row(g: pd.DataFrame) -> pd.Series:\n",
    "    return g.sort_values(\"confidence\", ascending=False).iloc[0]\n",
    "\n",
    "def english_first(en_text: str, original_text: str):\n",
    "    \"\"\"\n",
    "    Prefer English translation when available; otherwise fall back to original.\n",
    "    \"\"\"\n",
    "    return en_text if (en_text is not None and str(en_text).strip()) else (original_text if original_text else None)\n",
    "\n",
    "# ----------------------------\n",
    "# 8-7. Company-level aggregation\n",
    "# ----------------------------\n",
    "company_rows = []\n",
    "\n",
    "for company_key, g in df.groupby(\"company_key\", sort=False):\n",
    "    best = pick_highest_confidence_row(g)\n",
    "\n",
    "    # ENGLISH-ONLY display name (no CJK fallback)\n",
    "    company_name_display = (\n",
    "        best.get(\"company_name_english_llm\")\n",
    "        or best.get(\"company_name_english\")\n",
    "        or None\n",
    "    )\n",
    "\n",
    "    company_rows.append({\n",
    "        \"company_key\": company_key,\n",
    "        \"country\": best.get(\"country\"),\n",
    "\n",
    "        # Company names (English display only; preserve original/local separately)\n",
    "        \"company_name_display\": company_name_display,\n",
    "        \"company_name_english_llm\": best.get(\"company_name_english_llm\"),\n",
    "        \"company_name_english\": best.get(\"company_name_english\"),\n",
    "        \"company_name_local\": best.get(\"company_name_local\"),\n",
    "        \"company_name_original\": best.get(\"company_name_original\"),\n",
    "        \"company_name_norm\": best.get(\"company_name_norm\"),\n",
    "\n",
    "        # Core narrative (English-first display; preserve original + translated)\n",
    "        \"business_summary\": best.get(\"business_summary\"),\n",
    "        \"business_summary_en\": best.get(\"business_summary_en\"),\n",
    "        \"business_summary_display\": english_first(best.get(\"business_summary_en\"), best.get(\"business_summary\")),\n",
    "\n",
    "        \"service_or_product\": best.get(\"service_or_product\"),\n",
    "        \"service_or_product_en\": best.get(\"service_or_product_en\"),\n",
    "        \"service_or_product_display\": english_first(best.get(\"service_or_product_en\"), best.get(\"service_or_product\")),\n",
    "\n",
    "        \"target_market\": best.get(\"target_market\"),\n",
    "        \"target_market_en\": best.get(\"target_market_en\"),\n",
    "        \"target_market_display\": english_first(best.get(\"target_market_en\"), best.get(\"target_market\")),\n",
    "\n",
    "        \"customer_segments\": best.get(\"customer_segments\"),\n",
    "        \"customer_segments_en\": best.get(\"customer_segments_en\"),\n",
    "        \"customer_segments_display\": english_first(best.get(\"customer_segments_en\"), best.get(\"customer_segments\")),\n",
    "\n",
    "        # Funding (numeric + formatted)\n",
    "        \"funding_round\": best.get(\"funding_round\"),\n",
    "        \"funding_amount_numeric\": best.get(\"funding_amount_numeric\"),\n",
    "        \"funding_amount_fmt\": format_int_commas(best.get(\"funding_amount_numeric\")),\n",
    "        \"funding_amount_raw\": best.get(\"funding_amount\"),\n",
    "        \"funding_amount_currency\": best.get(\"funding_amount_currency\"),\n",
    "        \"total_funding_to_date\": best.get(\"total_funding_to_date\"),\n",
    "        \"valuation\": best.get(\"valuation\"),\n",
    "\n",
    "        # Aggregated fields\n",
    "        \"investors\": merge_unique_lists(g.get(\"investors\", pd.Series([]))),\n",
    "        \"source_urls\": merge_unique_lists(g.get(\"source_urls\", pd.Series([]))),\n",
    "\n",
    "        # Metadata\n",
    "        \"max_confidence\": float(g[\"confidence\"].max()),\n",
    "        \"num_sources\": int(len(g))\n",
    "    })\n",
    "\n",
    "company_level_df = pd.DataFrame(company_rows).sort_values(\n",
    "    by=[\"max_confidence\", \"num_sources\"],\n",
    "    ascending=[False, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Remove rows where we still do not have an English display name\n",
    "company_level_df = company_level_df[company_level_df[\"company_name_display\"].notna()].copy().reset_index(drop=True)\n",
    "\n",
    "print(\"\\n‚úÖ Company-level dataset created\")\n",
    "print(\"Companies:\", len(company_level_df))\n",
    "\n",
    "# Compact overview\n",
    "display_cols = [\n",
    "    \"company_name_display\",\n",
    "    \"funding_round\",\n",
    "    \"funding_amount_fmt\",\n",
    "    \"funding_amount_currency\",\n",
    "    \"max_confidence\",\n",
    "    \"num_sources\"\n",
    "]\n",
    "display(company_level_df[display_cols].head(30))\n",
    "\n",
    "# ----------------------------\n",
    "# 8-8. Sanity checks\n",
    "# ----------------------------\n",
    "assert company_level_df[\"company_key\"].is_unique, \"Duplicate company_key detected.\"\n",
    "\n",
    "# Ensure company_name_display contains no CJK characters\n",
    "bad = company_level_df[\"company_name_display\"].dropna().apply(contains_cjk)\n",
    "print(\"Rows with CJK in company_name_display:\", int(bad.sum()))\n",
    "if bad.any():\n",
    "    display(company_level_df.loc[bad, [\"company_name_display\", \"company_name_local\", \"company_name_original\"]].head(20))\n",
    "\n",
    "print(\"Missing funding_amount_numeric:\", company_level_df[\"funding_amount_numeric\"].isna().sum())\n",
    "\n",
    "# Next:\n",
    "#   - Section 013-9 Output generation (CSV / Parquet / SQLite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "907d91ed-24db-40a5-aa86-76e6574b559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Export timestamp (UTC): 20251229_052907\n",
      "üìÅ Output folder: /Users/yuetoya/Desktop/researchOS100-private/notebooks/data\n",
      "‚úÖ Saved CSV: data/company_level_20251229_052907.csv\n",
      "‚ÑπÔ∏è Parquet export skipped (optional dependency not installed).\n",
      "   Reason: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\n",
      "   ‚Üí CSV export is still available and sufficient for most use cases.\n",
      "‚úÖ Saved URL-level CSV: data/url_level_startups_20251229_052907.csv\n",
      "‚úÖ Saved manifest: data/run_manifest_20251229_052907.json\n",
      "\n",
      "üìå Preview (top rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_key</th>\n",
       "      <th>country</th>\n",
       "      <th>company_name_display</th>\n",
       "      <th>company_name_english_llm</th>\n",
       "      <th>company_name_english</th>\n",
       "      <th>company_name_local</th>\n",
       "      <th>company_name_original</th>\n",
       "      <th>business_summary_display</th>\n",
       "      <th>service_or_product_display</th>\n",
       "      <th>target_market_display</th>\n",
       "      <th>...</th>\n",
       "      <th>company_name_norm</th>\n",
       "      <th>business_summary</th>\n",
       "      <th>business_summary_en</th>\n",
       "      <th>service_or_product</th>\n",
       "      <th>service_or_product_en</th>\n",
       "      <th>target_market</th>\n",
       "      <th>target_market_en</th>\n",
       "      <th>customer_segments</th>\n",
       "      <th>customer_segments_en</th>\n",
       "      <th>funding_amount_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8632be66cb22e714</td>\n",
       "      <td>JP</td>\n",
       "      <td>Perio Therapia</td>\n",
       "      <td>Perio Therapia</td>\n",
       "      <td>None</td>\n",
       "      <td>„Éö„É™„Ç™„Çª„É©„Éî„Ç¢Ê†™Âºè‰ºöÁ§æ</td>\n",
       "      <td>„Éö„É™„Ç™„Çª„É©„Éî„Ç¢Ê†™Âºè‰ºöÁ§æ</td>\n",
       "      <td>A drug discovery venture originating from Osak...</td>\n",
       "      <td>Antibody drugs targeting pathological periosti...</td>\n",
       "      <td>Triple-negative breast cancer and metastatic r...</td>\n",
       "      <td>...</td>\n",
       "      <td>„Éö„É™„Ç™„Çª„É©„Éî„Ç¢</td>\n",
       "      <td>A drug discovery venture originating from Osak...</td>\n",
       "      <td>None</td>\n",
       "      <td>Antibody drugs targeting pathological periosti...</td>\n",
       "      <td>None</td>\n",
       "      <td>Triple-negative breast cancer and metastatic r...</td>\n",
       "      <td>None</td>\n",
       "      <td>Patients with difficult-to-treat diseases such...</td>\n",
       "      <td>None</td>\n",
       "      <td>Á¥Ñ1ÂÑÑÂÜÜ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80b9c03f7ffa10ad</td>\n",
       "      <td>JP</td>\n",
       "      <td>Inovacell</td>\n",
       "      <td>Inovacell</td>\n",
       "      <td>None</td>\n",
       "      <td>„Ç§„Éé„Éê„Çª„É´Ê†™Âºè‰ºöÁ§æ</td>\n",
       "      <td>„Ç§„Éé„Éê„Çª„É´Ê†™Âºè‰ºöÁ§æ</td>\n",
       "      <td>Innovacell is a regenerative medicine venture ...</td>\n",
       "      <td>ICEF15, a cell therapy product using patient's...</td>\n",
       "      <td>Patients suffering from urge fecal incontinenc...</td>\n",
       "      <td>...</td>\n",
       "      <td>„Ç§„Éé„Éê„Çª„É´</td>\n",
       "      <td>Innovacell is a regenerative medicine venture ...</td>\n",
       "      <td>None</td>\n",
       "      <td>ICEF15, a cell therapy product using patient's...</td>\n",
       "      <td>None</td>\n",
       "      <td>Patients suffering from urge fecal incontinenc...</td>\n",
       "      <td>None</td>\n",
       "      <td>Healthcare providers and patients requiring tr...</td>\n",
       "      <td>None</td>\n",
       "      <td>10.6ÂÑÑÂÜÜ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>542fdb9efc59f6e1</td>\n",
       "      <td>JP</td>\n",
       "      <td>bitBiome</td>\n",
       "      <td>bitBiome</td>\n",
       "      <td>bitBiomeÊ†™Âºè‰ºöÁ§æ</td>\n",
       "      <td>bitBiomeÊ†™Âºè‰ºöÁ§æ</td>\n",
       "      <td>bitBiomeÊ†™Âºè‰ºöÁ§æ</td>\n",
       "      <td>bitBiome is a biotechnology company leveraging...</td>\n",
       "      <td>Microbial genome database (bit-GEM), single-ce...</td>\n",
       "      <td>Biomanufacturing industry, pharmaceutical manu...</td>\n",
       "      <td>...</td>\n",
       "      <td>bitbiome</td>\n",
       "      <td>bitBiome is a biotechnology company leveraging...</td>\n",
       "      <td>None</td>\n",
       "      <td>Microbial genome database (bit-GEM), single-ce...</td>\n",
       "      <td>None</td>\n",
       "      <td>Biomanufacturing industry, pharmaceutical manu...</td>\n",
       "      <td>None</td>\n",
       "      <td>Biotech companies, pharmaceutical companies, r...</td>\n",
       "      <td>None</td>\n",
       "      <td>400,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7812d7f415357394</td>\n",
       "      <td>JP</td>\n",
       "      <td>Power Diamond Systems</td>\n",
       "      <td>Power Diamond Systems</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æPower Diamond Systems</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æPower Diamond Systems</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æPower Diamond Systems</td>\n",
       "      <td>Power Diamond Systems is a startup conducting ...</td>\n",
       "      <td>Diamond semiconductor devices and modules</td>\n",
       "      <td>Next-generation power electronics including el...</td>\n",
       "      <td>...</td>\n",
       "      <td>power diamond systems</td>\n",
       "      <td>Power Diamond Systems is a startup conducting ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Diamond semiconductor devices and modules</td>\n",
       "      <td>None</td>\n",
       "      <td>Next-generation power electronics including el...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>100000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dd11d5fb630ed8f2</td>\n",
       "      <td>JP</td>\n",
       "      <td>Legalscape</td>\n",
       "      <td>Legalscape</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æLegalscape</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æLegalscape</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æLegalscape</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æLegalscape provides an AI-powered legal re...</td>\n",
       "      <td>AI legal research platform 'Legalscape' that i...</td>\n",
       "      <td>Legal professionals including lawyers, corpora...</td>\n",
       "      <td>...</td>\n",
       "      <td>legalscape</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æLegalscape provides an AI-powered legal re...</td>\n",
       "      <td>None</td>\n",
       "      <td>AI legal research platform 'Legalscape' that i...</td>\n",
       "      <td>None</td>\n",
       "      <td>Legal professionals including lawyers, corpora...</td>\n",
       "      <td>None</td>\n",
       "      <td>Lawyers, corporate legal departments, social i...</td>\n",
       "      <td>None</td>\n",
       "      <td>160,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e77464f75872db2c</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>bythen</td>\n",
       "      <td>bythen</td>\n",
       "      <td>bythen</td>\n",
       "      <td>None</td>\n",
       "      <td>bythen</td>\n",
       "      <td>bythen is an AI technology startup specializin...</td>\n",
       "      <td>Personalized AI assistant, 3D avatar 'Bytes', ...</td>\n",
       "      <td>Global online content creators and consumers, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>bythen</td>\n",
       "      <td>bythen is an AI technology startup specializin...</td>\n",
       "      <td>None</td>\n",
       "      <td>Personalized AI assistant, 3D avatar 'Bytes', ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Global online content creators and consumers, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Content creators, consumers interested in virt...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>edf81f95b08df804</td>\n",
       "      <td>JP</td>\n",
       "      <td>Sukidayo</td>\n",
       "      <td>Sukidayo</td>\n",
       "      <td>None</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà is a startup focused on solving socia...</td>\n",
       "      <td>„Ç´„ÉÉ„Éó„É´Tech„Ç¢„Éó„É™„Äå„Åµ„Åü„Çä‰ºöË≠∞„Äç, a communication app that h...</td>\n",
       "      <td>Couples and families in Japan and potentially ...</td>\n",
       "      <td>...</td>\n",
       "      <td>„Åô„Åç„Å†„Çà</td>\n",
       "      <td>Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà is a startup focused on solving socia...</td>\n",
       "      <td>None</td>\n",
       "      <td>„Ç´„ÉÉ„Éó„É´Tech„Ç¢„Éó„É™„Äå„Åµ„Åü„Çä‰ºöË≠∞„Äç, a communication app that h...</td>\n",
       "      <td>None</td>\n",
       "      <td>Couples and families in Japan and potentially ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Couples, spouses, families, and organizations ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c263a03fa987f706</td>\n",
       "      <td>JP</td>\n",
       "      <td>Legal Agent</td>\n",
       "      <td>Legal Agent</td>\n",
       "      <td>Legal Agent</td>\n",
       "      <td>None</td>\n",
       "      <td>Legal Agent</td>\n",
       "      <td>Legal Agent provides legal services leveraging...</td>\n",
       "      <td>Legal services powered by generative AI and la...</td>\n",
       "      <td>Enterprises, venture capital (VC) and corporat...</td>\n",
       "      <td>...</td>\n",
       "      <td>legal agent</td>\n",
       "      <td>Legal Agent provides legal services leveraging...</td>\n",
       "      <td>None</td>\n",
       "      <td>Legal services powered by generative AI and la...</td>\n",
       "      <td>None</td>\n",
       "      <td>Enterprises, venture capital (VC) and corporat...</td>\n",
       "      <td>None</td>\n",
       "      <td>Enterprise legal departments, VC/CVC firms, st...</td>\n",
       "      <td>None</td>\n",
       "      <td>50,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>310f8f37762c6c74</td>\n",
       "      <td>JP</td>\n",
       "      <td>Manabie International Pte. Ltd.</td>\n",
       "      <td>Manabie International Pte. Ltd.</td>\n",
       "      <td>Manabie International Pte. Ltd.</td>\n",
       "      <td>None</td>\n",
       "      <td>Manabie International Pte. Ltd.</td>\n",
       "      <td>Manabie is an EdTech startup providing an educ...</td>\n",
       "      <td>Manabie LMS (learning management system), Mana...</td>\n",
       "      <td>Education institutions including cram schools ...</td>\n",
       "      <td>...</td>\n",
       "      <td>manabie international pte</td>\n",
       "      <td>Manabie is an EdTech startup providing an educ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Manabie LMS (learning management system), Mana...</td>\n",
       "      <td>None</td>\n",
       "      <td>Education institutions including cram schools ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Learning institutions such as cram schools and...</td>\n",
       "      <td>None</td>\n",
       "      <td>33ÂÑÑÂÜÜ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e007166977e5d928</td>\n",
       "      <td>JP</td>\n",
       "      <td>Medteria</td>\n",
       "      <td>Medteria</td>\n",
       "      <td>Medteria</td>\n",
       "      <td>None</td>\n",
       "      <td>Medteria</td>\n",
       "      <td>Medteria provides a healthcare communication c...</td>\n",
       "      <td>Healthcare communication cloud platform enabli...</td>\n",
       "      <td>Medical professionals, medical students, unive...</td>\n",
       "      <td>...</td>\n",
       "      <td>medteria</td>\n",
       "      <td>Medteria provides a healthcare communication c...</td>\n",
       "      <td>None</td>\n",
       "      <td>Healthcare communication cloud platform enabli...</td>\n",
       "      <td>None</td>\n",
       "      <td>Medical professionals, medical students, unive...</td>\n",
       "      <td>None</td>\n",
       "      <td>Medical students, medical professionals includ...</td>\n",
       "      <td>None</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        company_key    country             company_name_display  \\\n",
       "0  8632be66cb22e714         JP                   Perio Therapia   \n",
       "1  80b9c03f7ffa10ad         JP                        Inovacell   \n",
       "2  542fdb9efc59f6e1         JP                         bitBiome   \n",
       "3  7812d7f415357394         JP            Power Diamond Systems   \n",
       "4  dd11d5fb630ed8f2         JP                       Legalscape   \n",
       "5  e77464f75872db2c  Indonesia                           bythen   \n",
       "6  edf81f95b08df804         JP                         Sukidayo   \n",
       "7  c263a03fa987f706         JP                      Legal Agent   \n",
       "8  310f8f37762c6c74         JP  Manabie International Pte. Ltd.   \n",
       "9  e007166977e5d928         JP                         Medteria   \n",
       "\n",
       "          company_name_english_llm             company_name_english  \\\n",
       "0                   Perio Therapia                             None   \n",
       "1                        Inovacell                             None   \n",
       "2                         bitBiome                     bitBiomeÊ†™Âºè‰ºöÁ§æ   \n",
       "3            Power Diamond Systems        Ê†™Âºè‰ºöÁ§æPower Diamond Systems   \n",
       "4                       Legalscape                   Ê†™Âºè‰ºöÁ§æLegalscape   \n",
       "5                           bythen                           bythen   \n",
       "6                         Sukidayo                             None   \n",
       "7                      Legal Agent                      Legal Agent   \n",
       "8  Manabie International Pte. Ltd.  Manabie International Pte. Ltd.   \n",
       "9                         Medteria                         Medteria   \n",
       "\n",
       "          company_name_local            company_name_original  \\\n",
       "0                „Éö„É™„Ç™„Çª„É©„Éî„Ç¢Ê†™Âºè‰ºöÁ§æ                      „Éö„É™„Ç™„Çª„É©„Éî„Ç¢Ê†™Âºè‰ºöÁ§æ   \n",
       "1                  „Ç§„Éé„Éê„Çª„É´Ê†™Âºè‰ºöÁ§æ                        „Ç§„Éé„Éê„Çª„É´Ê†™Âºè‰ºöÁ§æ   \n",
       "2               bitBiomeÊ†™Âºè‰ºöÁ§æ                     bitBiomeÊ†™Âºè‰ºöÁ§æ   \n",
       "3  Ê†™Âºè‰ºöÁ§æPower Diamond Systems        Ê†™Âºè‰ºöÁ§æPower Diamond Systems   \n",
       "4             Ê†™Âºè‰ºöÁ§æLegalscape                   Ê†™Âºè‰ºöÁ§æLegalscape   \n",
       "5                       None                           bythen   \n",
       "6                   Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà                         Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà   \n",
       "7                       None                      Legal Agent   \n",
       "8                       None  Manabie International Pte. Ltd.   \n",
       "9                       None                         Medteria   \n",
       "\n",
       "                            business_summary_display  \\\n",
       "0  A drug discovery venture originating from Osak...   \n",
       "1  Innovacell is a regenerative medicine venture ...   \n",
       "2  bitBiome is a biotechnology company leveraging...   \n",
       "3  Power Diamond Systems is a startup conducting ...   \n",
       "4  Ê†™Âºè‰ºöÁ§æLegalscape provides an AI-powered legal re...   \n",
       "5  bythen is an AI technology startup specializin...   \n",
       "6  Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà is a startup focused on solving socia...   \n",
       "7  Legal Agent provides legal services leveraging...   \n",
       "8  Manabie is an EdTech startup providing an educ...   \n",
       "9  Medteria provides a healthcare communication c...   \n",
       "\n",
       "                          service_or_product_display  \\\n",
       "0  Antibody drugs targeting pathological periosti...   \n",
       "1  ICEF15, a cell therapy product using patient's...   \n",
       "2  Microbial genome database (bit-GEM), single-ce...   \n",
       "3          Diamond semiconductor devices and modules   \n",
       "4  AI legal research platform 'Legalscape' that i...   \n",
       "5  Personalized AI assistant, 3D avatar 'Bytes', ...   \n",
       "6  „Ç´„ÉÉ„Éó„É´Tech„Ç¢„Éó„É™„Äå„Åµ„Åü„Çä‰ºöË≠∞„Äç, a communication app that h...   \n",
       "7  Legal services powered by generative AI and la...   \n",
       "8  Manabie LMS (learning management system), Mana...   \n",
       "9  Healthcare communication cloud platform enabli...   \n",
       "\n",
       "                               target_market_display  ...  \\\n",
       "0  Triple-negative breast cancer and metastatic r...  ...   \n",
       "1  Patients suffering from urge fecal incontinenc...  ...   \n",
       "2  Biomanufacturing industry, pharmaceutical manu...  ...   \n",
       "3  Next-generation power electronics including el...  ...   \n",
       "4  Legal professionals including lawyers, corpora...  ...   \n",
       "5  Global online content creators and consumers, ...  ...   \n",
       "6  Couples and families in Japan and potentially ...  ...   \n",
       "7  Enterprises, venture capital (VC) and corporat...  ...   \n",
       "8  Education institutions including cram schools ...  ...   \n",
       "9  Medical professionals, medical students, unive...  ...   \n",
       "\n",
       "           company_name_norm  \\\n",
       "0                    „Éö„É™„Ç™„Çª„É©„Éî„Ç¢   \n",
       "1                      „Ç§„Éé„Éê„Çª„É´   \n",
       "2                   bitbiome   \n",
       "3      power diamond systems   \n",
       "4                 legalscape   \n",
       "5                     bythen   \n",
       "6                       „Åô„Åç„Å†„Çà   \n",
       "7                legal agent   \n",
       "8  manabie international pte   \n",
       "9                   medteria   \n",
       "\n",
       "                                    business_summary  business_summary_en  \\\n",
       "0  A drug discovery venture originating from Osak...                 None   \n",
       "1  Innovacell is a regenerative medicine venture ...                 None   \n",
       "2  bitBiome is a biotechnology company leveraging...                 None   \n",
       "3  Power Diamond Systems is a startup conducting ...                 None   \n",
       "4  Ê†™Âºè‰ºöÁ§æLegalscape provides an AI-powered legal re...                 None   \n",
       "5  bythen is an AI technology startup specializin...                 None   \n",
       "6  Ê†™Âºè‰ºöÁ§æ„Åô„Åç„Å†„Çà is a startup focused on solving socia...                 None   \n",
       "7  Legal Agent provides legal services leveraging...                 None   \n",
       "8  Manabie is an EdTech startup providing an educ...                 None   \n",
       "9  Medteria provides a healthcare communication c...                 None   \n",
       "\n",
       "                                  service_or_product service_or_product_en  \\\n",
       "0  Antibody drugs targeting pathological periosti...                  None   \n",
       "1  ICEF15, a cell therapy product using patient's...                  None   \n",
       "2  Microbial genome database (bit-GEM), single-ce...                  None   \n",
       "3          Diamond semiconductor devices and modules                  None   \n",
       "4  AI legal research platform 'Legalscape' that i...                  None   \n",
       "5  Personalized AI assistant, 3D avatar 'Bytes', ...                  None   \n",
       "6  „Ç´„ÉÉ„Éó„É´Tech„Ç¢„Éó„É™„Äå„Åµ„Åü„Çä‰ºöË≠∞„Äç, a communication app that h...                  None   \n",
       "7  Legal services powered by generative AI and la...                  None   \n",
       "8  Manabie LMS (learning management system), Mana...                  None   \n",
       "9  Healthcare communication cloud platform enabli...                  None   \n",
       "\n",
       "                                       target_market target_market_en  \\\n",
       "0  Triple-negative breast cancer and metastatic r...             None   \n",
       "1  Patients suffering from urge fecal incontinenc...             None   \n",
       "2  Biomanufacturing industry, pharmaceutical manu...             None   \n",
       "3  Next-generation power electronics including el...             None   \n",
       "4  Legal professionals including lawyers, corpora...             None   \n",
       "5  Global online content creators and consumers, ...             None   \n",
       "6  Couples and families in Japan and potentially ...             None   \n",
       "7  Enterprises, venture capital (VC) and corporat...             None   \n",
       "8  Education institutions including cram schools ...             None   \n",
       "9  Medical professionals, medical students, unive...             None   \n",
       "\n",
       "                                   customer_segments customer_segments_en  \\\n",
       "0  Patients with difficult-to-treat diseases such...                 None   \n",
       "1  Healthcare providers and patients requiring tr...                 None   \n",
       "2  Biotech companies, pharmaceutical companies, r...                 None   \n",
       "3                                               None                 None   \n",
       "4  Lawyers, corporate legal departments, social i...                 None   \n",
       "5  Content creators, consumers interested in virt...                 None   \n",
       "6  Couples, spouses, families, and organizations ...                 None   \n",
       "7  Enterprise legal departments, VC/CVC firms, st...                 None   \n",
       "8  Learning institutions such as cram schools and...                 None   \n",
       "9  Medical students, medical professionals includ...                 None   \n",
       "\n",
       "   funding_amount_raw  \n",
       "0                Á¥Ñ1ÂÑÑÂÜÜ  \n",
       "1              10.6ÂÑÑÂÜÜ  \n",
       "2         400,000,000  \n",
       "3           100000000  \n",
       "4         160,000,000  \n",
       "5                None  \n",
       "6                None  \n",
       "7          50,000,000  \n",
       "8                33ÂÑÑÂÜÜ  \n",
       "9         100,000,000  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 013-9 Output Data Generation (Timestamped Exports)\n",
    "# ============================================================\n",
    "# This section exports the cleaned, company-level dataset (and optional URL-level tables)\n",
    "# into a local `data/` folder with timestamped filenames for reproducibility.\n",
    "#\n",
    "# Inputs (expected):\n",
    "#   - company_level_df  (from Section 013-8)\n",
    "#   - (optional) df     (URL-level startup table built in Section 013-8)\n",
    "#   - (optional) fetch_df / llm_results_df for deeper debugging\n",
    "#\n",
    "# Outputs:\n",
    "#   - data/company_level_<YYYYMMDD_HHMMSS>.csv\n",
    "#   - data/company_level_<YYYYMMDD_HHMMSS>.parquet\n",
    "#   - (optional) data/url_level_startups_<YYYYMMDD_HHMMSS>.csv\n",
    "#   - (optional) data/run_manifest_<YYYYMMDD_HHMMSS>.json\n",
    "#\n",
    "# Notes:\n",
    "#   - CSV is convenient for inspection and sharing.\n",
    "#   - Parquet is efficient for analysis and storage.\n",
    "#   - A manifest file captures key run metadata for auditability.\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# 9-1. Create output folder + timestamp\n",
    "# ----------------------------\n",
    "DATA_DIR = Path(\"./data\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Use UTC timestamp for reproducibility (change to local time if you prefer)\n",
    "ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(f\"üì¶ Export timestamp (UTC): {ts}\")\n",
    "print(f\"üìÅ Output folder: {DATA_DIR.resolve()}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 9-2. Basic schema checks\n",
    "# ----------------------------\n",
    "if \"company_level_df\" not in globals() or company_level_df is None or company_level_df.empty:\n",
    "    raise ValueError(\"company_level_df is missing or empty. Run Section 013-8 first.\")\n",
    "\n",
    "# Ensure stable column order (optional, but helpful)\n",
    "PREFERRED_COL_ORDER = [\n",
    "    \"company_key\", \"country\",\n",
    "    \"company_name_display\",\n",
    "    \"company_name_english_llm\", \"company_name_english\",\n",
    "    \"company_name_local\", \"company_name_original\",\n",
    "    \"business_summary_display\", \"service_or_product_display\",\n",
    "    \"target_market_display\", \"customer_segments_display\",\n",
    "    \"funding_round\",\n",
    "    \"funding_amount_numeric\", \"funding_amount_fmt\", \"funding_amount_currency\",\n",
    "    \"total_funding_to_date\", \"valuation\",\n",
    "    \"investors\", \"source_urls\",\n",
    "    \"max_confidence\", \"num_sources\"\n",
    "]\n",
    "cols = [c for c in PREFERRED_COL_ORDER if c in company_level_df.columns] + \\\n",
    "       [c for c in company_level_df.columns if c not in PREFERRED_COL_ORDER]\n",
    "\n",
    "export_company_df = company_level_df[cols].copy()\n",
    "\n",
    "# ----------------------------\n",
    "# 9-3. File paths (timestamped)\n",
    "# ----------------------------\n",
    "company_csv_path = DATA_DIR / f\"company_level_{ts}.csv\"\n",
    "company_parquet_path = DATA_DIR / f\"company_level_{ts}.parquet\"\n",
    "\n",
    "# Optional: URL-level startup table (from Section 013-8)\n",
    "url_csv_path = DATA_DIR / f\"url_level_startups_{ts}.csv\"\n",
    "\n",
    "# Optional: manifest (run metadata)\n",
    "manifest_path = DATA_DIR / f\"run_manifest_{ts}.json\"\n",
    "\n",
    "# ----------------------------\n",
    "# 9-4. Export: CSV (pandas 2.x compatible)\n",
    "# ----------------------------\n",
    "# Convert list/dict columns to JSON strings for CSV compatibility\n",
    "\n",
    "def _to_json_str_if_needed(series: pd.Series) -> pd.Series:\n",
    "    if series.dtype == \"object\":\n",
    "        return series.map(\n",
    "            lambda x: json.dumps(x, ensure_ascii=False)\n",
    "            if isinstance(x, (list, dict)) else x\n",
    "        )\n",
    "    return series\n",
    "\n",
    "export_company_csv = export_company_df.copy()\n",
    "for col in export_company_csv.columns:\n",
    "    export_company_csv[col] = _to_json_str_if_needed(export_company_csv[col])\n",
    "\n",
    "export_company_csv.to_csv(\n",
    "    company_csv_path,\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "print(f\"‚úÖ Saved CSV: {company_csv_path}\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 9-5. Export: Parquet (optional)\n",
    "# ----------------------------\n",
    "# Parquet export is optional and depends on the runtime environment.\n",
    "# If pyarrow / fastparquet is not installed, we gracefully skip.\n",
    "\n",
    "try:\n",
    "    export_company_df.to_parquet(company_parquet_path, index=False)\n",
    "    print(f\"‚úÖ Saved Parquet: {company_parquet_path}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ÑπÔ∏è Parquet export skipped (optional dependency not installed).\")\n",
    "    print(\"   Reason:\", str(e).split(\"\\n\")[0])\n",
    "    print(\"   ‚Üí CSV export is still available and sufficient for most use cases.\")\n",
    "\n",
    "# ----------------------------\n",
    "# 9-6. Optional export: URL-level startup rows used in 013-8\n",
    "# ----------------------------\n",
    "# If you kept `df` in Section 013-8, export it for debugging / traceability.\n",
    "if \"df\" in globals() and isinstance(df, pd.DataFrame) and not df.empty:\n",
    "    url_export = df.copy()\n",
    "\n",
    "    for col in url_export.columns:\n",
    "        if url_export[col].dtype == \"object\":\n",
    "            url_export[col] = url_export[col].map(\n",
    "                lambda x: json.dumps(x, ensure_ascii=False)\n",
    "                if isinstance(x, (list, dict)) else x\n",
    "            )\n",
    "\n",
    "    url_export.to_csv(url_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"‚úÖ Saved URL-level CSV: {url_csv_path}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Skipped URL-level export (df not found or empty).\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 9-7. Manifest (recommended for auditability)\n",
    "# ----------------------------\n",
    "manifest = {\n",
    "    \"timestamp_utc\": ts,\n",
    "    \"outputs\": {\n",
    "        \"company_csv\": str(company_csv_path),\n",
    "        \"company_parquet\": str(company_parquet_path),\n",
    "        \"url_level_csv\": str(url_csv_path) if url_csv_path.exists() else None\n",
    "    },\n",
    "    \"row_counts\": {\n",
    "        \"company_level_df\": int(len(company_level_df)),\n",
    "        \"url_level_df\": int(len(df)) if (\"df\" in globals() and isinstance(df, pd.DataFrame)) else None\n",
    "    },\n",
    "    \"columns\": {\n",
    "        \"company_level_df\": list(company_level_df.columns)\n",
    "    }\n",
    "}\n",
    "\n",
    "manifest_path.write_text(json.dumps(manifest, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Saved manifest: {manifest_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 9-8. Quick preview\n",
    "# ----------------------------\n",
    "print(\"\\nüìå Preview (top rows):\")\n",
    "display(export_company_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2d986-b3b3-4332-babd-7073631fc5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
